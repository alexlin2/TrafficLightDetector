{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from dataset import TrafficLightDataset, collate_fn\n",
    "from model import trafficLightDetectionModel\n",
    "from train import train_one_epoch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/home/alexlin/traffic_net/dataset_train_rgb/\"\n",
    "labels_dir = \"/home/alexlin/traffic_net/dataset_train_rgb/train.yaml\"\n",
    "classes = ['background', 'GreenLeft', 'RedStraightLeft', 'RedLeft', 'off', 'GreenStraight', 'GreenStraightRight',\n",
    "             'GreenStraightLeft', 'RedStraight', 'GreenRight', 'Green', 'Yellow', 'RedRight', 'Red']\n",
    "\n",
    "dataset = TrafficLightDataset(img_dir, labels_dir, classes)\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=16, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "data_list = list(train_data)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 288, 512])\n"
     ]
    }
   ],
   "source": [
    "print(data_list[2][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trafficLightDetectionModel(num_classes=len(classes)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexlin/.local/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]Epoch: [0][10/5093]\tLoss_sum:  1.157192( 3.612841)\tCls:  0.086427( 1.502535)\tBox:  0.006731( 0.001734)\tObj:  0.608177( 0.677314)\tRPN  0.455856( 1.431258)\n",
      "[Train]Epoch: [0][20/5093]\tLoss_sum:  0.993073( 2.549130)\tCls:  0.214922( 0.841104)\tBox:  0.015407( 0.005028)\tObj:  0.699233( 0.634882)\tRPN  0.063512( 1.068116)\n",
      "[Train]Epoch: [0][30/5093]\tLoss_sum:  0.789345( 1.978990)\tCls:  0.100664( 0.585539)\tBox:  0.031837( 0.006146)\tObj:  0.581751( 0.649352)\tRPN  0.075093( 0.737953)\n",
      "[Train]Epoch: [0][40/5093]\tLoss_sum:  2.601005( 1.790591)\tCls:  0.003736( 0.458502)\tBox:  0.000000( 0.007925)\tObj:  0.621233( 0.615667)\tRPN  1.976035( 0.708497)\n",
      "[Train]Epoch: [0][50/5093]\tLoss_sum:  1.040406( 1.778031)\tCls:  0.002560( 0.367213)\tBox:  0.000000( 0.006340)\tObj:  0.541960( 0.617752)\tRPN  0.495886( 0.786726)\n",
      "[Train]Epoch: [0][60/5093]\tLoss_sum:  0.796837( 1.643425)\tCls:  0.002155( 0.306102)\tBox:  0.000000( 0.005283)\tObj:  0.531878( 0.607899)\tRPN  0.262804( 0.724141)\n",
      "[Train]Epoch: [0][70/5093]\tLoss_sum:  0.824285( 1.545384)\tCls:  0.000095( 0.262464)\tBox:  0.000000( 0.004528)\tObj:  0.438914( 0.590523)\tRPN  0.385276( 0.687868)\n",
      "[Train]Epoch: [0][80/5093]\tLoss_sum:  1.545722( 1.457487)\tCls:  0.000003( 0.229901)\tBox:  0.000000( 0.003962)\tObj:  0.184522( 0.558049)\tRPN  1.361198( 0.665575)\n",
      "[Train]Epoch: [0][90/5093]\tLoss_sum:  0.520448( 1.395576)\tCls:  0.000012( 0.204497)\tBox:  0.000000( 0.003522)\tObj:  0.062496( 0.513094)\tRPN  0.457940( 0.674462)\n",
      "[Train]Epoch: [0][100/5093]\tLoss_sum:  0.870452( 1.377834)\tCls:  0.120583( 0.192975)\tBox:  0.002050( 0.003341)\tObj:  0.569730( 0.530309)\tRPN  0.178089( 0.651209)\n",
      "[Train]Epoch: [0][110/5093]\tLoss_sum:  0.417816( 1.310315)\tCls:  0.056417( 0.183226)\tBox:  0.001323( 0.003544)\tObj:  0.284611( 0.520937)\tRPN  0.075465( 0.602608)\n",
      "[Train]Epoch: [0][120/5093]\tLoss_sum:  1.022692( 1.314701)\tCls:  0.000126( 0.170068)\tBox:  0.000000( 0.003606)\tObj:  0.553876( 0.521764)\tRPN  0.468690( 0.619263)\n",
      "[Train]Epoch: [0][130/5093]\tLoss_sum:  1.209843( 1.313395)\tCls:  0.061106( 0.158263)\tBox:  0.001527( 0.003354)\tObj:  0.515509( 0.520544)\tRPN  0.631702( 0.631234)\n",
      "[Train]Epoch: [0][140/5093]\tLoss_sum:  0.557399( 1.278003)\tCls:  0.044571( 0.151272)\tBox:  0.000794( 0.003227)\tObj:  0.479826( 0.520923)\tRPN  0.032208( 0.602582)\n",
      "[Train]Epoch: [0][150/5093]\tLoss_sum:  0.790391( 1.288009)\tCls:  0.000029( 0.141666)\tBox:  0.000000( 0.003017)\tObj:  0.417907( 0.519306)\tRPN  0.372455( 0.624021)\n",
      "[Train]Epoch: [0][160/5093]\tLoss_sum:  0.472692( 1.250190)\tCls:  0.000152( 0.132815)\tBox:  0.000000( 0.002828)\tObj:  0.184568( 0.506856)\tRPN  0.287973( 0.607691)\n",
      "[Train]Epoch: [0][170/5093]\tLoss_sum:  0.445485( 1.198642)\tCls:  0.000079( 0.125016)\tBox:  0.000000( 0.002662)\tObj:  0.040443( 0.484001)\tRPN  0.404963( 0.586964)\n",
      "[Train]Epoch: [0][180/5093]\tLoss_sum:  0.705355( 1.164223)\tCls:  0.000008( 0.118095)\tBox:  0.000000( 0.002514)\tObj:  0.099011( 0.461311)\tRPN  0.606336( 0.582304)\n",
      "[Train]Epoch: [0][190/5093]\tLoss_sum:  0.262785( 1.120492)\tCls:  0.000130( 0.111887)\tBox:  0.000000( 0.002381)\tObj:  0.080785( 0.441591)\tRPN  0.181870( 0.564632)\n",
      "[Train]Epoch: [0][200/5093]\tLoss_sum:  1.140980( 1.127583)\tCls:  0.052686( 0.107411)\tBox:  0.001504( 0.002286)\tObj:  0.523321( 0.446758)\tRPN  0.563470( 0.571128)\n",
      "[Train]Epoch: [0][210/5093]\tLoss_sum:  0.792831( 1.121809)\tCls:  0.155719( 0.106155)\tBox:  0.000265( 0.002222)\tObj:  0.555768( 0.450085)\tRPN  0.081079( 0.563346)\n",
      "[Train]Epoch: [0][220/5093]\tLoss_sum:  1.837307( 1.135577)\tCls:  0.000876( 0.103435)\tBox:  0.000000( 0.002126)\tObj:  0.335513( 0.451599)\tRPN  1.500917( 0.578417)\n",
      "[Train]Epoch: [0][230/5093]\tLoss_sum:  0.779525( 1.132051)\tCls:  0.000000( 0.098939)\tBox:  0.000000( 0.002033)\tObj:  0.238306( 0.442635)\tRPN  0.541219( 0.588444)\n",
      "[Train]Epoch: [0][240/5093]\tLoss_sum:  0.698055( 1.118299)\tCls:  0.071734( 0.096535)\tBox:  0.000841( 0.001974)\tObj:  0.318583( 0.437926)\tRPN  0.306898( 0.581865)\n",
      "[Train]Epoch: [0][250/5093]\tLoss_sum:  0.690878( 1.110001)\tCls:  0.066521( 0.095627)\tBox:  0.000392( 0.001953)\tObj:  0.322366( 0.435495)\tRPN  0.301599( 0.576927)\n",
      "[Train]Epoch: [0][260/5093]\tLoss_sum:  0.906311( 1.100310)\tCls:  0.076565( 0.094353)\tBox:  0.007376( 0.001941)\tObj:  0.297815( 0.432545)\tRPN  0.524555( 0.571471)\n",
      "[Train]Epoch: [0][270/5093]\tLoss_sum:  0.807477( 1.088747)\tCls:  0.103071( 0.093080)\tBox:  0.025194( 0.002039)\tObj:  0.422443( 0.431694)\tRPN  0.256769( 0.561934)\n",
      "[Train]Epoch: [0][280/5093]\tLoss_sum:  0.448865( 1.071386)\tCls:  0.101737( 0.092581)\tBox:  0.030338( 0.002188)\tObj:  0.236570( 0.427600)\tRPN  0.080220( 0.549016)\n",
      "[Train]Epoch: [0][290/5093]\tLoss_sum:  0.867936( 1.080816)\tCls:  0.000103( 0.089596)\tBox:  0.000000( 0.002113)\tObj:  0.167105( 0.427465)\tRPN  0.700728( 0.561642)\n",
      "[Train]Epoch: [0][300/5093]\tLoss_sum:  0.271890( 1.059456)\tCls:  0.000897( 0.086626)\tBox:  0.000000( 0.002043)\tObj:  0.057738( 0.416841)\tRPN  0.213255( 0.553946)\n",
      "[Train]Epoch: [0][310/5093]\tLoss_sum:  0.994740( 1.070570)\tCls:  0.040506( 0.085097)\tBox:  0.000555( 0.001989)\tObj:  0.753101( 0.423361)\tRPN  0.200578( 0.560124)\n",
      "[Train]Epoch: [0][320/5093]\tLoss_sum:  0.645384( 1.066932)\tCls:  0.000830( 0.082693)\tBox:  0.000000( 0.001927)\tObj:  0.336410( 0.423168)\tRPN  0.308144( 0.559144)\n",
      "[Train]Epoch: [0][330/5093]\tLoss_sum:  0.669441( 1.055527)\tCls:  0.000262( 0.080241)\tBox:  0.000000( 0.001869)\tObj:  0.290087( 0.419823)\tRPN  0.379092( 0.553594)\n",
      "[Train]Epoch: [0][340/5093]\tLoss_sum:  1.188932( 1.054863)\tCls:  0.072723( 0.078731)\tBox:  0.000467( 0.001832)\tObj:  0.319102( 0.418369)\tRPN  0.796640( 0.555931)\n",
      "[Train]Epoch: [0][350/5093]\tLoss_sum:  0.322777( 1.041180)\tCls:  0.057184( 0.077849)\tBox:  0.000239( 0.001785)\tObj:  0.201454( 0.415239)\tRPN  0.063901( 0.546307)\n",
      "[Train]Epoch: [0][360/5093]\tLoss_sum:  1.122149( 1.027243)\tCls:  0.002694( 0.077764)\tBox:  0.000000( 0.001985)\tObj:  0.272192( 0.409413)\tRPN  0.847263( 0.538081)\n",
      "[Train]Epoch: [0][370/5093]\tLoss_sum:  1.012691( 1.024022)\tCls:  0.000016( 0.076705)\tBox:  0.000000( 0.001943)\tObj:  0.268235( 0.405514)\tRPN  0.744440( 0.539860)\n",
      "[Train]Epoch: [0][380/5093]\tLoss_sum:  0.309019( 1.011946)\tCls:  0.048940( 0.076303)\tBox:  0.000143( 0.001933)\tObj:  0.146958( 0.401594)\tRPN  0.112978( 0.532115)\n",
      "[Train]Epoch: [0][390/5093]\tLoss_sum:  0.568738( 1.011324)\tCls:  0.057606( 0.075661)\tBox:  0.006242( 0.001904)\tObj:  0.433243( 0.405512)\tRPN  0.071647( 0.528248)\n",
      "[Train]Epoch: [0][400/5093]\tLoss_sum:  0.995721( 1.016307)\tCls:  0.034216( 0.074169)\tBox:  0.000080( 0.001857)\tObj:  0.398890( 0.405823)\tRPN  0.562534( 0.534457)\n",
      "[Train]Epoch: [0][410/5093]\tLoss_sum:  0.686722( 1.011765)\tCls:  0.055727( 0.073436)\tBox:  0.000696( 0.001865)\tObj:  0.247584( 0.404663)\tRPN  0.382716( 0.531801)\n",
      "[Train]Epoch: [0][420/5093]\tLoss_sum:  0.658567( 1.003578)\tCls:  0.110254( 0.074041)\tBox:  0.030734( 0.002350)\tObj:  0.242111( 0.400544)\tRPN  0.275468( 0.526643)\n",
      "[Train]Epoch: [0][430/5093]\tLoss_sum:  0.527605( 0.995994)\tCls:  0.036019( 0.074450)\tBox:  0.000247( 0.002519)\tObj:  0.247908( 0.396095)\tRPN  0.243431( 0.522930)\n",
      "[Train]Epoch: [0][440/5093]\tLoss_sum:  0.541708( 0.984362)\tCls:  0.114052( 0.074059)\tBox:  0.032523( 0.002770)\tObj:  0.167168( 0.390132)\tRPN  0.227966( 0.517401)\n",
      "[Train]Epoch: [0][450/5093]\tLoss_sum:  0.264081( 0.971926)\tCls:  0.097853( 0.074118)\tBox:  0.039801( 0.003157)\tObj:  0.093095( 0.384209)\tRPN  0.033331( 0.510443)\n",
      "[Train]Epoch: [0][460/5093]\tLoss_sum:  0.247052( 0.961704)\tCls:  0.078134( 0.073505)\tBox:  0.018230( 0.003317)\tObj:  0.077832( 0.378680)\tRPN  0.072856( 0.506202)\n",
      "[Train]Epoch: [0][470/5093]\tLoss_sum:  0.133527( 0.945952)\tCls:  0.031890( 0.073120)\tBox:  0.007428( 0.003648)\tObj:  0.061094( 0.372367)\tRPN  0.033114( 0.496818)\n",
      "[Train]Epoch: [0][480/5093]\tLoss_sum:  0.283897( 0.935667)\tCls:  0.026684( 0.072127)\tBox:  0.004936( 0.003670)\tObj:  0.109350( 0.368337)\tRPN  0.142926( 0.491533)\n",
      "[Train]Epoch: [0][490/5093]\tLoss_sum:  0.929709( 0.926238)\tCls:  0.001642( 0.071144)\tBox:  0.000000( 0.003640)\tObj:  0.071800( 0.364385)\tRPN  0.856266( 0.487070)\n",
      "[Train]Epoch: [0][500/5093]\tLoss_sum:  0.724325( 0.920623)\tCls:  0.057672( 0.070771)\tBox:  0.004929( 0.003764)\tObj:  0.135422( 0.358946)\tRPN  0.526302( 0.487142)\n",
      "[Train]Epoch: [0][510/5093]\tLoss_sum:  0.682524( 0.914945)\tCls:  0.182963( 0.071710)\tBox:  0.098602( 0.004525)\tObj:  0.174093( 0.354699)\tRPN  0.226865( 0.484011)\n",
      "[Train]Epoch: [0][520/5093]\tLoss_sum:  0.669647( 0.907878)\tCls:  0.003267( 0.071676)\tBox:  0.000000( 0.005080)\tObj:  0.100650( 0.351047)\tRPN  0.565730( 0.480074)\n",
      "[Train]Epoch: [0][530/5093]\tLoss_sum:  0.296979( 0.897571)\tCls:  0.000142( 0.070344)\tBox:  0.000000( 0.004984)\tObj:  0.026414( 0.344855)\tRPN  0.270423( 0.477388)\n",
      "[Train]Epoch: [0][540/5093]\tLoss_sum:  0.082638( 0.884347)\tCls:  0.000284( 0.069046)\tBox:  0.000000( 0.004892)\tObj:  0.012762( 0.338962)\tRPN  0.069592( 0.471446)\n",
      "[Train]Epoch: [0][550/5093]\tLoss_sum:  0.865403( 0.878054)\tCls:  0.025498( 0.068476)\tBox:  0.000263( 0.004816)\tObj:  0.366961( 0.336395)\tRPN  0.472681( 0.468366)\n",
      "[Train]Epoch: [0][560/5093]\tLoss_sum:  0.454851( 0.875380)\tCls:  0.010427( 0.067841)\tBox:  0.000000( 0.004799)\tObj:  0.208491( 0.335188)\tRPN  0.235932( 0.467553)\n",
      "[Train]Epoch: [0][570/5093]\tLoss_sum:  0.162713( 0.865461)\tCls:  0.008753( 0.066837)\tBox:  0.000000( 0.004715)\tObj:  0.056601( 0.331089)\tRPN  0.097359( 0.462820)\n",
      "[Train]Epoch: [0][580/5093]\tLoss_sum:  1.267960( 0.858111)\tCls:  0.109604( 0.066035)\tBox:  0.018254( 0.004666)\tObj:  0.766126( 0.330150)\tRPN  0.373976( 0.457260)\n",
      "[Train]Epoch: [0][590/5093]\tLoss_sum:  0.543884( 0.852272)\tCls:  0.002316( 0.066083)\tBox:  0.000000( 0.004759)\tObj:  0.151025( 0.329054)\tRPN  0.390543( 0.452377)\n",
      "[Train]Epoch: [0][600/5093]\tLoss_sum:  0.183784( 0.847097)\tCls:  0.003700( 0.065920)\tBox:  0.000000( 0.005166)\tObj:  0.032204( 0.326617)\tRPN  0.147880( 0.449394)\n",
      "[Train]Epoch: [0][610/5093]\tLoss_sum:  0.137024( 0.836939)\tCls:  0.001054( 0.064871)\tBox:  0.000000( 0.005082)\tObj:  0.029324( 0.321882)\tRPN  0.106645( 0.445105)\n",
      "[Train]Epoch: [0][620/5093]\tLoss_sum:  0.787755( 0.831301)\tCls:  0.070193( 0.064509)\tBox:  0.017597( 0.005279)\tObj:  0.209946( 0.319285)\tRPN  0.490020( 0.442228)\n",
      "[Train]Epoch: [0][630/5093]\tLoss_sum:  0.598831( 0.829372)\tCls:  0.108491( 0.064782)\tBox:  0.036915( 0.005604)\tObj:  0.174854( 0.316655)\tRPN  0.278571( 0.442331)\n",
      "[Train]Epoch: [0][640/5093]\tLoss_sum:  0.318522( 0.821704)\tCls:  0.003940( 0.064391)\tBox:  0.000000( 0.005689)\tObj:  0.034811( 0.313071)\tRPN  0.279771( 0.438553)\n",
      "[Train]Epoch: [0][650/5093]\tLoss_sum:  0.608644( 0.818663)\tCls:  0.144109( 0.064082)\tBox:  0.029495( 0.005783)\tObj:  0.064632( 0.311042)\tRPN  0.370407( 0.437755)\n",
      "[Train]Epoch: [0][660/5093]\tLoss_sum:  0.333846( 0.814809)\tCls:  0.060838( 0.064660)\tBox:  0.017382( 0.006221)\tObj:  0.188415( 0.309524)\tRPN  0.067211( 0.434404)\n",
      "[Train]Epoch: [0][670/5093]\tLoss_sum:  1.707399( 0.812211)\tCls:  0.013069( 0.064924)\tBox:  0.000000( 0.006614)\tObj:  0.632339( 0.308326)\tRPN  1.061990( 0.432348)\n",
      "[Train]Epoch: [0][680/5093]\tLoss_sum:  0.723776( 0.813481)\tCls:  0.002255( 0.064545)\tBox:  0.000000( 0.006687)\tObj:  0.156753( 0.307639)\tRPN  0.564767( 0.434609)\n",
      "[Train]Epoch: [0][690/5093]\tLoss_sum:  0.309468( 0.810750)\tCls:  0.023527( 0.064308)\tBox:  0.000084( 0.006672)\tObj:  0.252115( 0.306115)\tRPN  0.033742( 0.433654)\n",
      "[Train]Epoch: [0][700/5093]\tLoss_sum:  0.647258( 0.809315)\tCls:  0.099432( 0.063899)\tBox:  0.046888( 0.006655)\tObj:  0.091893( 0.303758)\tRPN  0.409046( 0.435003)\n",
      "[Train]Epoch: [0][710/5093]\tLoss_sum:  0.241941( 0.804554)\tCls:  0.037801( 0.064201)\tBox:  0.000180( 0.007071)\tObj:  0.108389( 0.301097)\tRPN  0.095571( 0.432185)\n",
      "[Train]Epoch: [0][720/5093]\tLoss_sum:  0.606072( 0.800479)\tCls:  0.001438( 0.064435)\tBox:  0.000000( 0.007306)\tObj:  0.245252( 0.299394)\tRPN  0.359383( 0.429343)\n",
      "[Train]Epoch: [0][730/5093]\tLoss_sum:  0.537938( 0.799159)\tCls:  0.173982( 0.064975)\tBox:  0.060819( 0.007665)\tObj:  0.178004( 0.297353)\tRPN  0.125133( 0.429166)\n",
      "[Train]Epoch: [0][740/5093]\tLoss_sum:  0.932516( 0.796038)\tCls:  0.156656( 0.065157)\tBox:  0.077734( 0.007951)\tObj:  0.105186( 0.294766)\tRPN  0.592940( 0.428164)\n",
      "[Train]Epoch: [0][750/5093]\tLoss_sum:  0.982685( 0.791424)\tCls:  0.002819( 0.065503)\tBox:  0.000000( 0.008263)\tObj:  0.157982( 0.292231)\tRPN  0.821884( 0.425427)\n",
      "[Train]Epoch: [0][760/5093]\tLoss_sum:  0.166193( 0.784992)\tCls:  0.002965( 0.064671)\tBox:  0.000000( 0.008154)\tObj:  0.056597( 0.289518)\tRPN  0.106630( 0.422649)\n",
      "[Train]Epoch: [0][770/5093]\tLoss_sum:  0.290695( 0.777795)\tCls:  0.000737( 0.063844)\tBox:  0.000000( 0.008048)\tObj:  0.052131( 0.286666)\tRPN  0.237827( 0.419238)\n",
      "[Train]Epoch: [0][780/5093]\tLoss_sum:  0.263819( 0.770494)\tCls:  0.000173( 0.063031)\tBox:  0.000000( 0.007945)\tObj:  0.005538( 0.283125)\tRPN  0.258108( 0.416393)\n",
      "[Train]Epoch: [0][790/5093]\tLoss_sum:  0.693471( 0.766040)\tCls:  0.076444( 0.062609)\tBox:  0.007966( 0.007897)\tObj:  0.225650( 0.281677)\tRPN  0.383410( 0.413857)\n",
      "[Train]Epoch: [0][800/5093]\tLoss_sum:  0.364024( 0.761186)\tCls:  0.008567( 0.061956)\tBox:  0.000000( 0.007798)\tObj:  0.072967( 0.279292)\tRPN  0.282490( 0.412139)\n",
      "[Train]Epoch: [0][810/5093]\tLoss_sum:  0.924018( 0.759020)\tCls:  0.232646( 0.062231)\tBox:  0.130030( 0.008184)\tObj:  0.105260( 0.276943)\tRPN  0.456083( 0.411662)\n",
      "[Train]Epoch: [0][820/5093]\tLoss_sum:  0.236568( 0.755990)\tCls:  0.004632( 0.063089)\tBox:  0.000000( 0.009016)\tObj:  0.024061( 0.274548)\tRPN  0.207875( 0.409336)\n",
      "[Train]Epoch: [0][830/5093]\tLoss_sum:  0.117698( 0.749064)\tCls:  0.001231( 0.062379)\tBox:  0.000000( 0.008908)\tObj:  0.015545( 0.271516)\tRPN  0.100922( 0.406261)\n",
      "[Train]Epoch: [0][840/5093]\tLoss_sum:  0.196737( 0.742266)\tCls:  0.001358( 0.061661)\tBox:  0.000000( 0.008802)\tObj:  0.022062( 0.268516)\tRPN  0.173317( 0.403287)\n",
      "[Train]Epoch: [0][850/5093]\tLoss_sum:  0.040511( 0.734568)\tCls:  0.000263( 0.060940)\tBox:  0.000000( 0.008698)\tObj:  0.007446( 0.265477)\tRPN  0.032802( 0.399453)\n",
      "[Train]Epoch: [0][860/5093]\tLoss_sum:  0.035833( 0.726761)\tCls:  0.000184( 0.060239)\tBox:  0.000000( 0.008597)\tObj:  0.008071( 0.262510)\tRPN  0.027579( 0.395415)\n",
      "[Train]Epoch: [0][870/5093]\tLoss_sum:  0.030102( 0.719815)\tCls:  0.000238( 0.059548)\tBox:  0.000000( 0.008498)\tObj:  0.008279( 0.259592)\tRPN  0.021584( 0.392177)\n",
      "[Train]Epoch: [0][880/5093]\tLoss_sum:  0.207392( 0.713865)\tCls:  0.000142( 0.058902)\tBox:  0.000000( 0.008402)\tObj:  0.006074( 0.257044)\tRPN  0.201176( 0.389516)\n",
      "[Train]Epoch: [0][890/5093]\tLoss_sum:  0.826553( 0.711388)\tCls:  0.092787( 0.059413)\tBox:  0.039484( 0.008851)\tObj:  0.115070( 0.255954)\tRPN  0.579212( 0.387170)\n",
      "[Train]Epoch: [0][900/5093]\tLoss_sum:  0.169947( 0.707069)\tCls:  0.003608( 0.059222)\tBox:  0.000000( 0.009007)\tObj:  0.113444( 0.254730)\tRPN  0.052896( 0.384110)\n",
      "[Train]Epoch: [0][910/5093]\tLoss_sum:  0.453934( 0.704555)\tCls:  0.154197( 0.059379)\tBox:  0.082728( 0.009275)\tObj:  0.061647( 0.252587)\tRPN  0.155362( 0.383315)\n",
      "[Train]Epoch: [0][920/5093]\tLoss_sum:  0.268205( 0.702054)\tCls:  0.099545( 0.059327)\tBox:  0.032577( 0.009416)\tObj:  0.049723( 0.250673)\tRPN  0.086360( 0.382638)\n",
      "[Train]Epoch: [0][930/5093]\tLoss_sum:  0.159073( 0.699105)\tCls:  0.006443( 0.058908)\tBox:  0.000000( 0.009369)\tObj:  0.038321( 0.249147)\tRPN  0.114308( 0.381681)\n",
      "[Train]Epoch: [0][940/5093]\tLoss_sum:  0.416806( 0.695851)\tCls:  0.101029( 0.059018)\tBox:  0.059386( 0.009592)\tObj:  0.152515( 0.247657)\tRPN  0.103877( 0.379585)\n",
      "[Train]Epoch: [0][950/5093]\tLoss_sum:  0.546161( 0.694084)\tCls:  0.208734( 0.059381)\tBox:  0.164594( 0.009921)\tObj:  0.086255( 0.245896)\tRPN  0.086579( 0.378886)\n",
      "[Train]Epoch: [0][960/5093]\tLoss_sum:  0.344935( 0.692944)\tCls:  0.085565( 0.060167)\tBox:  0.054668( 0.010666)\tObj:  0.077067( 0.244178)\tRPN  0.127635( 0.377933)\n",
      "[Train]Epoch: [0][970/5093]\tLoss_sum:  0.227810( 0.689321)\tCls:  0.005757( 0.060008)\tBox:  0.000000( 0.010813)\tObj:  0.028244( 0.242053)\tRPN  0.193809( 0.376447)\n",
      "[Train]Epoch: [0][980/5093]\tLoss_sum:  0.582867( 0.686881)\tCls:  0.012907( 0.060166)\tBox:  0.000000( 0.011060)\tObj:  0.058640( 0.240888)\tRPN  0.511320( 0.374768)\n",
      "[Train]Epoch: [0][990/5093]\tLoss_sum:  0.318803( 0.683960)\tCls:  0.024664( 0.060052)\tBox:  0.000047( 0.011141)\tObj:  0.065971( 0.239614)\tRPN  0.228120( 0.373153)\n",
      "[Train]Epoch: [0][1000/5093]\tLoss_sum:  0.672495( 0.682169)\tCls:  0.115847( 0.060527)\tBox:  0.080582( 0.011707)\tObj:  0.115959( 0.238009)\tRPN  0.360108( 0.371927)\n",
      "[Train]Epoch: [0][1010/5093]\tLoss_sum:  0.240489( 0.681711)\tCls:  0.009667( 0.060677)\tBox:  0.000000( 0.011997)\tObj:  0.020557( 0.236108)\tRPN  0.210266( 0.372930)\n",
      "[Train]Epoch: [0][1020/5093]\tLoss_sum:  0.221482( 0.681034)\tCls:  0.079786( 0.061705)\tBox:  0.018679( 0.012806)\tObj:  0.085493( 0.234873)\tRPN  0.037524( 0.371650)\n",
      "[Train]Epoch: [0][1030/5093]\tLoss_sum:  0.773335( 0.685073)\tCls:  0.079489( 0.061771)\tBox:  0.026650( 0.012979)\tObj:  0.053655( 0.233627)\tRPN  0.613541( 0.376696)\n",
      "[Train]Epoch: [0][1040/5093]\tLoss_sum:  0.697590( 0.683674)\tCls:  0.125188( 0.062360)\tBox:  0.066728( 0.013412)\tObj:  0.145408( 0.232175)\tRPN  0.360266( 0.375727)\n",
      "[Train]Epoch: [0][1050/5093]\tLoss_sum:  0.402993( 0.682972)\tCls:  0.001874( 0.062375)\tBox:  0.000000( 0.013784)\tObj:  0.005148( 0.230293)\tRPN  0.395971( 0.376519)\n",
      "[Train]Epoch: [0][1060/5093]\tLoss_sum:  0.198052( 0.679056)\tCls:  0.001188( 0.061802)\tBox:  0.000000( 0.013654)\tObj:  0.005290( 0.228207)\tRPN  0.191574( 0.375393)\n",
      "[Train]Epoch: [0][1070/5093]\tLoss_sum:  0.193590( 0.674926)\tCls:  0.066920( 0.061606)\tBox:  0.022066( 0.013605)\tObj:  0.036894( 0.226787)\tRPN  0.067711( 0.372927)\n",
      "[Train]Epoch: [0][1080/5093]\tLoss_sum:  0.784938( 0.673074)\tCls:  0.070532( 0.061294)\tBox:  0.009711( 0.013546)\tObj:  0.191199( 0.225148)\tRPN  0.513496( 0.373087)\n",
      "[Train]Epoch: [0][1090/5093]\tLoss_sum:  0.254682( 0.671408)\tCls:  0.006034( 0.061183)\tBox:  0.000000( 0.013519)\tObj:  0.080734( 0.224117)\tRPN  0.167914( 0.372588)\n",
      "[Train]Epoch: [0][1100/5093]\tLoss_sum:  0.750701( 0.668230)\tCls:  0.126565( 0.061002)\tBox:  0.055857( 0.013516)\tObj:  0.121553( 0.222734)\tRPN  0.446726( 0.370978)\n",
      "[Train]Epoch: [0][1110/5093]\tLoss_sum:  0.328377( 0.665189)\tCls:  0.002718( 0.060940)\tBox:  0.000000( 0.013706)\tObj:  0.027856( 0.221233)\tRPN  0.297803( 0.369310)\n",
      "[Train]Epoch: [0][1120/5093]\tLoss_sum:  0.343843( 0.663306)\tCls:  0.074000( 0.061016)\tBox:  0.031163( 0.013878)\tObj:  0.074993( 0.220272)\tRPN  0.163688( 0.368140)\n",
      "[Train]Epoch: [0][1130/5093]\tLoss_sum:  0.343003( 0.661359)\tCls:  0.005087( 0.061031)\tBox:  0.000000( 0.014022)\tObj:  0.035084( 0.219092)\tRPN  0.302833( 0.367215)\n",
      "[Train]Epoch: [0][1140/5093]\tLoss_sum:  0.165631( 0.657534)\tCls:  0.007403( 0.060547)\tBox:  0.000000( 0.013899)\tObj:  0.008074( 0.217449)\tRPN  0.150155( 0.365639)\n",
      "[Train]Epoch: [0][1150/5093]\tLoss_sum:  0.065197( 0.654100)\tCls:  0.001315( 0.060492)\tBox:  0.000000( 0.014093)\tObj:  0.011069( 0.216034)\tRPN  0.052813( 0.363480)\n",
      "[Train]Epoch: [0][1160/5093]\tLoss_sum:  0.637957( 0.649642)\tCls:  0.043946( 0.060045)\tBox:  0.000148( 0.013972)\tObj:  0.088617( 0.214367)\tRPN  0.505247( 0.361259)\n",
      "[Train]Epoch: [0][1170/5093]\tLoss_sum:  0.250154( 0.647403)\tCls:  0.027228( 0.059847)\tBox:  0.004402( 0.013984)\tObj:  0.095293( 0.213526)\tRPN  0.123231( 0.360046)\n",
      "[Train]Epoch: [0][1180/5093]\tLoss_sum:  0.641865( 0.646495)\tCls:  0.170049( 0.059918)\tBox:  0.053434( 0.014112)\tObj:  0.092284( 0.212382)\tRPN  0.326098( 0.360083)\n",
      "[Train]Epoch: [0][1190/5093]\tLoss_sum:  0.289025( 0.643762)\tCls:  0.002132( 0.059597)\tBox:  0.000000( 0.014070)\tObj:  0.028112( 0.211126)\tRPN  0.258780( 0.358970)\n",
      "[Train]Epoch: [0][1200/5093]\tLoss_sum:  0.879872( 0.641497)\tCls:  0.206915( 0.059635)\tBox:  0.146247( 0.014242)\tObj:  0.358205( 0.210071)\tRPN  0.168506( 0.357549)\n",
      "[Train]Epoch: [0][1210/5093]\tLoss_sum:  0.274912( 0.640500)\tCls:  0.005155( 0.059887)\tBox:  0.000000( 0.014725)\tObj:  0.034168( 0.209051)\tRPN  0.235589( 0.356837)\n",
      "[Train]Epoch: [0][1220/5093]\tLoss_sum:  0.068332( 0.638344)\tCls:  0.002982( 0.059551)\tBox:  0.000000( 0.014646)\tObj:  0.023096( 0.208090)\tRPN  0.042254( 0.356056)\n",
      "[Train]Epoch: [0][1230/5093]\tLoss_sum:  0.308348( 0.636810)\tCls:  0.105666( 0.059700)\tBox:  0.076980( 0.014963)\tObj:  0.064764( 0.207225)\tRPN  0.060938( 0.354923)\n",
      "[Train]Epoch: [0][1240/5093]\tLoss_sum:  0.158583( 0.634164)\tCls:  0.005049( 0.059975)\tBox:  0.000000( 0.015342)\tObj:  0.017777( 0.205957)\tRPN  0.135757( 0.352890)\n",
      "[Train]Epoch: [0][1250/5093]\tLoss_sum:  0.054344( 0.630155)\tCls:  0.001917( 0.059520)\tBox:  0.000000( 0.015220)\tObj:  0.019462( 0.204475)\tRPN  0.032965( 0.350940)\n",
      "[Train]Epoch: [0][1260/5093]\tLoss_sum:  0.092112( 0.627394)\tCls:  0.001646( 0.059487)\tBox:  0.000000( 0.015414)\tObj:  0.006661( 0.203282)\tRPN  0.083805( 0.349211)\n",
      "[Train]Epoch: [0][1270/5093]\tLoss_sum:  0.443606( 0.625414)\tCls:  0.126589( 0.059685)\tBox:  0.088855( 0.015733)\tObj:  0.121014( 0.202113)\tRPN  0.107148( 0.347883)\n",
      "[Train]Epoch: [0][1280/5093]\tLoss_sum:  0.247808( 0.622524)\tCls:  0.009274( 0.059497)\tBox:  0.000000( 0.015767)\tObj:  0.010594( 0.200707)\tRPN  0.227940( 0.346554)\n",
      "[Train]Epoch: [0][1290/5093]\tLoss_sum:  0.512512( 0.620662)\tCls:  0.055306( 0.059613)\tBox:  0.022007( 0.015997)\tObj:  0.079298( 0.199710)\tRPN  0.355901( 0.345341)\n",
      "[Train]Epoch: [0][1300/5093]\tLoss_sum:  0.883428( 0.620517)\tCls:  0.004684( 0.059798)\tBox:  0.000000( 0.016295)\tObj:  0.032621( 0.198673)\tRPN  0.846123( 0.345751)\n",
      "[Train]Epoch: [0][1310/5093]\tLoss_sum:  1.311181( 0.622515)\tCls:  0.046522( 0.059626)\tBox:  0.000449( 0.016172)\tObj:  0.265380( 0.198299)\tRPN  0.998830( 0.348418)\n",
      "[Train]Epoch: [0][1320/5093]\tLoss_sum:  0.507368( 0.623621)\tCls:  0.044876( 0.060214)\tBox:  0.038802( 0.016618)\tObj:  0.093667( 0.198517)\tRPN  0.330023( 0.348272)\n",
      "[Train]Epoch: [0][1330/5093]\tLoss_sum:  0.609318( 0.623017)\tCls:  0.194898( 0.060566)\tBox:  0.139837( 0.017146)\tObj:  0.061135( 0.198417)\tRPN  0.213447( 0.346887)\n",
      "[Train]Epoch: [0][1340/5093]\tLoss_sum:  0.607948( 0.623256)\tCls:  0.226949( 0.061261)\tBox:  0.203420( 0.017925)\tObj:  0.099139( 0.197947)\tRPN  0.078441( 0.346123)\n",
      "[Train]Epoch: [0][1350/5093]\tLoss_sum:  0.652451( 0.622852)\tCls:  0.118594( 0.061415)\tBox:  0.041749( 0.018046)\tObj:  0.063486( 0.196912)\tRPN  0.428622( 0.346479)\n",
      "[Train]Epoch: [0][1360/5093]\tLoss_sum:  0.326509( 0.622634)\tCls:  0.044794( 0.062213)\tBox:  0.000000( 0.018802)\tObj:  0.073660( 0.196240)\tRPN  0.208055( 0.345378)\n",
      "[Train]Epoch: [0][1370/5093]\tLoss_sum:  0.108825( 0.621437)\tCls:  0.001358( 0.062392)\tBox:  0.000000( 0.019204)\tObj:  0.038564( 0.195357)\tRPN  0.068903( 0.344485)\n",
      "[Train]Epoch: [0][1380/5093]\tLoss_sum:  0.667301( 0.620131)\tCls:  0.237089( 0.062618)\tBox:  0.160452( 0.019323)\tObj:  0.021141( 0.194288)\tRPN  0.248620( 0.343902)\n",
      "[Train]Epoch: [0][1390/5093]\tLoss_sum:  0.483357( 0.619415)\tCls:  0.186969( 0.063654)\tBox:  0.197327( 0.020523)\tObj:  0.067834( 0.193217)\tRPN  0.031227( 0.342020)\n",
      "[Train]Epoch: [0][1400/5093]\tLoss_sum:  0.560376( 0.620815)\tCls:  0.072867( 0.063487)\tBox:  0.068063( 0.020544)\tObj:  0.133575( 0.192372)\tRPN  0.285872( 0.344412)\n",
      "[Train]Epoch: [0][1410/5093]\tLoss_sum:  0.192611( 0.618196)\tCls:  0.002624( 0.063236)\tBox:  0.000000( 0.020493)\tObj:  0.035215( 0.191529)\tRPN  0.154771( 0.342937)\n",
      "[Train]Epoch: [0][1420/5093]\tLoss_sum:  0.457268( 0.616780)\tCls:  0.127758( 0.063337)\tBox:  0.097328( 0.020665)\tObj:  0.114080( 0.190696)\tRPN  0.118101( 0.342083)\n",
      "[Train]Epoch: [0][1430/5093]\tLoss_sum:  0.665638( 0.616460)\tCls:  0.072730( 0.063533)\tBox:  0.011123( 0.020881)\tObj:  0.049288( 0.189805)\tRPN  0.532497( 0.342241)\n",
      "[Train]Epoch: [0][1440/5093]\tLoss_sum:  0.753910( 0.615328)\tCls:  0.043689( 0.064119)\tBox:  0.000223( 0.021584)\tObj:  0.025954( 0.188827)\tRPN  0.684043( 0.340799)\n",
      "[Train]Epoch: [0][1450/5093]\tLoss_sum:  0.613974( 0.615814)\tCls:  0.147891( 0.064752)\tBox:  0.097545( 0.022379)\tObj:  0.042264( 0.187859)\tRPN  0.326274( 0.340823)\n",
      "[Train]Epoch: [0][1460/5093]\tLoss_sum:  0.205830( 0.614369)\tCls:  0.005570( 0.064867)\tBox:  0.000000( 0.022705)\tObj:  0.033854( 0.186921)\tRPN  0.166406( 0.339876)\n",
      "[Train]Epoch: [0][1470/5093]\tLoss_sum:  0.626060( 0.614758)\tCls:  0.060979( 0.064707)\tBox:  0.001596( 0.022599)\tObj:  0.065035( 0.185873)\tRPN  0.498449( 0.341579)\n",
      "[Train]Epoch: [0][1480/5093]\tLoss_sum:  0.166613( 0.612831)\tCls:  0.003830( 0.064658)\tBox:  0.000000( 0.022587)\tObj:  0.006176( 0.184907)\tRPN  0.156607( 0.340678)\n",
      "[Train]Epoch: [0][1490/5093]\tLoss_sum:  0.458146( 0.613396)\tCls:  0.125220( 0.064953)\tBox:  0.096938( 0.022884)\tObj:  0.060666( 0.184603)\tRPN  0.175322( 0.340955)\n",
      "[Train]Epoch: [0][1500/5093]\tLoss_sum:  0.451849( 0.613108)\tCls:  0.112357( 0.065180)\tBox:  0.088684( 0.023223)\tObj:  0.069608( 0.184020)\tRPN  0.181200( 0.340685)\n",
      "[Train]Epoch: [0][1510/5093]\tLoss_sum:  0.543163( 0.611505)\tCls:  0.063571( 0.065110)\tBox:  0.039136( 0.023224)\tObj:  0.148031( 0.183253)\tRPN  0.292425( 0.339919)\n",
      "[Train]Epoch: [0][1520/5093]\tLoss_sum:  0.239698( 0.610259)\tCls:  0.014731( 0.065156)\tBox:  0.000000( 0.023358)\tObj:  0.120935( 0.183107)\tRPN  0.104031( 0.338638)\n",
      "[Train]Epoch: [0][1530/5093]\tLoss_sum:  0.507284( 0.610162)\tCls:  0.089324( 0.065465)\tBox:  0.122583( 0.023564)\tObj:  0.117094( 0.182835)\tRPN  0.178283( 0.338299)\n",
      "[Train]Epoch: [0][1540/5093]\tLoss_sum:  0.471200( 0.608080)\tCls:  0.124984( 0.065327)\tBox:  0.095431( 0.023559)\tObj:  0.083087( 0.182120)\tRPN  0.167698( 0.337074)\n",
      "[Train]Epoch: [0][1550/5093]\tLoss_sum:  0.667204( 0.607648)\tCls:  0.011496( 0.065964)\tBox:  0.000000( 0.024286)\tObj:  0.033484( 0.181372)\tRPN  0.622225( 0.336027)\n",
      "[Train]Epoch: [0][1560/5093]\tLoss_sum:  0.911817( 0.606946)\tCls:  0.056595( 0.065636)\tBox:  0.000625( 0.024131)\tObj:  0.228861( 0.180555)\tRPN  0.625737( 0.336625)\n",
      "[Train]Epoch: [0][1570/5093]\tLoss_sum:  0.320332( 0.605976)\tCls:  0.078588( 0.066058)\tBox:  0.078487( 0.024702)\tObj:  0.128062( 0.179865)\tRPN  0.035195( 0.335350)\n",
      "[Train]Epoch: [0][1580/5093]\tLoss_sum:  0.252775( 0.604991)\tCls:  0.011122( 0.066204)\tBox:  0.000000( 0.025132)\tObj:  0.044879( 0.179120)\tRPN  0.196774( 0.334534)\n",
      "[Train]Epoch: [0][1590/5093]\tLoss_sum:  0.425399( 0.604257)\tCls:  0.128972( 0.066474)\tBox:  0.122447( 0.025551)\tObj:  0.060181( 0.178453)\tRPN  0.113799( 0.333779)\n",
      "[Train]Epoch: [0][1600/5093]\tLoss_sum:  0.549162( 0.603432)\tCls:  0.161528( 0.066670)\tBox:  0.153094( 0.025893)\tObj:  0.073455( 0.177920)\tRPN  0.161085( 0.332948)\n",
      "[Train]Epoch: [0][1610/5093]\tLoss_sum:  0.607203( 0.603254)\tCls:  0.115318( 0.066998)\tBox:  0.052514( 0.026431)\tObj:  0.150382( 0.177465)\tRPN  0.288989( 0.332359)\n",
      "[Train]Epoch: [0][1620/5093]\tLoss_sum:  0.741994( 0.601933)\tCls:  0.002259( 0.067090)\tBox:  0.000000( 0.026607)\tObj:  0.067089( 0.177244)\tRPN  0.672647( 0.330992)\n",
      "[Train]Epoch: [0][1630/5093]\tLoss_sum:  0.885959( 0.600831)\tCls:  0.041862( 0.066710)\tBox:  0.008805( 0.026449)\tObj:  0.238933( 0.176469)\tRPN  0.596358( 0.331203)\n",
      "[Train]Epoch: [0][1640/5093]\tLoss_sum:  0.969631( 0.600659)\tCls:  0.028781( 0.066994)\tBox:  0.000074( 0.026789)\tObj:  0.154996( 0.175863)\tRPN  0.785780( 0.331014)\n",
      "[Train]Epoch: [0][1650/5093]\tLoss_sum:  0.305815( 0.599650)\tCls:  0.062278( 0.066937)\tBox:  0.048938( 0.026866)\tObj:  0.152220( 0.175625)\tRPN  0.042379( 0.330222)\n",
      "[Train]Epoch: [0][1660/5093]\tLoss_sum:  0.085400( 0.597443)\tCls:  0.003264( 0.066602)\tBox:  0.000000( 0.026753)\tObj:  0.029359( 0.174950)\tRPN  0.052777( 0.329138)\n",
      "[Train]Epoch: [0][1670/5093]\tLoss_sum:  0.332938( 0.596457)\tCls:  0.002785( 0.066605)\tBox:  0.000000( 0.026976)\tObj:  0.039745( 0.174390)\tRPN  0.290407( 0.328486)\n",
      "[Train]Epoch: [0][1680/5093]\tLoss_sum:  0.516454( 0.595623)\tCls:  0.248141( 0.066875)\tBox:  0.146044( 0.027282)\tObj:  0.041091( 0.173826)\tRPN  0.081178( 0.327641)\n",
      "[Train]Epoch: [0][1690/5093]\tLoss_sum:  0.338240( 0.594252)\tCls:  0.002686( 0.066714)\tBox:  0.000000( 0.027367)\tObj:  0.020826( 0.172975)\tRPN  0.314728( 0.327197)\n",
      "[Train]Epoch: [0][1700/5093]\tLoss_sum:  0.060543( 0.591942)\tCls:  0.000663( 0.066334)\tBox:  0.000000( 0.027206)\tObj:  0.016517( 0.172079)\tRPN  0.043362( 0.326324)\n",
      "[Train]Epoch: [0][1710/5093]\tLoss_sum:  0.446764( 0.591006)\tCls:  0.162216( 0.066562)\tBox:  0.151136( 0.027508)\tObj:  0.042305( 0.171404)\tRPN  0.091106( 0.325532)\n",
      "[Train]Epoch: [0][1720/5093]\tLoss_sum:  0.053577( 0.588883)\tCls:  0.003355( 0.066552)\tBox:  0.000000( 0.027671)\tObj:  0.015518( 0.170637)\tRPN  0.034705( 0.324023)\n",
      "[Train]Epoch: [0][1730/5093]\tLoss_sum:  0.152972( 0.587362)\tCls:  0.009372( 0.066606)\tBox:  0.000000( 0.027830)\tObj:  0.022663( 0.169938)\tRPN  0.120937( 0.322988)\n",
      "[Train]Epoch: [0][1740/5093]\tLoss_sum:  0.320965( 0.586357)\tCls:  0.039438( 0.066548)\tBox:  0.000598( 0.027984)\tObj:  0.041194( 0.169269)\tRPN  0.239734( 0.322556)\n",
      "[Train]Epoch: [0][1750/5093]\tLoss_sum:  0.228490( 0.584824)\tCls:  0.053461( 0.066339)\tBox:  0.033317( 0.027965)\tObj:  0.035836( 0.168641)\tRPN  0.105876( 0.321879)\n",
      "[Train]Epoch: [0][1760/5093]\tLoss_sum:  0.479315( 0.583247)\tCls:  0.003629( 0.066248)\tBox:  0.000000( 0.027992)\tObj:  0.017490( 0.167971)\tRPN  0.458196( 0.321035)\n",
      "[Train]Epoch: [0][1770/5093]\tLoss_sum:  0.058079( 0.581403)\tCls:  0.020095( 0.066087)\tBox:  0.010077( 0.027970)\tObj:  0.008957( 0.167330)\tRPN  0.018950( 0.320017)\n",
      "[Train]Epoch: [0][1780/5093]\tLoss_sum:  0.148009( 0.580541)\tCls:  0.007881( 0.066000)\tBox:  0.000000( 0.028119)\tObj:  0.016143( 0.166579)\tRPN  0.123986( 0.319844)\n",
      "[Train]Epoch: [0][1790/5093]\tLoss_sum:  0.491837( 0.579395)\tCls:  0.130034( 0.065849)\tBox:  0.087700( 0.028081)\tObj:  0.105134( 0.165846)\tRPN  0.168969( 0.319618)\n",
      "[Train]Epoch: [0][1800/5093]\tLoss_sum:  0.463647( 0.578562)\tCls:  0.049762( 0.065832)\tBox:  0.039988( 0.028252)\tObj:  0.130713( 0.165155)\tRPN  0.243184( 0.319322)\n",
      "[Train]Epoch: [0][1810/5093]\tLoss_sum:  0.489475( 0.578114)\tCls:  0.092087( 0.065842)\tBox:  0.084966( 0.028457)\tObj:  0.075286( 0.164493)\tRPN  0.237136( 0.319323)\n",
      "[Train]Epoch: [0][1820/5093]\tLoss_sum:  0.150137( 0.576822)\tCls:  0.001304( 0.065893)\tBox:  0.000000( 0.028755)\tObj:  0.020225( 0.163875)\tRPN  0.128607( 0.318299)\n",
      "[Train]Epoch: [0][1830/5093]\tLoss_sum:  0.058339( 0.574082)\tCls:  0.000498( 0.065545)\tBox:  0.000000( 0.028598)\tObj:  0.008957( 0.163077)\tRPN  0.048883( 0.316862)\n",
      "[Train]Epoch: [0][1840/5093]\tLoss_sum:  0.337873( 0.573563)\tCls:  0.110546( 0.065654)\tBox:  0.130535( 0.028893)\tObj:  0.078467( 0.162800)\tRPN  0.018326( 0.316217)\n",
      "[Train]Epoch: [0][1850/5093]\tLoss_sum:  0.113643( 0.570954)\tCls:  0.002271( 0.065312)\tBox:  0.000000( 0.028736)\tObj:  0.074528( 0.162167)\tRPN  0.036844( 0.314739)\n",
      "[Train]Epoch: [0][1860/5093]\tLoss_sum:  0.246380( 0.568314)\tCls:  0.074478( 0.065025)\tBox:  0.032438( 0.028605)\tObj:  0.049301( 0.161458)\tRPN  0.090164( 0.313227)\n",
      "[Train]Epoch: [0][1870/5093]\tLoss_sum:  0.930199( 0.566026)\tCls:  0.079110( 0.064741)\tBox:  0.022088( 0.028477)\tObj:  0.658445( 0.161051)\tRPN  0.170555( 0.311756)\n",
      "[Train]Epoch: [0][1880/5093]\tLoss_sum:  0.157877( 0.565053)\tCls:  0.006423( 0.064567)\tBox:  0.000000( 0.028400)\tObj:  0.108649( 0.160992)\tRPN  0.042805( 0.311094)\n",
      "[Train]Epoch: [0][1890/5093]\tLoss_sum:  0.380079( 0.563646)\tCls:  0.005070( 0.064390)\tBox:  0.000000( 0.028416)\tObj:  0.053754( 0.160670)\tRPN  0.321256( 0.310169)\n",
      "[Train]Epoch: [0][1900/5093]\tLoss_sum:  0.053664( 0.561780)\tCls:  0.001816( 0.064077)\tBox:  0.000000( 0.028267)\tObj:  0.017729( 0.160019)\tRPN  0.034119( 0.309417)\n",
      "[Train]Epoch: [0][1910/5093]\tLoss_sum:  0.108992( 0.560677)\tCls:  0.002277( 0.063986)\tBox:  0.000000( 0.028315)\tObj:  0.039830( 0.159706)\tRPN  0.066884( 0.308670)\n",
      "[Train]Epoch: [0][1920/5093]\tLoss_sum:  0.066774( 0.559169)\tCls:  0.001450( 0.063795)\tBox:  0.000000( 0.028317)\tObj:  0.012584( 0.159172)\tRPN  0.052740( 0.307884)\n",
      "[Train]Epoch: [0][1930/5093]\tLoss_sum:  0.031616( 0.556513)\tCls:  0.000679( 0.063471)\tBox:  0.000000( 0.028171)\tObj:  0.014282( 0.158455)\tRPN  0.016656( 0.306416)\n",
      "[Train]Epoch: [0][1940/5093]\tLoss_sum:  0.953951( 0.555442)\tCls:  0.073951( 0.063588)\tBox:  0.000419( 0.028320)\tObj:  0.335485( 0.158158)\tRPN  0.544097( 0.305376)\n",
      "[Train]Epoch: [0][1950/5093]\tLoss_sum:  0.578446( 0.555699)\tCls:  0.118593( 0.064034)\tBox:  0.160091( 0.029014)\tObj:  0.067921( 0.157777)\tRPN  0.231841( 0.304874)\n",
      "[Train]Epoch: [0][1960/5093]\tLoss_sum:  0.310138( 0.554072)\tCls:  0.058870( 0.063978)\tBox:  0.026092( 0.029145)\tObj:  0.068851( 0.157276)\tRPN  0.156325( 0.303672)\n",
      "[Train]Epoch: [0][1970/5093]\tLoss_sum:  0.292865( 0.553122)\tCls:  0.017524( 0.064020)\tBox:  0.010124( 0.029365)\tObj:  0.034851( 0.156721)\tRPN  0.230366( 0.303016)\n",
      "[Train]Epoch: [0][1980/5093]\tLoss_sum:  0.372064( 0.551981)\tCls:  0.166316( 0.064221)\tBox:  0.185443( 0.029730)\tObj:  0.006409( 0.156097)\tRPN  0.013896( 0.301934)\n",
      "[Train]Epoch: [0][1990/5093]\tLoss_sum:  0.439085( 0.551419)\tCls:  0.133782( 0.064390)\tBox:  0.166179( 0.030070)\tObj:  0.035053( 0.155584)\tRPN  0.104071( 0.301375)\n",
      "[Train]Epoch: [0][2000/5093]\tLoss_sum:  0.580870( 0.551219)\tCls:  0.162036( 0.064732)\tBox:  0.289402( 0.030708)\tObj:  0.103589( 0.155186)\tRPN  0.025844( 0.300593)\n",
      "[Train]Epoch: [0][2010/5093]\tLoss_sum:  0.208177( 0.549641)\tCls:  0.051045( 0.064520)\tBox:  0.040117( 0.030629)\tObj:  0.085703( 0.154639)\tRPN  0.031313( 0.299852)\n",
      "[Train]Epoch: [0][2020/5093]\tLoss_sum:  0.445198( 0.549706)\tCls:  0.007291( 0.064794)\tBox:  0.000000( 0.031038)\tObj:  0.027039( 0.154236)\tRPN  0.410868( 0.299638)\n",
      "[Train]Epoch: [0][2030/5093]\tLoss_sum:  0.494329( 0.549722)\tCls:  0.154598( 0.064906)\tBox:  0.233991( 0.031349)\tObj:  0.025823( 0.153751)\tRPN  0.079917( 0.299715)\n",
      "[Train]Epoch: [0][2040/5093]\tLoss_sum:  0.400011( 0.548797)\tCls:  0.095564( 0.064899)\tBox:  0.053081( 0.031436)\tObj:  0.063493( 0.153474)\tRPN  0.187872( 0.298989)\n",
      "[Train]Epoch: [0][2050/5093]\tLoss_sum:  0.412736( 0.548797)\tCls:  0.002504( 0.064753)\tBox:  0.000000( 0.031421)\tObj:  0.027932( 0.153058)\tRPN  0.382300( 0.299565)\n",
      "[Train]Epoch: [0][2060/5093]\tLoss_sum:  0.421989( 0.547735)\tCls:  0.148618( 0.064656)\tBox:  0.211357( 0.031509)\tObj:  0.029245( 0.152548)\tRPN  0.032769( 0.299022)\n",
      "[Train]Epoch: [0][2070/5093]\tLoss_sum:  0.152378( 0.546180)\tCls:  0.007038( 0.064526)\tBox:  0.000000( 0.031397)\tObj:  0.007429( 0.151916)\tRPN  0.137912( 0.298341)\n",
      "[Train]Epoch: [0][2080/5093]\tLoss_sum:  0.454733( 0.546715)\tCls:  0.028277( 0.064346)\tBox:  0.048163( 0.031329)\tObj:  0.350116( 0.153180)\tRPN  0.028177( 0.297860)\n",
      "[Train]Epoch: [0][2090/5093]\tLoss_sum:  0.413419( 0.547016)\tCls:  0.166870( 0.064505)\tBox:  0.141406( 0.031643)\tObj:  0.081895( 0.152978)\tRPN  0.023248( 0.297890)\n",
      "[Train]Epoch: [0][2100/5093]\tLoss_sum:  0.125168( 0.545774)\tCls:  0.005816( 0.064542)\tBox:  0.000000( 0.031729)\tObj:  0.017826( 0.152443)\tRPN  0.101525( 0.297060)\n",
      "[Train]Epoch: [0][2110/5093]\tLoss_sum:  1.163203( 0.545214)\tCls:  0.143215( 0.064419)\tBox:  0.113153( 0.031721)\tObj:  0.158640( 0.152144)\tRPN  0.748195( 0.296931)\n",
      "[Train]Epoch: [0][2120/5093]\tLoss_sum:  0.763162( 0.546201)\tCls:  0.169565( 0.064756)\tBox:  0.146782( 0.032030)\tObj:  0.099817( 0.151728)\tRPN  0.346998( 0.297687)\n",
      "[Train]Epoch: [0][2130/5093]\tLoss_sum:  0.191208( 0.545028)\tCls:  0.074831( 0.064856)\tBox:  0.067647( 0.032187)\tObj:  0.035776( 0.151217)\tRPN  0.012954( 0.296768)\n",
      "[Train]Epoch: [0][2140/5093]\tLoss_sum:  0.106340( 0.543722)\tCls:  0.004831( 0.064716)\tBox:  0.000000( 0.032179)\tObj:  0.016611( 0.150881)\tRPN  0.084898( 0.295946)\n",
      "[Train]Epoch: [0][2150/5093]\tLoss_sum:  0.111137( 0.541757)\tCls:  0.008854( 0.064474)\tBox:  0.000000( 0.032029)\tObj:  0.074155( 0.150499)\tRPN  0.028128( 0.294755)\n",
      "[Train]Epoch: [0][2160/5093]\tLoss_sum:  0.351499( 0.541086)\tCls:  0.108332( 0.064567)\tBox:  0.091142( 0.032225)\tObj:  0.076920( 0.150257)\tRPN  0.075105( 0.294036)\n",
      "[Train]Epoch: [0][2170/5093]\tLoss_sum:  0.409894( 0.540635)\tCls:  0.168149( 0.064800)\tBox:  0.145332( 0.032522)\tObj:  0.087702( 0.149896)\tRPN  0.008711( 0.293418)\n",
      "[Train]Epoch: [0][2180/5093]\tLoss_sum:  0.122443( 0.539175)\tCls:  0.004339( 0.064687)\tBox:  0.000000( 0.032465)\tObj:  0.010450( 0.149423)\tRPN  0.107654( 0.292599)\n",
      "[Train]Epoch: [0][2190/5093]\tLoss_sum:  0.532041( 0.538490)\tCls:  0.128287( 0.064790)\tBox:  0.201672( 0.032739)\tObj:  0.098576( 0.149051)\tRPN  0.103506( 0.291910)\n",
      "[Train]Epoch: [0][2200/5093]\tLoss_sum:  0.205576( 0.537749)\tCls:  0.025497( 0.064689)\tBox:  0.005692( 0.032735)\tObj:  0.042895( 0.148655)\tRPN  0.131491( 0.291669)\n",
      "[Train]Epoch: [0][2210/5093]\tLoss_sum:  0.518932( 0.537418)\tCls:  0.200673( 0.064956)\tBox:  0.215494( 0.033111)\tObj:  0.030608( 0.148206)\tRPN  0.072156( 0.291145)\n",
      "[Train]Epoch: [0][2220/5093]\tLoss_sum:  0.628121( 0.537397)\tCls:  0.091294( 0.065250)\tBox:  0.068395( 0.033487)\tObj:  0.147252( 0.147934)\tRPN  0.321180( 0.290726)\n",
      "[Train]Epoch: [0][2230/5093]\tLoss_sum:  0.129518( 0.537130)\tCls:  0.004891( 0.065547)\tBox:  0.000000( 0.034053)\tObj:  0.024295( 0.147611)\tRPN  0.100332( 0.289920)\n",
      "[Train]Epoch: [0][2240/5093]\tLoss_sum:  0.126922( 0.536011)\tCls:  0.000923( 0.065414)\tBox:  0.000000( 0.034093)\tObj:  0.009375( 0.147205)\tRPN  0.116624( 0.289298)\n",
      "[Train]Epoch: [0][2250/5093]\tLoss_sum:  0.177651( 0.535015)\tCls:  0.001770( 0.065268)\tBox:  0.000000( 0.034143)\tObj:  0.020938( 0.146853)\tRPN  0.154944( 0.288751)\n",
      "[Train]Epoch: [0][2260/5093]\tLoss_sum:  0.085774( 0.533101)\tCls:  0.001471( 0.064993)\tBox:  0.000000( 0.033992)\tObj:  0.037576( 0.146321)\tRPN  0.046727( 0.287795)\n",
      "[Train]Epoch: [0][2270/5093]\tLoss_sum:  0.335680( 0.532767)\tCls:  0.083184( 0.065208)\tBox:  0.050252( 0.034270)\tObj:  0.143567( 0.146117)\tRPN  0.058678( 0.287171)\n",
      "[Train]Epoch: [0][2280/5093]\tLoss_sum:  0.387079( 0.532218)\tCls:  0.104564( 0.065294)\tBox:  0.138791( 0.034447)\tObj:  0.041825( 0.145691)\tRPN  0.101898( 0.286786)\n",
      "[Train]Epoch: [0][2290/5093]\tLoss_sum:  0.143935( 0.531084)\tCls:  0.005633( 0.065332)\tBox:  0.000000( 0.034693)\tObj:  0.024494( 0.145186)\tRPN  0.113808( 0.285873)\n",
      "[Train]Epoch: [0][2300/5093]\tLoss_sum:  0.544679( 0.530334)\tCls:  0.107572( 0.065162)\tBox:  0.188861( 0.034660)\tObj:  0.072740( 0.144937)\tRPN  0.175505( 0.285575)\n",
      "[Train]Epoch: [0][2310/5093]\tLoss_sum:  0.204658( 0.529909)\tCls:  0.000952( 0.065257)\tBox:  0.000000( 0.034869)\tObj:  0.022716( 0.144593)\tRPN  0.180990( 0.285189)\n",
      "[Train]Epoch: [0][2320/5093]\tLoss_sum:  0.603680( 0.529764)\tCls:  0.162139( 0.065421)\tBox:  0.139764( 0.035174)\tObj:  0.047967( 0.144197)\tRPN  0.253810( 0.284971)\n",
      "[Train]Epoch: [0][2330/5093]\tLoss_sum:  0.095531( 0.529004)\tCls:  0.000714( 0.065515)\tBox:  0.000000( 0.035508)\tObj:  0.008368( 0.143783)\tRPN  0.086449( 0.284198)\n",
      "[Train]Epoch: [0][2340/5093]\tLoss_sum:  0.275768( 0.528888)\tCls:  0.021285( 0.065582)\tBox:  0.019290( 0.035751)\tObj:  0.039974( 0.143305)\tRPN  0.195219( 0.284251)\n",
      "[Train]Epoch: [0][2350/5093]\tLoss_sum:  0.704888( 0.528817)\tCls:  0.159091( 0.065715)\tBox:  0.233251( 0.036012)\tObj:  0.048899( 0.142948)\tRPN  0.263647( 0.284142)\n",
      "[Train]Epoch: [0][2360/5093]\tLoss_sum:  0.990863( 0.528883)\tCls:  0.272261( 0.066095)\tBox:  0.342656( 0.036578)\tObj:  0.119187( 0.142629)\tRPN  0.256760( 0.283580)\n",
      "[Train]Epoch: [0][2370/5093]\tLoss_sum:  0.455953( 0.528981)\tCls:  0.081617( 0.066385)\tBox:  0.140359( 0.037138)\tObj:  0.044718( 0.142231)\tRPN  0.189259( 0.283227)\n",
      "[Train]Epoch: [0][2380/5093]\tLoss_sum:  0.022055( 0.527599)\tCls:  0.001912( 0.066327)\tBox:  0.000000( 0.037253)\tObj:  0.006299( 0.141741)\tRPN  0.013845( 0.282278)\n",
      "[Train]Epoch: [0][2390/5093]\tLoss_sum:  0.390900( 0.526966)\tCls:  0.060608( 0.066368)\tBox:  0.088694( 0.037462)\tObj:  0.016624( 0.141293)\tRPN  0.224975( 0.281843)\n",
      "[Train]Epoch: [0][2400/5093]\tLoss_sum:  0.056298( 0.526034)\tCls:  0.002762( 0.066351)\tBox:  0.000000( 0.037715)\tObj:  0.006274( 0.140797)\tRPN  0.047262( 0.281171)\n",
      "[Train]Epoch: [0][2410/5093]\tLoss_sum:  0.059130( 0.524042)\tCls:  0.012959( 0.066085)\tBox:  0.000000( 0.037559)\tObj:  0.021279( 0.140252)\tRPN  0.024893( 0.280147)\n",
      "[Train]Epoch: [0][2420/5093]\tLoss_sum:  0.053463( 0.522577)\tCls:  0.002058( 0.065839)\tBox:  0.000000( 0.037404)\tObj:  0.037599( 0.139991)\tRPN  0.013806( 0.279344)\n",
      "[Train]Epoch: [0][2430/5093]\tLoss_sum:  0.252858( 0.521871)\tCls:  0.029937( 0.065753)\tBox:  0.090098( 0.037431)\tObj:  0.089540( 0.139733)\tRPN  0.043283( 0.278954)\n",
      "[Train]Epoch: [0][2440/5093]\tLoss_sum:  0.122834( 0.520685)\tCls:  0.002730( 0.065601)\tBox:  0.000000( 0.037428)\tObj:  0.024981( 0.139362)\tRPN  0.095124( 0.278294)\n",
      "[Train]Epoch: [0][2450/5093]\tLoss_sum:  0.053449( 0.518895)\tCls:  0.001142( 0.065339)\tBox:  0.000000( 0.037275)\tObj:  0.009386( 0.138855)\tRPN  0.042921( 0.277425)\n",
      "[Train]Epoch: [0][2460/5093]\tLoss_sum:  0.350137( 0.517789)\tCls:  0.049302( 0.065172)\tBox:  0.033077( 0.037174)\tObj:  0.046649( 0.138505)\tRPN  0.221108( 0.276938)\n",
      "[Train]Epoch: [0][2470/5093]\tLoss_sum:  0.145610( 0.516495)\tCls:  0.001242( 0.064982)\tBox:  0.000000( 0.037167)\tObj:  0.038913( 0.138090)\tRPN  0.105454( 0.276256)\n",
      "[Train]Epoch: [0][2480/5093]\tLoss_sum:  0.363679( 0.515265)\tCls:  0.093637( 0.064830)\tBox:  0.138806( 0.037138)\tObj:  0.034654( 0.137705)\tRPN  0.096582( 0.275591)\n",
      "[Train]Epoch: [0][2490/5093]\tLoss_sum:  0.126525( 0.514828)\tCls:  0.000973( 0.064969)\tBox:  0.000000( 0.037571)\tObj:  0.013582( 0.137359)\tRPN  0.111970( 0.274929)\n",
      "[Train]Epoch: [0][2500/5093]\tLoss_sum:  0.718039( 0.513288)\tCls:  0.036711( 0.064728)\tBox:  0.000202( 0.037421)\tObj:  0.070343( 0.136912)\tRPN  0.610783( 0.274227)\n",
      "[Train]Epoch: [0][2510/5093]\tLoss_sum:  0.174731( 0.513007)\tCls:  0.049913( 0.064747)\tBox:  0.041974( 0.037619)\tObj:  0.074992( 0.136572)\tRPN  0.007852( 0.274070)\n",
      "[Train]Epoch: [0][2520/5093]\tLoss_sum:  0.262329( 0.512275)\tCls:  0.000873( 0.064846)\tBox:  0.000000( 0.037816)\tObj:  0.007846( 0.136192)\tRPN  0.253609( 0.273420)\n",
      "[Train]Epoch: [0][2530/5093]\tLoss_sum:  0.579018( 0.511469)\tCls:  0.165998( 0.064764)\tBox:  0.143454( 0.037794)\tObj:  0.064333( 0.135824)\tRPN  0.205233( 0.273087)\n",
      "[Train]Epoch: [0][2540/5093]\tLoss_sum:  0.480207( 0.511195)\tCls:  0.111734( 0.065078)\tBox:  0.111665( 0.038261)\tObj:  0.042404( 0.135432)\tRPN  0.214403( 0.272424)\n",
      "[Train]Epoch: [0][2550/5093]\tLoss_sum:  0.164332( 0.510572)\tCls:  0.027561( 0.065175)\tBox:  0.047447( 0.038480)\tObj:  0.076823( 0.135105)\tRPN  0.012501( 0.271812)\n",
      "[Train]Epoch: [0][2560/5093]\tLoss_sum:  0.233965( 0.509507)\tCls:  0.073076( 0.065009)\tBox:  0.020900( 0.038414)\tObj:  0.029463( 0.134769)\tRPN  0.110526( 0.271315)\n",
      "[Train]Epoch: [0][2570/5093]\tLoss_sum:  0.179361( 0.508823)\tCls:  0.001198( 0.065043)\tBox:  0.000000( 0.038666)\tObj:  0.010191( 0.134350)\tRPN  0.167973( 0.270764)\n",
      "[Train]Epoch: [0][2580/5093]\tLoss_sum:  0.349682( 0.508752)\tCls:  0.156516( 0.065228)\tBox:  0.115168( 0.039002)\tObj:  0.021061( 0.134098)\tRPN  0.056936( 0.270425)\n",
      "[Train]Epoch: [0][2590/5093]\tLoss_sum:  0.378798( 0.508099)\tCls:  0.049821( 0.065296)\tBox:  0.048468( 0.039261)\tObj:  0.101922( 0.133747)\tRPN  0.178586( 0.269796)\n",
      "[Train]Epoch: [0][2600/5093]\tLoss_sum:  0.189366( 0.507599)\tCls:  0.003299( 0.065344)\tBox:  0.000000( 0.039565)\tObj:  0.020320( 0.133404)\tRPN  0.165747( 0.269286)\n",
      "[Train]Epoch: [0][2610/5093]\tLoss_sum:  0.408021( 0.506795)\tCls:  0.104488( 0.065360)\tBox:  0.115861( 0.039659)\tObj:  0.025634( 0.133063)\tRPN  0.162037( 0.268713)\n",
      "[Train]Epoch: [0][2620/5093]\tLoss_sum:  0.363159( 0.506306)\tCls:  0.080679( 0.065386)\tBox:  0.074232( 0.039833)\tObj:  0.052306( 0.132720)\tRPN  0.155942( 0.268368)\n",
      "[Train]Epoch: [0][2630/5093]\tLoss_sum:  0.177457( 0.505590)\tCls:  0.000752( 0.065399)\tBox:  0.000000( 0.040165)\tObj:  0.028263( 0.132327)\tRPN  0.148442( 0.267699)\n",
      "[Train]Epoch: [0][2640/5093]\tLoss_sum:  0.070783( 0.503995)\tCls:  0.000313( 0.065155)\tBox:  0.000000( 0.040013)\tObj:  0.012075( 0.131879)\tRPN  0.058394( 0.266949)\n",
      "[Train]Epoch: [0][2650/5093]\tLoss_sum:  0.553246( 0.503596)\tCls:  0.118212( 0.065173)\tBox:  0.106780( 0.040118)\tObj:  0.253641( 0.131845)\tRPN  0.074614( 0.266460)\n",
      "[Train]Epoch: [0][2660/5093]\tLoss_sum:  0.063003( 0.502222)\tCls:  0.001637( 0.065033)\tBox:  0.000000( 0.040045)\tObj:  0.026025( 0.131529)\tRPN  0.035341( 0.265615)\n",
      "[Train]Epoch: [0][2670/5093]\tLoss_sum:  0.705467( 0.501504)\tCls:  0.264005( 0.065043)\tBox:  0.287707( 0.040125)\tObj:  0.042430( 0.131181)\tRPN  0.111326( 0.265156)\n",
      "[Train]Epoch: [0][2680/5093]\tLoss_sum:  0.292335( 0.501112)\tCls:  0.103421( 0.065156)\tBox:  0.154489( 0.040291)\tObj:  0.024860( 0.130848)\tRPN  0.009565( 0.264817)\n",
      "[Train]Epoch: [0][2690/5093]\tLoss_sum:  0.286787( 0.500452)\tCls:  0.066164( 0.065152)\tBox:  0.054578( 0.040399)\tObj:  0.062723( 0.130486)\tRPN  0.103321( 0.264416)\n",
      "[Train]Epoch: [0][2700/5093]\tLoss_sum:  0.148667( 0.500164)\tCls:  0.000403( 0.065093)\tBox:  0.000000( 0.040476)\tObj:  0.033037( 0.130133)\tRPN  0.115227( 0.264462)\n",
      "[Train]Epoch: [0][2710/5093]\tLoss_sum:  0.368371( 0.499128)\tCls:  0.120081( 0.064943)\tBox:  0.095999( 0.040390)\tObj:  0.035059( 0.129755)\tRPN  0.117231( 0.264040)\n",
      "[Train]Epoch: [0][2720/5093]\tLoss_sum:  0.843727( 0.499726)\tCls:  0.010417( 0.064964)\tBox:  0.000000( 0.040516)\tObj:  0.063492( 0.129899)\tRPN  0.769818( 0.264346)\n",
      "[Train]Epoch: [0][2730/5093]\tLoss_sum:  0.428989( 0.499613)\tCls:  0.006700( 0.064977)\tBox:  0.000000( 0.040664)\tObj:  0.082408( 0.129785)\tRPN  0.339880( 0.264186)\n",
      "[Train]Epoch: [0][2740/5093]\tLoss_sum:  0.300943( 0.498639)\tCls:  0.043502( 0.064775)\tBox:  0.043160( 0.040539)\tObj:  0.074532( 0.129493)\tRPN  0.139748( 0.263832)\n",
      "[Train]Epoch: [0][2750/5093]\tLoss_sum:  0.109030( 0.497656)\tCls:  0.001568( 0.064653)\tBox:  0.000000( 0.040502)\tObj:  0.019036( 0.129123)\tRPN  0.088426( 0.263377)\n",
      "[Train]Epoch: [0][2760/5093]\tLoss_sum:  0.603944( 0.496746)\tCls:  0.174452( 0.064630)\tBox:  0.244597( 0.040596)\tObj:  0.052534( 0.128769)\tRPN  0.132362( 0.262751)\n",
      "[Train]Epoch: [0][2770/5093]\tLoss_sum:  0.418178( 0.496982)\tCls:  0.124448( 0.064911)\tBox:  0.199550( 0.041243)\tObj:  0.082764( 0.128630)\tRPN  0.011416( 0.262198)\n",
      "[Train]Epoch: [0][2780/5093]\tLoss_sum:  0.712253( 0.496544)\tCls:  0.227658( 0.064970)\tBox:  0.374109( 0.041487)\tObj:  0.086397( 0.128320)\tRPN  0.024089( 0.261767)\n",
      "[Train]Epoch: [0][2790/5093]\tLoss_sum:  0.475131( 0.495938)\tCls:  0.248998( 0.065000)\tBox:  0.142534( 0.041632)\tObj:  0.023484( 0.127985)\tRPN  0.060115( 0.261320)\n",
      "[Train]Epoch: [0][2800/5093]\tLoss_sum:  0.168511( 0.495708)\tCls:  0.003431( 0.065167)\tBox:  0.000000( 0.041906)\tObj:  0.014091( 0.127668)\tRPN  0.150989( 0.260967)\n",
      "[Train]Epoch: [0][2810/5093]\tLoss_sum:  0.094379( 0.494233)\tCls:  0.003361( 0.064945)\tBox:  0.000000( 0.041756)\tObj:  0.041785( 0.127264)\tRPN  0.049234( 0.260267)\n",
      "[Train]Epoch: [0][2820/5093]\tLoss_sum:  0.042035( 0.493439)\tCls:  0.002200( 0.064996)\tBox:  0.000000( 0.041902)\tObj:  0.013530( 0.126947)\tRPN  0.026305( 0.259594)\n",
      "[Train]Epoch: [0][2830/5093]\tLoss_sum:  0.057282( 0.491856)\tCls:  0.002964( 0.064780)\tBox:  0.000000( 0.041754)\tObj:  0.044391( 0.126590)\tRPN  0.009927( 0.258732)\n",
      "[Train]Epoch: [0][2840/5093]\tLoss_sum:  0.519445( 0.491609)\tCls:  0.234658( 0.064952)\tBox:  0.176682( 0.042018)\tObj:  0.043022( 0.126316)\tRPN  0.065083( 0.258323)\n",
      "[Train]Epoch: [0][2850/5093]\tLoss_sum:  0.072571( 0.491272)\tCls:  0.015070( 0.065097)\tBox:  0.000000( 0.042334)\tObj:  0.046585( 0.126189)\tRPN  0.010915( 0.257653)\n",
      "[Train]Epoch: [0][2860/5093]\tLoss_sum:  0.279431( 0.490085)\tCls:  0.070401( 0.064980)\tBox:  0.070652( 0.042244)\tObj:  0.035442( 0.125920)\tRPN  0.102937( 0.256940)\n",
      "[Train]Epoch: [0][2870/5093]\tLoss_sum:  0.110815( 0.489342)\tCls:  0.000610( 0.064958)\tBox:  0.000000( 0.042444)\tObj:  0.018151( 0.125583)\tRPN  0.092054( 0.256358)\n",
      "[Train]Epoch: [0][2880/5093]\tLoss_sum:  0.268695( 0.488466)\tCls:  0.000219( 0.064812)\tBox:  0.000000( 0.042352)\tObj:  0.005857( 0.125274)\tRPN  0.262619( 0.256028)\n",
      "[Train]Epoch: [0][2890/5093]\tLoss_sum:  0.535149( 0.488140)\tCls:  0.124004( 0.064872)\tBox:  0.163709( 0.042658)\tObj:  0.072045( 0.124976)\tRPN  0.175392( 0.255633)\n",
      "[Train]Epoch: [0][2900/5093]\tLoss_sum:  0.503212( 0.488355)\tCls:  0.052117( 0.064829)\tBox:  0.047940( 0.042742)\tObj:  0.030860( 0.124733)\tRPN  0.372295( 0.256051)\n",
      "[Train]Epoch: [0][2910/5093]\tLoss_sum:  0.573668( 0.488431)\tCls:  0.099541( 0.065015)\tBox:  0.213741( 0.043144)\tObj:  0.041400( 0.124479)\tRPN  0.218985( 0.255792)\n",
      "[Train]Epoch: [0][2920/5093]\tLoss_sum:  0.417290( 0.487759)\tCls:  0.116023( 0.065015)\tBox:  0.104607( 0.043322)\tObj:  0.064717( 0.124195)\tRPN  0.131944( 0.255227)\n",
      "[Train]Epoch: [0][2930/5093]\tLoss_sum:  0.239616( 0.487243)\tCls:  0.000290( 0.065100)\tBox:  0.000000( 0.043590)\tObj:  0.013037( 0.123876)\tRPN  0.226288( 0.254678)\n",
      "[Train]Epoch: [0][2940/5093]\tLoss_sum:  0.092606( 0.485931)\tCls:  0.019844( 0.064886)\tBox:  0.033919( 0.043454)\tObj:  0.011564( 0.123494)\tRPN  0.027279( 0.254097)\n",
      "[Train]Epoch: [0][2950/5093]\tLoss_sum:  0.355979( 0.485636)\tCls:  0.005566( 0.065081)\tBox:  0.000000( 0.043730)\tObj:  0.010891( 0.123150)\tRPN  0.339522( 0.253675)\n",
      "[Train]Epoch: [0][2960/5093]\tLoss_sum:  0.330815( 0.484860)\tCls:  0.044736( 0.064905)\tBox:  0.046166( 0.043606)\tObj:  0.038728( 0.122940)\tRPN  0.201184( 0.253408)\n",
      "[Train]Epoch: [0][2970/5093]\tLoss_sum:  0.184635( 0.484199)\tCls:  0.047034( 0.065026)\tBox:  0.047223( 0.043569)\tObj:  0.080143( 0.122632)\tRPN  0.010235( 0.252971)\n",
      "[Train]Epoch: [0][2980/5093]\tLoss_sum:  0.281266( 0.483563)\tCls:  0.000164( 0.064861)\tBox:  0.000000( 0.043475)\tObj:  0.008165( 0.122275)\tRPN  0.272937( 0.252952)\n",
      "[Train]Epoch: [0][2990/5093]\tLoss_sum:  0.604011( 0.483150)\tCls:  0.079353( 0.064909)\tBox:  0.122337( 0.043610)\tObj:  0.106350( 0.122002)\tRPN  0.295971( 0.252628)\n",
      "[Train]Epoch: [0][3000/5093]\tLoss_sum:  0.121542( 0.482270)\tCls:  0.001713( 0.064752)\tBox:  0.000000( 0.043609)\tObj:  0.010973( 0.121683)\tRPN  0.108855( 0.252225)\n",
      "[Train]Epoch: [0][3010/5093]\tLoss_sum:  0.261146( 0.481841)\tCls:  0.033919( 0.064716)\tBox:  0.006731( 0.043735)\tObj:  0.028423( 0.121370)\tRPN  0.192074( 0.252020)\n",
      "[Train]Epoch: [0][3020/5093]\tLoss_sum:  0.900658( 0.481897)\tCls:  0.201759( 0.064887)\tBox:  0.212764( 0.043989)\tObj:  0.065466( 0.121091)\tRPN  0.420670( 0.251930)\n",
      "[Train]Epoch: [0][3030/5093]\tLoss_sum:  0.569578( 0.482245)\tCls:  0.131917( 0.065134)\tBox:  0.278930( 0.044484)\tObj:  0.029856( 0.120877)\tRPN  0.128876( 0.251750)\n",
      "[Train]Epoch: [0][3040/5093]\tLoss_sum:  0.313414( 0.482431)\tCls:  0.090329( 0.065338)\tBox:  0.103836( 0.044848)\tObj:  0.018910( 0.120613)\tRPN  0.100338( 0.251633)\n",
      "[Train]Epoch: [0][3050/5093]\tLoss_sum:  0.477681( 0.482109)\tCls:  0.050034( 0.065294)\tBox:  0.068789( 0.045009)\tObj:  0.024008( 0.120385)\tRPN  0.334850( 0.251421)\n",
      "[Train]Epoch: [0][3060/5093]\tLoss_sum:  0.034167( 0.481050)\tCls:  0.001143( 0.065203)\tBox:  0.000000( 0.045049)\tObj:  0.008409( 0.120055)\tRPN  0.024615( 0.250742)\n",
      "[Train]Epoch: [0][3070/5093]\tLoss_sum:  0.392097( 0.480682)\tCls:  0.062517( 0.065135)\tBox:  0.105277( 0.045086)\tObj:  0.025002( 0.119744)\tRPN  0.199302( 0.250717)\n",
      "[Train]Epoch: [0][3080/5093]\tLoss_sum:  0.030602( 0.479720)\tCls:  0.000943( 0.065093)\tBox:  0.000000( 0.045113)\tObj:  0.004994( 0.119418)\tRPN  0.024666( 0.250096)\n",
      "[Train]Epoch: [0][3090/5093]\tLoss_sum:  0.074828( 0.478877)\tCls:  0.000815( 0.064988)\tBox:  0.000000( 0.045133)\tObj:  0.009500( 0.119112)\tRPN  0.064513( 0.249643)\n",
      "[Train]Epoch: [0][3100/5093]\tLoss_sum:  0.252858( 0.477888)\tCls:  0.043980( 0.064826)\tBox:  0.082217( 0.045059)\tObj:  0.009222( 0.118781)\tRPN  0.117439( 0.249222)\n",
      "[Train]Epoch: [0][3110/5093]\tLoss_sum:  0.238661( 0.477370)\tCls:  0.039967( 0.064814)\tBox:  0.078828( 0.045251)\tObj:  0.039321( 0.118550)\tRPN  0.080545( 0.248753)\n",
      "[Train]Epoch: [0][3120/5093]\tLoss_sum:  0.088918( 0.476507)\tCls:  0.005522( 0.064675)\tBox:  0.000000( 0.045188)\tObj:  0.034428( 0.118392)\tRPN  0.048968( 0.248252)\n",
      "[Train]Epoch: [0][3130/5093]\tLoss_sum:  0.170666( 0.475879)\tCls:  0.013811( 0.064628)\tBox:  0.038550( 0.045299)\tObj:  0.084943( 0.118160)\tRPN  0.033363( 0.247791)\n",
      "[Train]Epoch: [0][3140/5093]\tLoss_sum:  0.366710( 0.475303)\tCls:  0.001199( 0.064583)\tBox:  0.000000( 0.045479)\tObj:  0.013627( 0.117886)\tRPN  0.351884( 0.247355)\n",
      "[Train]Epoch: [0][3150/5093]\tLoss_sum:  0.526826( 0.474648)\tCls:  0.042624( 0.064430)\tBox:  0.145855( 0.045440)\tObj:  0.047322( 0.117579)\tRPN  0.291025( 0.247199)\n",
      "[Train]Epoch: [0][3160/5093]\tLoss_sum:  0.370777( 0.474205)\tCls:  0.000187( 0.064323)\tBox:  0.000000( 0.045549)\tObj:  0.008446( 0.117293)\tRPN  0.362144( 0.247040)\n",
      "[Train]Epoch: [0][3170/5093]\tLoss_sum:  0.143017( 0.473243)\tCls:  0.022023( 0.064136)\tBox:  0.033726( 0.045429)\tObj:  0.040090( 0.116969)\tRPN  0.047178( 0.246708)\n",
      "[Train]Epoch: [0][3180/5093]\tLoss_sum:  0.210117( 0.472720)\tCls:  0.033980( 0.064082)\tBox:  0.107010( 0.045495)\tObj:  0.011183( 0.116718)\tRPN  0.057944( 0.246424)\n",
      "[Train]Epoch: [0][3190/5093]\tLoss_sum:  0.342426( 0.472403)\tCls:  0.038673( 0.064044)\tBox:  0.064594( 0.045575)\tObj:  0.022947( 0.116673)\tRPN  0.216213( 0.246111)\n",
      "[Train]Epoch: [0][3200/5093]\tLoss_sum:  0.182468( 0.471629)\tCls:  0.026350( 0.063926)\tBox:  0.038870( 0.045576)\tObj:  0.050302( 0.116470)\tRPN  0.066947( 0.245657)\n",
      "[Train]Epoch: [0][3210/5093]\tLoss_sum:  0.085530( 0.470831)\tCls:  0.002545( 0.063789)\tBox:  0.000000( 0.045570)\tObj:  0.008331( 0.116251)\tRPN  0.074653( 0.245222)\n",
      "[Train]Epoch: [0][3220/5093]\tLoss_sum:  0.217965( 0.469982)\tCls:  0.030858( 0.063670)\tBox:  0.080957( 0.045539)\tObj:  0.052340( 0.115992)\tRPN  0.053810( 0.244781)\n",
      "[Train]Epoch: [0][3230/5093]\tLoss_sum:  0.296509( 0.469198)\tCls:  0.070854( 0.063686)\tBox:  0.193159( 0.045742)\tObj:  0.024554( 0.115691)\tRPN  0.007942( 0.244078)\n",
      "[Train]Epoch: [0][3240/5093]\tLoss_sum:  0.209847( 0.468890)\tCls:  0.034943( 0.063616)\tBox:  0.083921( 0.045776)\tObj:  0.041183( 0.115677)\tRPN  0.049800( 0.243821)\n",
      "[Train]Epoch: [0][3250/5093]\tLoss_sum:  0.159742( 0.468157)\tCls:  0.012613( 0.063490)\tBox:  0.019550( 0.045709)\tObj:  0.090114( 0.115546)\tRPN  0.037465( 0.243411)\n",
      "[Train]Epoch: [0][3260/5093]\tLoss_sum:  0.296457( 0.467524)\tCls:  0.059289( 0.063427)\tBox:  0.154948( 0.045808)\tObj:  0.040003( 0.115345)\tRPN  0.042216( 0.242944)\n",
      "[Train]Epoch: [0][3270/5093]\tLoss_sum:  0.110059( 0.466846)\tCls:  0.001129( 0.063262)\tBox:  0.000000( 0.045701)\tObj:  0.043536( 0.115323)\tRPN  0.065394( 0.242560)\n",
      "[Train]Epoch: [0][3280/5093]\tLoss_sum:  0.500171( 0.466726)\tCls:  0.067088( 0.063260)\tBox:  0.168494( 0.045888)\tObj:  0.117629( 0.115241)\tRPN  0.146960( 0.242337)\n",
      "[Train]Epoch: [0][3290/5093]\tLoss_sum:  0.469940( 0.466517)\tCls:  0.070349( 0.063258)\tBox:  0.066722( 0.045987)\tObj:  0.075564( 0.115089)\tRPN  0.257306( 0.242184)\n",
      "[Train]Epoch: [0][3300/5093]\tLoss_sum:  0.159454( 0.466747)\tCls:  0.037000( 0.063438)\tBox:  0.067587( 0.046301)\tObj:  0.017517( 0.114930)\tRPN  0.037350( 0.242079)\n",
      "[Train]Epoch: [0][3310/5093]\tLoss_sum:  0.209955( 0.466290)\tCls:  0.065961( 0.063418)\tBox:  0.107369( 0.046439)\tObj:  0.027551( 0.114712)\tRPN  0.009074( 0.241721)\n",
      "[Train]Epoch: [0][3320/5093]\tLoss_sum:  0.443535( 0.466055)\tCls:  0.072218( 0.063346)\tBox:  0.167261( 0.046505)\tObj:  0.014995( 0.114480)\tRPN  0.189061( 0.241724)\n",
      "[Train]Epoch: [0][3330/5093]\tLoss_sum:  0.528901( 0.465816)\tCls:  0.094040( 0.063410)\tBox:  0.252123( 0.046732)\tObj:  0.042399( 0.114246)\tRPN  0.140339( 0.241429)\n",
      "[Train]Epoch: [0][3340/5093]\tLoss_sum:  0.860335( 0.465489)\tCls:  0.028135( 0.063436)\tBox:  0.000220( 0.046971)\tObj:  0.279629( 0.114048)\tRPN  0.552351( 0.241033)\n",
      "[Train]Epoch: [0][3350/5093]\tLoss_sum:  0.359568( 0.465245)\tCls:  0.044536( 0.063362)\tBox:  0.053475( 0.046911)\tObj:  0.142324( 0.113981)\tRPN  0.119232( 0.240992)\n",
      "[Train]Epoch: [0][3360/5093]\tLoss_sum:  0.277031( 0.464675)\tCls:  0.098408( 0.063267)\tBox:  0.070893( 0.046864)\tObj:  0.053216( 0.113869)\tRPN  0.054514( 0.240675)\n",
      "[Train]Epoch: [0][3370/5093]\tLoss_sum:  0.213575( 0.464084)\tCls:  0.011946( 0.063240)\tBox:  0.006514( 0.046970)\tObj:  0.008027( 0.113648)\tRPN  0.187089( 0.240227)\n",
      "[Train]Epoch: [0][3380/5093]\tLoss_sum:  0.028802( 0.463327)\tCls:  0.000714( 0.063155)\tBox:  0.000000( 0.047002)\tObj:  0.010097( 0.113386)\tRPN  0.017991( 0.239784)\n",
      "[Train]Epoch: [0][3390/5093]\tLoss_sum:  0.033535( 0.462067)\tCls:  0.005929( 0.062974)\tBox:  0.000000( 0.046863)\tObj:  0.013561( 0.113092)\tRPN  0.014045( 0.239139)\n",
      "[Train]Epoch: [0][3400/5093]\tLoss_sum:  0.420398( 0.461599)\tCls:  0.067027( 0.062871)\tBox:  0.211270( 0.046849)\tObj:  0.028412( 0.112892)\tRPN  0.113689( 0.238988)\n",
      "[Train]Epoch: [0][3410/5093]\tLoss_sum:  0.161410( 0.460929)\tCls:  0.004097( 0.062798)\tBox:  0.000000( 0.046865)\tObj:  0.027467( 0.112660)\tRPN  0.129846( 0.238606)\n",
      "[Train]Epoch: [0][3420/5093]\tLoss_sum:  0.508467( 0.460538)\tCls:  0.055684( 0.062705)\tBox:  0.074773( 0.046833)\tObj:  0.100455( 0.112709)\tRPN  0.277555( 0.238291)\n",
      "[Train]Epoch: [0][3430/5093]\tLoss_sum:  0.225972( 0.460110)\tCls:  0.051795( 0.062698)\tBox:  0.107650( 0.046902)\tObj:  0.044208( 0.112654)\tRPN  0.022320( 0.237856)\n",
      "[Train]Epoch: [0][3440/5093]\tLoss_sum:  0.159089( 0.459599)\tCls:  0.000469( 0.062656)\tBox:  0.000000( 0.047001)\tObj:  0.018563( 0.112449)\tRPN  0.140057( 0.237494)\n",
      "[Train]Epoch: [0][3450/5093]\tLoss_sum:  0.334186( 0.459050)\tCls:  0.000653( 0.062551)\tBox:  0.000000( 0.047002)\tObj:  0.026472( 0.112238)\tRPN  0.307062( 0.237260)\n",
      "[Train]Epoch: [0][3460/5093]\tLoss_sum:  0.445354( 0.458496)\tCls:  0.111879( 0.062502)\tBox:  0.170867( 0.047016)\tObj:  0.035038( 0.111995)\tRPN  0.127570( 0.236983)\n",
      "[Train]Epoch: [0][3470/5093]\tLoss_sum:  0.510697( 0.458279)\tCls:  0.004711( 0.062589)\tBox:  0.000000( 0.047297)\tObj:  0.007022( 0.111753)\tRPN  0.498964( 0.236641)\n",
      "[Train]Epoch: [0][3480/5093]\tLoss_sum:  0.447103( 0.458819)\tCls:  0.061680( 0.062665)\tBox:  0.083620( 0.047412)\tObj:  0.027506( 0.111810)\tRPN  0.274297( 0.236932)\n",
      "[Train]Epoch: [0][3490/5093]\tLoss_sum:  0.386753( 0.458330)\tCls:  0.080326( 0.062681)\tBox:  0.103227( 0.047493)\tObj:  0.087141( 0.111703)\tRPN  0.116059( 0.236453)\n",
      "[Train]Epoch: [0][3500/5093]\tLoss_sum:  0.326103( 0.458075)\tCls:  0.086720( 0.062722)\tBox:  0.105626( 0.047698)\tObj:  0.099224( 0.111593)\tRPN  0.034533( 0.236062)\n",
      "[Train]Epoch: [0][3510/5093]\tLoss_sum:  0.170475( 0.457588)\tCls:  0.028844( 0.062692)\tBox:  0.063329( 0.047749)\tObj:  0.058584( 0.111438)\tRPN  0.019718( 0.235710)\n",
      "[Train]Epoch: [0][3520/5093]\tLoss_sum:  0.169839( 0.456636)\tCls:  0.013172( 0.062530)\tBox:  0.008539( 0.047628)\tObj:  0.032475( 0.111182)\tRPN  0.115653( 0.235297)\n",
      "[Train]Epoch: [0][3530/5093]\tLoss_sum:  0.085077( 0.456060)\tCls:  0.001762( 0.062463)\tBox:  0.000000( 0.047649)\tObj:  0.010086( 0.110979)\tRPN  0.073230( 0.234968)\n",
      "[Train]Epoch: [0][3540/5093]\tLoss_sum:  0.172180( 0.455419)\tCls:  0.062652( 0.062394)\tBox:  0.039684( 0.047689)\tObj:  0.017520( 0.110728)\tRPN  0.052325( 0.234608)\n",
      "[Train]Epoch: [0][3550/5093]\tLoss_sum:  0.277490( 0.455185)\tCls:  0.020487( 0.062473)\tBox:  0.092876( 0.047851)\tObj:  0.015216( 0.110509)\tRPN  0.148911( 0.234353)\n",
      "[Train]Epoch: [0][3560/5093]\tLoss_sum:  0.431619( 0.455112)\tCls:  0.000662( 0.062455)\tBox:  0.000000( 0.047983)\tObj:  0.024048( 0.110392)\tRPN  0.406909( 0.234283)\n",
      "[Train]Epoch: [0][3570/5093]\tLoss_sum:  0.069066( 0.454437)\tCls:  0.001414( 0.062287)\tBox:  0.000000( 0.047848)\tObj:  0.011877( 0.110197)\tRPN  0.055775( 0.234105)\n",
      "[Train]Epoch: [0][3580/5093]\tLoss_sum:  0.286250( 0.454107)\tCls:  0.073112( 0.062408)\tBox:  0.168320( 0.048032)\tObj:  0.041558( 0.110002)\tRPN  0.003261( 0.233665)\n",
      "[Train]Epoch: [0][3590/5093]\tLoss_sum:  0.298569( 0.453704)\tCls:  0.003787( 0.062424)\tBox:  0.000000( 0.048129)\tObj:  0.014786( 0.109788)\tRPN  0.279996( 0.233363)\n",
      "[Train]Epoch: [0][3600/5093]\tLoss_sum:  0.208876( 0.453157)\tCls:  0.043492( 0.062382)\tBox:  0.133368( 0.048201)\tObj:  0.002741( 0.109547)\tRPN  0.029276( 0.233027)\n",
      "[Train]Epoch: [0][3610/5093]\tLoss_sum:  0.080405( 0.452240)\tCls:  0.001490( 0.062250)\tBox:  0.000000( 0.048155)\tObj:  0.006301( 0.109281)\tRPN  0.072614( 0.232553)\n",
      "[Train]Epoch: [0][3620/5093]\tLoss_sum:  0.050559( 0.451538)\tCls:  0.000439( 0.062214)\tBox:  0.000000( 0.048216)\tObj:  0.005958( 0.109037)\tRPN  0.044162( 0.232071)\n",
      "[Train]Epoch: [0][3630/5093]\tLoss_sum:  0.337985( 0.451116)\tCls:  0.069938( 0.062211)\tBox:  0.155313( 0.048413)\tObj:  0.026839( 0.108798)\tRPN  0.085895( 0.231693)\n",
      "[Train]Epoch: [0][3640/5093]\tLoss_sum:  0.416489( 0.450806)\tCls:  0.124858( 0.062236)\tBox:  0.241168( 0.048698)\tObj:  0.008570( 0.108596)\tRPN  0.041894( 0.231275)\n",
      "[Train]Epoch: [0][3650/5093]\tLoss_sum:  0.108395( 0.449896)\tCls:  0.023471( 0.062126)\tBox:  0.030422( 0.048649)\tObj:  0.020543( 0.108379)\tRPN  0.033960( 0.230742)\n",
      "[Train]Epoch: [0][3660/5093]\tLoss_sum:  0.028470( 0.449115)\tCls:  0.003889( 0.062136)\tBox:  0.000000( 0.048634)\tObj:  0.004155( 0.108157)\tRPN  0.020427( 0.230187)\n",
      "[Train]Epoch: [0][3670/5093]\tLoss_sum:  0.012142( 0.448505)\tCls:  0.001002( 0.062086)\tBox:  0.000000( 0.048816)\tObj:  0.003410( 0.107924)\tRPN  0.007729( 0.229679)\n",
      "[Train]Epoch: [0][3680/5093]\tLoss_sum:  0.045410( 0.447486)\tCls:  0.001831( 0.061951)\tBox:  0.000000( 0.048758)\tObj:  0.025313( 0.107668)\tRPN  0.018267( 0.229109)\n",
      "[Train]Epoch: [0][3690/5093]\tLoss_sum:  0.400759( 0.446945)\tCls:  0.161262( 0.061955)\tBox:  0.171879( 0.048855)\tObj:  0.027682( 0.107442)\tRPN  0.039936( 0.228693)\n",
      "[Train]Epoch: [0][3700/5093]\tLoss_sum:  0.370988( 0.446863)\tCls:  0.073383( 0.061972)\tBox:  0.199102( 0.048974)\tObj:  0.039763( 0.107419)\tRPN  0.058740( 0.228498)\n",
      "[Train]Epoch: [0][3710/5093]\tLoss_sum:  0.360520( 0.446835)\tCls:  0.061286( 0.061953)\tBox:  0.090929( 0.048959)\tObj:  0.050090( 0.107375)\tRPN  0.158216( 0.228548)\n",
      "[Train]Epoch: [0][3720/5093]\tLoss_sum:  0.058344( 0.446176)\tCls:  0.000659( 0.061867)\tBox:  0.000000( 0.048954)\tObj:  0.029207( 0.107196)\tRPN  0.028478( 0.228159)\n",
      "[Train]Epoch: [0][3730/5093]\tLoss_sum:  0.236910( 0.445666)\tCls:  0.085041( 0.061833)\tBox:  0.086545( 0.048961)\tObj:  0.014464( 0.107007)\tRPN  0.050860( 0.227865)\n",
      "[Train]Epoch: [0][3740/5093]\tLoss_sum:  0.114272( 0.445482)\tCls:  0.000952( 0.062028)\tBox:  0.000000( 0.049239)\tObj:  0.010173( 0.106776)\tRPN  0.103147( 0.227439)\n",
      "[Train]Epoch: [0][3750/5093]\tLoss_sum:  0.028474( 0.444883)\tCls:  0.002874( 0.061973)\tBox:  0.000000( 0.049273)\tObj:  0.010781( 0.106585)\tRPN  0.014819( 0.227052)\n",
      "[Train]Epoch: [0][3760/5093]\tLoss_sum:  0.225713( 0.444027)\tCls:  0.070810( 0.061873)\tBox:  0.082988( 0.049212)\tObj:  0.022884( 0.106348)\tRPN  0.049031( 0.226593)\n",
      "[Train]Epoch: [0][3770/5093]\tLoss_sum:  0.058600( 0.443656)\tCls:  0.001537( 0.061896)\tBox:  0.000000( 0.049352)\tObj:  0.016790( 0.106179)\tRPN  0.040273( 0.226228)\n",
      "[Train]Epoch: [0][3780/5093]\tLoss_sum:  0.125373( 0.443142)\tCls:  0.002742( 0.061846)\tBox:  0.000000( 0.049404)\tObj:  0.007681( 0.105978)\tRPN  0.114950( 0.225914)\n",
      "[Train]Epoch: [0][3790/5093]\tLoss_sum:  0.533868( 0.442544)\tCls:  0.168187( 0.061814)\tBox:  0.208681( 0.049426)\tObj:  0.023618( 0.105770)\tRPN  0.133383( 0.225534)\n",
      "[Train]Epoch: [0][3800/5093]\tLoss_sum:  0.107750( 0.441907)\tCls:  0.003295( 0.061705)\tBox:  0.000000( 0.049416)\tObj:  0.012665( 0.105545)\tRPN  0.091791( 0.225241)\n",
      "[Train]Epoch: [0][3810/5093]\tLoss_sum:  0.409008( 0.441524)\tCls:  0.111181( 0.061708)\tBox:  0.111817( 0.049443)\tObj:  0.032045( 0.105419)\tRPN  0.153966( 0.224954)\n",
      "[Train]Epoch: [0][3820/5093]\tLoss_sum:  0.244867( 0.441492)\tCls:  0.028693( 0.061776)\tBox:  0.000000( 0.049627)\tObj:  0.055783( 0.105317)\tRPN  0.160391( 0.224773)\n",
      "[Train]Epoch: [0][3830/5093]\tLoss_sum:  0.672227( 0.441297)\tCls:  0.095445( 0.061810)\tBox:  0.023402( 0.049816)\tObj:  0.119083( 0.105182)\tRPN  0.434296( 0.224490)\n",
      "[Train]Epoch: [0][3840/5093]\tLoss_sum:  0.301255( 0.440942)\tCls:  0.068213( 0.061793)\tBox:  0.100237( 0.049877)\tObj:  0.021578( 0.105023)\tRPN  0.111227( 0.224248)\n",
      "[Train]Epoch: [0][3850/5093]\tLoss_sum:  0.069752( 0.440486)\tCls:  0.010777( 0.061751)\tBox:  0.000000( 0.050016)\tObj:  0.013884( 0.104841)\tRPN  0.045090( 0.223878)\n",
      "[Train]Epoch: [0][3860/5093]\tLoss_sum:  0.256313( 0.440214)\tCls:  0.048991( 0.061780)\tBox:  0.182099( 0.050177)\tObj:  0.010733( 0.104669)\tRPN  0.014490( 0.223588)\n",
      "[Train]Epoch: [0][3870/5093]\tLoss_sum:  0.178258( 0.439732)\tCls:  0.037837( 0.061710)\tBox:  0.037831( 0.050154)\tObj:  0.010608( 0.104459)\tRPN  0.091982( 0.223409)\n",
      "[Train]Epoch: [0][3880/5093]\tLoss_sum:  0.158247( 0.439426)\tCls:  0.023393( 0.061693)\tBox:  0.041527( 0.050326)\tObj:  0.023760( 0.104250)\tRPN  0.069567( 0.223156)\n",
      "[Train]Epoch: [0][3890/5093]\tLoss_sum:  0.065723( 0.439230)\tCls:  0.022956( 0.061736)\tBox:  0.022722( 0.050445)\tObj:  0.017264( 0.104054)\tRPN  0.002781( 0.222995)\n",
      "[Train]Epoch: [0][3900/5093]\tLoss_sum:  0.342011( 0.438895)\tCls:  0.054216( 0.061769)\tBox:  0.162285( 0.050619)\tObj:  0.025943( 0.103842)\tRPN  0.099566( 0.222665)\n",
      "[Train]Epoch: [0][3910/5093]\tLoss_sum:  0.083165( 0.438526)\tCls:  0.003994( 0.061685)\tBox:  0.000000( 0.050717)\tObj:  0.023672( 0.103829)\tRPN  0.055498( 0.222295)\n",
      "[Train]Epoch: [0][3920/5093]\tLoss_sum:  0.176551( 0.438124)\tCls:  0.002315( 0.061665)\tBox:  0.000000( 0.050788)\tObj:  0.048402( 0.103675)\tRPN  0.125834( 0.221996)\n",
      "[Train]Epoch: [0][3930/5093]\tLoss_sum:  0.714515( 0.437342)\tCls:  0.024290( 0.061518)\tBox:  0.000048( 0.050659)\tObj:  0.558199( 0.103602)\tRPN  0.131978( 0.221564)\n",
      "[Train]Epoch: [0][3940/5093]\tLoss_sum:  0.097521( 0.437057)\tCls:  0.000684( 0.061522)\tBox:  0.000000( 0.050832)\tObj:  0.010824( 0.103425)\tRPN  0.086013( 0.221279)\n",
      "[Train]Epoch: [0][3950/5093]\tLoss_sum:  0.052024( 0.436121)\tCls:  0.001194( 0.061372)\tBox:  0.000000( 0.050703)\tObj:  0.005489( 0.103193)\tRPN  0.045341( 0.220854)\n",
      "[Train]Epoch: [0][3960/5093]\tLoss_sum:  0.320107( 0.435174)\tCls:  0.063244( 0.061234)\tBox:  0.116093( 0.050605)\tObj:  0.037045( 0.102970)\tRPN  0.103725( 0.220365)\n",
      "[Train]Epoch: [0][3970/5093]\tLoss_sum:  0.320901( 0.434633)\tCls:  0.076436( 0.061189)\tBox:  0.146387( 0.050672)\tObj:  0.036037( 0.102771)\tRPN  0.062041( 0.220001)\n",
      "[Train]Epoch: [0][3980/5093]\tLoss_sum:  0.242106( 0.434129)\tCls:  0.052059( 0.061129)\tBox:  0.080575( 0.050683)\tObj:  0.037344( 0.102568)\tRPN  0.072128( 0.219749)\n",
      "[Train]Epoch: [0][3990/5093]\tLoss_sum:  0.179318( 0.433681)\tCls:  0.000250( 0.061061)\tBox:  0.000000( 0.050716)\tObj:  0.005090( 0.102357)\tRPN  0.173978( 0.219547)\n",
      "[Train]Epoch: [0][4000/5093]\tLoss_sum:  0.206548( 0.433251)\tCls:  0.053811( 0.061074)\tBox:  0.139370( 0.050825)\tObj:  0.005599( 0.102136)\tRPN  0.007768( 0.219217)\n",
      "[Train]Epoch: [0][4010/5093]\tLoss_sum:  0.324487( 0.433084)\tCls:  0.072083( 0.061046)\tBox:  0.170112( 0.050920)\tObj:  0.075331( 0.102156)\tRPN  0.006960( 0.218962)\n",
      "[Train]Epoch: [0][4020/5093]\tLoss_sum:  0.258173( 0.432794)\tCls:  0.073179( 0.061023)\tBox:  0.105446( 0.050947)\tObj:  0.034331( 0.102025)\tRPN  0.045218( 0.218799)\n",
      "[Train]Epoch: [0][4030/5093]\tLoss_sum:  0.206085( 0.432482)\tCls:  0.001164( 0.061061)\tBox:  0.000000( 0.051035)\tObj:  0.028152( 0.101848)\tRPN  0.176769( 0.218537)\n",
      "[Train]Epoch: [0][4040/5093]\tLoss_sum:  0.287113( 0.432102)\tCls:  0.064026( 0.061049)\tBox:  0.185486( 0.051126)\tObj:  0.021634( 0.101666)\tRPN  0.015966( 0.218261)\n",
      "[Train]Epoch: [0][4050/5093]\tLoss_sum:  0.490425( 0.431980)\tCls:  0.136865( 0.061111)\tBox:  0.180924( 0.051293)\tObj:  0.016109( 0.101479)\tRPN  0.156527( 0.218097)\n",
      "[Train]Epoch: [0][4060/5093]\tLoss_sum:  0.690498( 0.432077)\tCls:  0.000306( 0.061118)\tBox:  0.000000( 0.051433)\tObj:  0.001957( 0.101276)\tRPN  0.688235( 0.218249)\n",
      "[Train]Epoch: [0][4070/5093]\tLoss_sum:  0.134273( 0.431743)\tCls:  0.011151( 0.060972)\tBox:  0.016277( 0.051311)\tObj:  0.020217( 0.101061)\tRPN  0.086628( 0.218400)\n",
      "[Train]Epoch: [0][4080/5093]\tLoss_sum:  0.045506( 0.431364)\tCls:  0.001031( 0.060880)\tBox:  0.000000( 0.051278)\tObj:  0.004272( 0.101121)\tRPN  0.040204( 0.218085)\n",
      "[Train]Epoch: [0][4090/5093]\tLoss_sum:  0.191102( 0.430722)\tCls:  0.061304( 0.060799)\tBox:  0.084299( 0.051275)\tObj:  0.010401( 0.100913)\tRPN  0.035098( 0.217735)\n",
      "[Train]Epoch: [0][4100/5093]\tLoss_sum:  0.446545( 0.430354)\tCls:  0.068012( 0.060725)\tBox:  0.153744( 0.051252)\tObj:  0.022072( 0.100742)\tRPN  0.202718( 0.217635)\n",
      "[Train]Epoch: [0][4110/5093]\tLoss_sum:  0.231750( 0.429853)\tCls:  0.072780( 0.060633)\tBox:  0.084327( 0.051198)\tObj:  0.035019( 0.100547)\tRPN  0.039625( 0.217475)\n",
      "[Train]Epoch: [0][4120/5093]\tLoss_sum:  0.216481( 0.429250)\tCls:  0.043597( 0.060589)\tBox:  0.118782( 0.051231)\tObj:  0.023575( 0.100401)\tRPN  0.030527( 0.217030)\n",
      "[Train]Epoch: [0][4130/5093]\tLoss_sum:  0.210041( 0.428808)\tCls:  0.027336( 0.060558)\tBox:  0.088410( 0.051305)\tObj:  0.026854( 0.100247)\tRPN  0.067441( 0.216697)\n",
      "[Train]Epoch: [0][4140/5093]\tLoss_sum:  0.139969( 0.428318)\tCls:  0.000745( 0.060473)\tBox:  0.000000( 0.051286)\tObj:  0.009193( 0.100059)\tRPN  0.130031( 0.216501)\n",
      "[Train]Epoch: [0][4150/5093]\tLoss_sum:  0.521716( 0.428105)\tCls:  0.141620( 0.060487)\tBox:  0.144670( 0.051368)\tObj:  0.057916( 0.099901)\tRPN  0.177510( 0.216350)\n",
      "[Train]Epoch: [0][4160/5093]\tLoss_sum:  0.262185( 0.427858)\tCls:  0.011333( 0.060509)\tBox:  0.000000( 0.051484)\tObj:  0.045210( 0.099765)\tRPN  0.205642( 0.216099)\n",
      "[Train]Epoch: [0][4170/5093]\tLoss_sum:  0.313094( 0.427351)\tCls:  0.094352( 0.060494)\tBox:  0.068012( 0.051468)\tObj:  0.106400( 0.099614)\tRPN  0.044331( 0.215775)\n",
      "[Train]Epoch: [0][4180/5093]\tLoss_sum:  0.053808( 0.426644)\tCls:  0.000382( 0.060375)\tBox:  0.000000( 0.051388)\tObj:  0.018393( 0.099457)\tRPN  0.035033( 0.215424)\n",
      "[Train]Epoch: [0][4190/5093]\tLoss_sum:  0.181980( 0.426089)\tCls:  0.062609( 0.060311)\tBox:  0.089637( 0.051369)\tObj:  0.012788( 0.099285)\tRPN  0.016946( 0.215123)\n",
      "[Train]Epoch: [0][4200/5093]\tLoss_sum:  0.580138( 0.425809)\tCls:  0.097516( 0.060300)\tBox:  0.212716( 0.051483)\tObj:  0.031316( 0.099107)\tRPN  0.238591( 0.214920)\n",
      "[Train]Epoch: [0][4210/5093]\tLoss_sum:  0.297750( 0.425186)\tCls:  0.047473( 0.060218)\tBox:  0.130017( 0.051474)\tObj:  0.007665( 0.098915)\tRPN  0.112595( 0.214579)\n",
      "[Train]Epoch: [0][4220/5093]\tLoss_sum:  0.654829( 0.424917)\tCls:  0.135419( 0.060212)\tBox:  0.235585( 0.051591)\tObj:  0.053196( 0.098750)\tRPN  0.230629( 0.214364)\n",
      "[Train]Epoch: [0][4230/5093]\tLoss_sum:  0.554447( 0.425423)\tCls:  0.096170( 0.060388)\tBox:  0.277209( 0.052106)\tObj:  0.043190( 0.098624)\tRPN  0.137878( 0.214306)\n",
      "[Train]Epoch: [0][4240/5093]\tLoss_sum:  0.272392( 0.425184)\tCls:  0.036751( 0.060443)\tBox:  0.042049( 0.052264)\tObj:  0.045378( 0.098461)\tRPN  0.148214( 0.214016)\n",
      "[Train]Epoch: [0][4250/5093]\tLoss_sum:  0.034985( 0.424665)\tCls:  0.000974( 0.060394)\tBox:  0.000000( 0.052298)\tObj:  0.010804( 0.098292)\tRPN  0.023207( 0.213681)\n",
      "[Train]Epoch: [0][4260/5093]\tLoss_sum:  0.187197( 0.424163)\tCls:  0.056320( 0.060374)\tBox:  0.089454( 0.052300)\tObj:  0.005436( 0.098108)\tRPN  0.035987( 0.213381)\n",
      "[Train]Epoch: [0][4270/5093]\tLoss_sum:  0.270970( 0.423645)\tCls:  0.056670( 0.060379)\tBox:  0.142472( 0.052394)\tObj:  0.036670( 0.097917)\tRPN  0.035158( 0.212955)\n",
      "[Train]Epoch: [0][4280/5093]\tLoss_sum:  0.596951( 0.423617)\tCls:  0.261623( 0.060459)\tBox:  0.299414( 0.052548)\tObj:  0.028975( 0.097776)\tRPN  0.006939( 0.212833)\n",
      "[Train]Epoch: [0][4290/5093]\tLoss_sum:  0.156492( 0.423179)\tCls:  0.000553( 0.060410)\tBox:  0.000000( 0.052584)\tObj:  0.006522( 0.097573)\tRPN  0.149417( 0.212612)\n",
      "[Train]Epoch: [0][4300/5093]\tLoss_sum:  0.337582( 0.423184)\tCls:  0.157658( 0.060572)\tBox:  0.121818( 0.052734)\tObj:  0.038024( 0.097544)\tRPN  0.020081( 0.212334)\n",
      "[Train]Epoch: [0][4310/5093]\tLoss_sum:  0.164528( 0.422656)\tCls:  0.019655( 0.060546)\tBox:  0.000000( 0.052688)\tObj:  0.033467( 0.097365)\tRPN  0.111406( 0.212057)\n",
      "[Train]Epoch: [0][4320/5093]\tLoss_sum:  0.410107( 0.422553)\tCls:  0.160252( 0.060667)\tBox:  0.209759( 0.052775)\tObj:  0.010796( 0.097240)\tRPN  0.029300( 0.211872)\n",
      "[Train]Epoch: [0][4330/5093]\tLoss_sum:  0.781648( 0.422905)\tCls:  0.201070( 0.060870)\tBox:  0.291454( 0.053002)\tObj:  0.100994( 0.097144)\tRPN  0.188130( 0.211889)\n",
      "[Train]Epoch: [0][4340/5093]\tLoss_sum:  0.272448( 0.422882)\tCls:  0.004216( 0.060945)\tBox:  0.000000( 0.053163)\tObj:  0.013919( 0.097027)\tRPN  0.254313( 0.211747)\n",
      "[Train]Epoch: [0][4350/5093]\tLoss_sum:  0.370299( 0.422890)\tCls:  0.082314( 0.061003)\tBox:  0.226418( 0.053304)\tObj:  0.056336( 0.096941)\tRPN  0.005232( 0.211641)\n",
      "[Train]Epoch: [0][4360/5093]\tLoss_sum:  0.223837( 0.422396)\tCls:  0.005015( 0.060876)\tBox:  0.000000( 0.053197)\tObj:  0.026987( 0.096784)\tRPN  0.191834( 0.211539)\n",
      "[Train]Epoch: [0][4370/5093]\tLoss_sum:  0.191905( 0.422397)\tCls:  0.054657( 0.061042)\tBox:  0.128888( 0.053416)\tObj:  0.004123( 0.096662)\tRPN  0.004236( 0.211277)\n",
      "[Train]Epoch: [0][4380/5093]\tLoss_sum:  0.068097( 0.421658)\tCls:  0.001513( 0.060929)\tBox:  0.000000( 0.053335)\tObj:  0.010484( 0.096471)\tRPN  0.056100( 0.210924)\n",
      "[Train]Epoch: [0][4390/5093]\tLoss_sum:  0.439085( 0.421333)\tCls:  0.134694( 0.060922)\tBox:  0.077275( 0.053350)\tObj:  0.130261( 0.096331)\tRPN  0.096856( 0.210729)\n",
      "[Train]Epoch: [0][4400/5093]\tLoss_sum:  0.218507( 0.421151)\tCls:  0.013711( 0.060938)\tBox:  0.000000( 0.053404)\tObj:  0.022625( 0.096337)\tRPN  0.182171( 0.210471)\n",
      "[Train]Epoch: [0][4410/5093]\tLoss_sum:  0.088559( 0.420473)\tCls:  0.001568( 0.060814)\tBox:  0.000000( 0.053283)\tObj:  0.030513( 0.096221)\tRPN  0.056479( 0.210155)\n",
      "[Train]Epoch: [0][4420/5093]\tLoss_sum:  0.087006( 0.420058)\tCls:  0.004727( 0.060807)\tBox:  0.000000( 0.053287)\tObj:  0.007757( 0.096077)\tRPN  0.074521( 0.209887)\n",
      "[Train]Epoch: [0][4430/5093]\tLoss_sum:  0.088456( 0.419265)\tCls:  0.004388( 0.060674)\tBox:  0.000000( 0.053167)\tObj:  0.029813( 0.095897)\tRPN  0.054255( 0.209527)\n",
      "[Train]Epoch: [0][4440/5093]\tLoss_sum:  0.092509( 0.419382)\tCls:  0.001203( 0.060774)\tBox:  0.000000( 0.053384)\tObj:  0.007360( 0.095848)\tRPN  0.083946( 0.209375)\n",
      "[Train]Epoch: [0][4450/5093]\tLoss_sum:  0.393024( 0.419092)\tCls:  0.083741( 0.060773)\tBox:  0.114736( 0.053434)\tObj:  0.081571( 0.095735)\tRPN  0.112976( 0.209149)\n",
      "[Train]Epoch: [0][4460/5093]\tLoss_sum:  0.240378( 0.418685)\tCls:  0.046497( 0.060761)\tBox:  0.114512( 0.053481)\tObj:  0.023649( 0.095648)\tRPN  0.055720( 0.208796)\n",
      "[Train]Epoch: [0][4470/5093]\tLoss_sum:  0.024744( 0.417877)\tCls:  0.000695( 0.060640)\tBox:  0.000000( 0.053406)\tObj:  0.013317( 0.095477)\tRPN  0.010733( 0.208354)\n",
      "[Train]Epoch: [0][4480/5093]\tLoss_sum:  0.015983( 0.417128)\tCls:  0.000314( 0.060537)\tBox:  0.000000( 0.053353)\tObj:  0.010244( 0.095306)\tRPN  0.005425( 0.207932)\n",
      "[Train]Epoch: [0][4490/5093]\tLoss_sum:  0.112073( 0.416278)\tCls:  0.016416( 0.060418)\tBox:  0.040843( 0.053252)\tObj:  0.035224( 0.095121)\tRPN  0.019590( 0.207487)\n",
      "[Train]Epoch: [0][4500/5093]\tLoss_sum:  0.022669( 0.415821)\tCls:  0.000794( 0.060411)\tBox:  0.000000( 0.053292)\tObj:  0.016468( 0.095041)\tRPN  0.005407( 0.207077)\n",
      "[Train]Epoch: [0][4510/5093]\tLoss_sum:  0.015108( 0.415160)\tCls:  0.003832( 0.060349)\tBox:  0.000000( 0.053256)\tObj:  0.006962( 0.094899)\tRPN  0.004315( 0.206656)\n",
      "[Train]Epoch: [0][4520/5093]\tLoss_sum:  0.393404( 0.414896)\tCls:  0.163192( 0.060397)\tBox:  0.168044( 0.053286)\tObj:  0.047565( 0.094789)\tRPN  0.014603( 0.206424)\n",
      "[Train]Epoch: [0][4530/5093]\tLoss_sum:  0.150195( 0.414439)\tCls:  0.013019( 0.060361)\tBox:  0.000000( 0.053285)\tObj:  0.020335( 0.094641)\tRPN  0.116840( 0.206152)\n",
      "[Train]Epoch: [0][4540/5093]\tLoss_sum:  0.078628( 0.414038)\tCls:  0.005969( 0.060317)\tBox:  0.000000( 0.053302)\tObj:  0.027982( 0.094524)\tRPN  0.044677( 0.205894)\n",
      "[Train]Epoch: [0][4550/5093]\tLoss_sum:  0.310681( 0.413415)\tCls:  0.038959( 0.060217)\tBox:  0.064444( 0.053232)\tObj:  0.029838( 0.094360)\tRPN  0.177440( 0.205607)\n",
      "[Train]Epoch: [0][4560/5093]\tLoss_sum:  0.115982( 0.412918)\tCls:  0.000397( 0.060146)\tBox:  0.000000( 0.053228)\tObj:  0.005111( 0.094183)\tRPN  0.110474( 0.205361)\n",
      "[Train]Epoch: [0][4570/5093]\tLoss_sum:  0.033474( 0.412145)\tCls:  0.013190( 0.060020)\tBox:  0.000000( 0.053111)\tObj:  0.004883( 0.094010)\tRPN  0.015401( 0.205005)\n",
      "[Train]Epoch: [0][4580/5093]\tLoss_sum:  0.408544( 0.411859)\tCls:  0.100678( 0.060016)\tBox:  0.164969( 0.053154)\tObj:  0.013175( 0.093964)\tRPN  0.129722( 0.204725)\n",
      "[Train]Epoch: [0][4590/5093]\tLoss_sum:  0.299049( 0.411605)\tCls:  0.036835( 0.060025)\tBox:  0.125048( 0.053286)\tObj:  0.045410( 0.093833)\tRPN  0.091756( 0.204460)\n",
      "[Train]Epoch: [0][4600/5093]\tLoss_sum:  0.224280( 0.411323)\tCls:  0.055768( 0.060022)\tBox:  0.033973( 0.053419)\tObj:  0.023406( 0.093710)\tRPN  0.111132( 0.204172)\n",
      "[Train]Epoch: [0][4610/5093]\tLoss_sum:  0.403093( 0.411111)\tCls:  0.055214( 0.060024)\tBox:  0.114426( 0.053556)\tObj:  0.094114( 0.093576)\tRPN  0.139339( 0.203955)\n",
      "[Train]Epoch: [0][4620/5093]\tLoss_sum:  0.294475( 0.410894)\tCls:  0.048379( 0.060040)\tBox:  0.102162( 0.053669)\tObj:  0.009814( 0.093439)\tRPN  0.134120( 0.203746)\n",
      "[Train]Epoch: [0][4630/5093]\tLoss_sum:  0.260429( 0.410498)\tCls:  0.040722( 0.060006)\tBox:  0.084765( 0.053710)\tObj:  0.018707( 0.093285)\tRPN  0.116235( 0.203497)\n",
      "[Train]Epoch: [0][4640/5093]\tLoss_sum:  0.224591( 0.410181)\tCls:  0.056479( 0.060034)\tBox:  0.074841( 0.053762)\tObj:  0.025746( 0.093160)\tRPN  0.067525( 0.203224)\n",
      "[Train]Epoch: [0][4650/5093]\tLoss_sum:  0.462642( 0.409859)\tCls:  0.014820( 0.060002)\tBox:  0.001291( 0.053726)\tObj:  0.025945( 0.093015)\tRPN  0.420585( 0.203116)\n",
      "[Train]Epoch: [0][4660/5093]\tLoss_sum:  0.803128( 0.409705)\tCls:  0.129938( 0.059981)\tBox:  0.236112( 0.053761)\tObj:  0.082072( 0.092874)\tRPN  0.355006( 0.203089)\n",
      "[Train]Epoch: [0][4670/5093]\tLoss_sum:  0.590568( 0.409793)\tCls:  0.144430( 0.060077)\tBox:  0.241777( 0.053964)\tObj:  0.062625( 0.092764)\tRPN  0.141736( 0.202989)\n",
      "[Train]Epoch: [0][4680/5093]\tLoss_sum:  0.338047( 0.410134)\tCls:  0.084235( 0.060344)\tBox:  0.124474( 0.054345)\tObj:  0.011463( 0.092618)\tRPN  0.117875( 0.202826)\n",
      "[Train]Epoch: [0][4690/5093]\tLoss_sum:  0.292154( 0.409764)\tCls:  0.086012( 0.060351)\tBox:  0.169090( 0.054449)\tObj:  0.030888( 0.092471)\tRPN  0.006164( 0.202493)\n",
      "[Train]Epoch: [0][4700/5093]\tLoss_sum:  0.422654( 0.409654)\tCls:  0.056264( 0.060243)\tBox:  0.020439( 0.054346)\tObj:  0.011917( 0.092306)\tRPN  0.334033( 0.202760)\n",
      "[Train]Epoch: [0][4710/5093]\tLoss_sum:  0.232391( 0.409619)\tCls:  0.059392( 0.060326)\tBox:  0.139107( 0.054435)\tObj:  0.029671( 0.092172)\tRPN  0.004220( 0.202686)\n",
      "[Train]Epoch: [0][4720/5093]\tLoss_sum:  0.467144( 0.409129)\tCls:  0.010421( 0.060211)\tBox:  0.001374( 0.054321)\tObj:  0.098379( 0.092021)\tRPN  0.356970( 0.202576)\n",
      "[Train]Epoch: [0][4730/5093]\tLoss_sum:  0.466998( 0.409205)\tCls:  0.000767( 0.060185)\tBox:  0.000000( 0.054390)\tObj:  0.002122( 0.091880)\tRPN  0.464110( 0.202750)\n",
      "[Train]Epoch: [0][4740/5093]\tLoss_sum:  0.142169( 0.408966)\tCls:  0.002421( 0.060108)\tBox:  0.000000( 0.054375)\tObj:  0.024926( 0.091790)\tRPN  0.114822( 0.202694)\n",
      "[Train]Epoch: [0][4750/5093]\tLoss_sum:  0.174066( 0.408349)\tCls:  0.016763( 0.059997)\tBox:  0.022481( 0.054284)\tObj:  0.032596( 0.091647)\tRPN  0.102226( 0.202421)\n",
      "[Train]Epoch: [0][4760/5093]\tLoss_sum:  0.096149( 0.407961)\tCls:  0.001203( 0.059912)\tBox:  0.000000( 0.054235)\tObj:  0.005113( 0.091500)\tRPN  0.089834( 0.202314)\n",
      "[Train]Epoch: [0][4770/5093]\tLoss_sum:  0.347938( 0.407587)\tCls:  0.063845( 0.059846)\tBox:  0.078003( 0.054186)\tObj:  0.034442( 0.091371)\tRPN  0.171647( 0.202184)\n",
      "[Train]Epoch: [0][4780/5093]\tLoss_sum:  0.320241( 0.407109)\tCls:  0.075895( 0.059788)\tBox:  0.118763( 0.054159)\tObj:  0.011395( 0.091218)\tRPN  0.114188( 0.201944)\n",
      "[Train]Epoch: [0][4790/5093]\tLoss_sum:  0.604076( 0.406918)\tCls:  0.105290( 0.059799)\tBox:  0.189659( 0.054227)\tObj:  0.031912( 0.091072)\tRPN  0.277214( 0.201820)\n",
      "[Train]Epoch: [0][4800/5093]\tLoss_sum:  0.292240( 0.407006)\tCls:  0.019445( 0.059829)\tBox:  0.001646( 0.054356)\tObj:  0.041047( 0.090970)\tRPN  0.230102( 0.201851)\n",
      "[Train]Epoch: [0][4810/5093]\tLoss_sum:  0.148676( 0.406666)\tCls:  0.008273( 0.059761)\tBox:  0.015891( 0.054358)\tObj:  0.017665( 0.090827)\tRPN  0.106848( 0.201720)\n",
      "[Train]Epoch: [0][4820/5093]\tLoss_sum:  0.291022( 0.406206)\tCls:  0.053794( 0.059676)\tBox:  0.121382( 0.054310)\tObj:  0.036478( 0.090699)\tRPN  0.079369( 0.201521)\n",
      "[Train]Epoch: [0][4830/5093]\tLoss_sum:  0.179808( 0.405978)\tCls:  0.039312( 0.059648)\tBox:  0.081185( 0.054347)\tObj:  0.006817( 0.090565)\tRPN  0.052494( 0.201419)\n",
      "[Train]Epoch: [0][4840/5093]\tLoss_sum:  0.058448( 0.405612)\tCls:  0.004059( 0.059619)\tBox:  0.000000( 0.054371)\tObj:  0.020242( 0.090442)\tRPN  0.034148( 0.201180)\n",
      "[Train]Epoch: [0][4850/5093]\tLoss_sum:  0.275893( 0.405144)\tCls:  0.099440( 0.059624)\tBox:  0.120758( 0.054379)\tObj:  0.054276( 0.090303)\tRPN  0.001419( 0.200839)\n",
      "[Train]Epoch: [0][4860/5093]\tLoss_sum:  0.243169( 0.404613)\tCls:  0.020990( 0.059537)\tBox:  0.029358( 0.054308)\tObj:  0.045122( 0.090150)\tRPN  0.147699( 0.200618)\n",
      "[Train]Epoch: [0][4870/5093]\tLoss_sum:  0.833791( 0.404741)\tCls:  0.139201( 0.059662)\tBox:  0.202625( 0.054472)\tObj:  0.179806( 0.090043)\tRPN  0.312160( 0.200565)\n",
      "[Train]Epoch: [0][4880/5093]\tLoss_sum:  0.045430( 0.404195)\tCls:  0.014161( 0.059604)\tBox:  0.000000( 0.054413)\tObj:  0.013068( 0.089899)\tRPN  0.018200( 0.200279)\n",
      "[Train]Epoch: [0][4890/5093]\tLoss_sum:  0.310926( 0.404448)\tCls:  0.000420( 0.059607)\tBox:  0.000000( 0.054449)\tObj:  0.007436( 0.089781)\tRPN  0.303070( 0.200612)\n",
      "[Train]Epoch: [0][4900/5093]\tLoss_sum:  0.083722( 0.403921)\tCls:  0.000649( 0.059488)\tBox:  0.000000( 0.054338)\tObj:  0.033506( 0.089619)\tRPN  0.049567( 0.200477)\n",
      "[Train]Epoch: [0][4910/5093]\tLoss_sum:  0.056124( 0.403460)\tCls:  0.000734( 0.059417)\tBox:  0.000000( 0.054302)\tObj:  0.031003( 0.089479)\tRPN  0.024387( 0.200262)\n",
      "[Train]Epoch: [0][4920/5093]\tLoss_sum:  0.039364( 0.403278)\tCls:  0.000652( 0.059442)\tBox:  0.000000( 0.054384)\tObj:  0.005381( 0.089402)\tRPN  0.033332( 0.200050)\n",
      "[Train]Epoch: [0][4930/5093]\tLoss_sum:  0.344312( 0.403214)\tCls:  0.136432( 0.059548)\tBox:  0.123723( 0.054519)\tObj:  0.077848( 0.089299)\tRPN  0.006308( 0.199847)\n",
      "[Train]Epoch: [0][4940/5093]\tLoss_sum:  0.580334( 0.402776)\tCls:  0.140881( 0.059514)\tBox:  0.048342( 0.054525)\tObj:  0.155481( 0.089191)\tRPN  0.235630( 0.199546)\n",
      "[Train]Epoch: [0][4950/5093]\tLoss_sum:  0.446264( 0.402941)\tCls:  0.166913( 0.059687)\tBox:  0.159301( 0.054748)\tObj:  0.020041( 0.089127)\tRPN  0.100009( 0.199378)\n",
      "[Train]Epoch: [0][4960/5093]\tLoss_sum:  0.049414( 0.402637)\tCls:  0.004517( 0.059693)\tBox:  0.000000( 0.054848)\tObj:  0.012441( 0.089018)\tRPN  0.032456( 0.199078)\n",
      "[Train]Epoch: [0][4970/5093]\tLoss_sum:  0.453617( 0.402440)\tCls:  0.138504( 0.059702)\tBox:  0.273503( 0.054949)\tObj:  0.009914( 0.088905)\tRPN  0.031697( 0.198884)\n",
      "[Train]Epoch: [0][4980/5093]\tLoss_sum:  0.076325( 0.401943)\tCls:  0.011088( 0.059655)\tBox:  0.000000( 0.054894)\tObj:  0.008153( 0.088754)\tRPN  0.057084( 0.198640)\n",
      "[Train]Epoch: [0][4990/5093]\tLoss_sum:  0.074486( 0.401977)\tCls:  0.015437( 0.059686)\tBox:  0.000000( 0.054966)\tObj:  0.019201( 0.088913)\tRPN  0.039848( 0.198413)\n",
      "[Train]Epoch: [0][5000/5093]\tLoss_sum:  0.424146( 0.402068)\tCls:  0.001047( 0.059661)\tBox:  0.000000( 0.054989)\tObj:  0.064134( 0.088920)\tRPN  0.358965( 0.198499)\n",
      "[Train]Epoch: [0][5010/5093]\tLoss_sum:  0.410323( 0.402131)\tCls:  0.035717( 0.059683)\tBox:  0.039879( 0.055048)\tObj:  0.070921( 0.088913)\tRPN  0.263806( 0.198487)\n",
      "[Train]Epoch: [0][5020/5093]\tLoss_sum:  0.261843( 0.402018)\tCls:  0.075747( 0.059729)\tBox:  0.142917( 0.055167)\tObj:  0.035098( 0.088842)\tRPN  0.008079( 0.198280)\n",
      "[Train]Epoch: [0][5030/5093]\tLoss_sum:  0.134206( 0.401772)\tCls:  0.000364( 0.059629)\tBox:  0.000000( 0.055080)\tObj:  0.007457( 0.088721)\tRPN  0.126385( 0.198343)\n",
      "[Train]Epoch: [0][5040/5093]\tLoss_sum:  0.487615( 0.401510)\tCls:  0.119334( 0.059572)\tBox:  0.139825( 0.055036)\tObj:  0.044518( 0.088701)\tRPN  0.183939( 0.198201)\n",
      "[Train]Epoch: [0][5050/5093]\tLoss_sum:  0.484225( 0.401337)\tCls:  0.004547( 0.059618)\tBox:  0.000000( 0.055158)\tObj:  0.015120( 0.088583)\tRPN  0.464558( 0.197979)\n",
      "[Train]Epoch: [0][5060/5093]\tLoss_sum:  0.099952( 0.401326)\tCls:  0.002015( 0.059659)\tBox:  0.000000( 0.055290)\tObj:  0.011206( 0.088472)\tRPN  0.086730( 0.197905)\n",
      "[Train]Epoch: [0][5070/5093]\tLoss_sum:  0.402110( 0.400974)\tCls:  0.083565( 0.059590)\tBox:  0.186872( 0.055264)\tObj:  0.017442( 0.088371)\tRPN  0.114231( 0.197749)\n",
      "[Train]Epoch: [0][5080/5093]\tLoss_sum:  0.172234( 0.400850)\tCls:  0.000303( 0.059582)\tBox:  0.000000( 0.055339)\tObj:  0.006555( 0.088231)\tRPN  0.165376( 0.197699)\n",
      "[Train]Epoch: [0][5090/5093]\tLoss_sum:  0.223597( 0.400347)\tCls:  0.078055( 0.059512)\tBox:  0.054426( 0.055278)\tObj:  0.010634( 0.088082)\tRPN  0.080483( 0.197475)\n",
      "[Train]Epoch: [1][10/5093]\tLoss_sum:  0.333238( 0.453846)\tCls:  0.068069( 0.090078)\tBox:  0.063184( 0.067799)\tObj:  0.039330( 0.100570)\tRPN  0.162655( 0.195399)\n",
      "[Train]Epoch: [1][20/5093]\tLoss_sum:  0.423468( 0.498416)\tCls:  0.095651( 0.102218)\tBox:  0.112624( 0.102243)\tObj:  0.157682( 0.089119)\tRPN  0.057512( 0.204835)\n",
      "[Train]Epoch: [1][30/5093]\tLoss_sum:  0.495766( 0.522900)\tCls:  0.183221( 0.135095)\tBox:  0.182218( 0.146077)\tObj:  0.078543( 0.090506)\tRPN  0.051784( 0.151223)\n",
      "[Train]Epoch: [1][40/5093]\tLoss_sum:  0.219239( 0.526341)\tCls:  0.000708( 0.145763)\tBox:  0.000000( 0.162587)\tObj:  0.010749( 0.077208)\tRPN  0.207782( 0.140782)\n",
      "[Train]Epoch: [1][50/5093]\tLoss_sum:  0.137347( 0.452285)\tCls:  0.000540( 0.117876)\tBox:  0.000000( 0.130070)\tObj:  0.008450( 0.065061)\tRPN  0.128358( 0.139279)\n",
      "[Train]Epoch: [1][60/5093]\tLoss_sum:  0.040805( 0.395411)\tCls:  0.000170( 0.098405)\tBox:  0.000000( 0.108391)\tObj:  0.017762( 0.057895)\tRPN  0.022873( 0.130720)\n",
      "[Train]Epoch: [1][70/5093]\tLoss_sum:  0.057764( 0.353571)\tCls:  0.000149( 0.084364)\tBox:  0.000000( 0.092907)\tObj:  0.005475( 0.052194)\tRPN  0.052140( 0.124106)\n",
      "[Train]Epoch: [1][80/5093]\tLoss_sum:  0.056721( 0.320623)\tCls:  0.000223( 0.073909)\tBox:  0.000000( 0.081293)\tObj:  0.025515( 0.046847)\tRPN  0.030983( 0.118574)\n",
      "[Train]Epoch: [1][90/5093]\tLoss_sum:  0.027200( 0.287827)\tCls:  0.000147( 0.065744)\tBox:  0.000000( 0.072261)\tObj:  0.003877( 0.042302)\tRPN  0.023176( 0.107521)\n",
      "[Train]Epoch: [1][100/5093]\tLoss_sum:  0.536568( 0.291554)\tCls:  0.186048( 0.068187)\tBox:  0.209040( 0.077844)\tObj:  0.049058( 0.041659)\tRPN  0.092422( 0.103863)\n",
      "[Train]Epoch: [1][110/5093]\tLoss_sum:  0.411909( 0.319852)\tCls:  0.177279( 0.085087)\tBox:  0.209868( 0.094118)\tObj:  0.011153( 0.042131)\tRPN  0.013608( 0.098516)\n",
      "[Train]Epoch: [1][120/5093]\tLoss_sum:  0.126276( 0.318881)\tCls:  0.010418( 0.084930)\tBox:  0.000000( 0.092795)\tObj:  0.003620( 0.040275)\tRPN  0.112238( 0.100881)\n",
      "[Train]Epoch: [1][130/5093]\tLoss_sum:  0.532956( 0.316512)\tCls:  0.046039( 0.079741)\tBox:  0.062832( 0.086465)\tObj:  0.034386( 0.039403)\tRPN  0.389699( 0.110904)\n",
      "[Train]Epoch: [1][140/5093]\tLoss_sum:  0.263776( 0.320316)\tCls:  0.080305( 0.081977)\tBox:  0.080273( 0.089534)\tObj:  0.078836( 0.039746)\tRPN  0.024361( 0.109059)\n",
      "[Train]Epoch: [1][150/5093]\tLoss_sum:  0.068409( 0.308406)\tCls:  0.000701( 0.077658)\tBox:  0.000000( 0.084791)\tObj:  0.019269( 0.037907)\tRPN  0.048439( 0.108050)\n",
      "[Train]Epoch: [1][160/5093]\tLoss_sum:  0.027293( 0.292899)\tCls:  0.001029( 0.072890)\tBox:  0.000000( 0.079492)\tObj:  0.004587( 0.036178)\tRPN  0.021676( 0.104340)\n",
      "[Train]Epoch: [1][170/5093]\tLoss_sum:  0.022983( 0.278070)\tCls:  0.000596( 0.068665)\tBox:  0.000000( 0.074816)\tObj:  0.004268( 0.034525)\tRPN  0.018119( 0.100064)\n",
      "[Train]Epoch: [1][180/5093]\tLoss_sum:  0.102649( 0.264720)\tCls:  0.000497( 0.064883)\tBox:  0.000000( 0.070659)\tObj:  0.025325( 0.033207)\tRPN  0.076827( 0.095971)\n",
      "[Train]Epoch: [1][190/5093]\tLoss_sum:  0.029474( 0.252924)\tCls:  0.000351( 0.061559)\tBox:  0.000000( 0.066940)\tObj:  0.004872( 0.032008)\tRPN  0.024251( 0.092417)\n",
      "[Train]Epoch: [1][200/5093]\tLoss_sum:  0.493976( 0.258220)\tCls:  0.049419( 0.059711)\tBox:  0.019586( 0.063974)\tObj:  0.018203( 0.033252)\tRPN  0.406769( 0.101283)\n",
      "[Train]Epoch: [1][210/5093]\tLoss_sum:  0.689181( 0.272906)\tCls:  0.295789( 0.064883)\tBox:  0.264738( 0.070141)\tObj:  0.046790( 0.033541)\tRPN  0.081865( 0.104341)\n",
      "[Train]Epoch: [1][220/5093]\tLoss_sum:  0.724466( 0.288487)\tCls:  0.005679( 0.066070)\tBox:  0.000000( 0.070698)\tObj:  0.010189( 0.033352)\tRPN  0.708598( 0.118366)\n",
      "[Train]Epoch: [1][230/5093]\tLoss_sum:  0.245615( 0.290203)\tCls:  0.002266( 0.063363)\tBox:  0.000000( 0.067625)\tObj:  0.029733( 0.032521)\tRPN  0.213616( 0.126695)\n",
      "[Train]Epoch: [1][240/5093]\tLoss_sum:  0.403673( 0.297517)\tCls:  0.096530( 0.062946)\tBox:  0.156680( 0.067884)\tObj:  0.071593( 0.039053)\tRPN  0.078869( 0.127634)\n",
      "[Train]Epoch: [1][250/5093]\tLoss_sum:  0.528282( 0.315283)\tCls:  0.101635( 0.064295)\tBox:  0.092243( 0.068608)\tObj:  0.096445( 0.041302)\tRPN  0.237959( 0.141079)\n",
      "[Train]Epoch: [1][260/5093]\tLoss_sum:  0.755219( 0.328542)\tCls:  0.083891( 0.065404)\tBox:  0.001156( 0.067116)\tObj:  0.128076( 0.043876)\tRPN  0.542096( 0.152146)\n",
      "[Train]Epoch: [1][270/5093]\tLoss_sum:  0.497463( 0.334580)\tCls:  0.105838( 0.067382)\tBox:  0.194521( 0.067739)\tObj:  0.048819( 0.044256)\tRPN  0.148285( 0.155203)\n",
      "[Train]Epoch: [1][280/5093]\tLoss_sum:  0.283321( 0.338793)\tCls:  0.074024( 0.069522)\tBox:  0.154386( 0.072841)\tObj:  0.030099( 0.044252)\tRPN  0.024812( 0.152178)\n",
      "[Train]Epoch: [1][290/5093]\tLoss_sum:  0.072809( 0.331782)\tCls:  0.002095( 0.067547)\tBox:  0.000000( 0.070847)\tObj:  0.012965( 0.043233)\tRPN  0.057749( 0.150155)\n",
      "[Train]Epoch: [1][300/5093]\tLoss_sum:  0.039129( 0.323005)\tCls:  0.001388( 0.065340)\tBox:  0.000000( 0.068486)\tObj:  0.003761( 0.042089)\tRPN  0.033979( 0.147091)\n",
      "[Train]Epoch: [1][310/5093]\tLoss_sum:  0.398682( 0.329848)\tCls:  0.058117( 0.065746)\tBox:  0.137249( 0.069236)\tObj:  0.185528( 0.047716)\tRPN  0.017788( 0.147150)\n",
      "[Train]Epoch: [1][320/5093]\tLoss_sum:  0.189114( 0.326166)\tCls:  0.007376( 0.064044)\tBox:  0.000000( 0.067240)\tObj:  0.118085( 0.049481)\tRPN  0.063654( 0.145402)\n",
      "[Train]Epoch: [1][330/5093]\tLoss_sum:  0.090871( 0.319779)\tCls:  0.000681( 0.062177)\tBox:  0.000000( 0.065202)\tObj:  0.012446( 0.048972)\tRPN  0.077744( 0.143428)\n",
      "[Train]Epoch: [1][340/5093]\tLoss_sum:  0.688901( 0.321842)\tCls:  0.122219( 0.062369)\tBox:  0.078279( 0.064590)\tObj:  0.034055( 0.048939)\tRPN  0.454349( 0.145944)\n",
      "[Train]Epoch: [1][350/5093]\tLoss_sum:  0.552791( 0.327688)\tCls:  0.202781( 0.064806)\tBox:  0.291165( 0.067751)\tObj:  0.034815( 0.048683)\tRPN  0.024029( 0.146447)\n",
      "[Train]Epoch: [1][360/5093]\tLoss_sum:  0.384439( 0.331866)\tCls:  0.007775( 0.067543)\tBox:  0.000000( 0.071201)\tObj:  0.013508( 0.047994)\tRPN  0.363156( 0.145128)\n",
      "[Train]Epoch: [1][370/5093]\tLoss_sum:  0.916619( 0.340003)\tCls:  0.004223( 0.066794)\tBox:  0.000000( 0.070465)\tObj:  0.021550( 0.049267)\tRPN  0.890847( 0.153477)\n",
      "[Train]Epoch: [1][380/5093]\tLoss_sum:  0.405605( 0.343008)\tCls:  0.128060( 0.067698)\tBox:  0.142896( 0.071782)\tObj:  0.104232( 0.049943)\tRPN  0.030417( 0.153585)\n",
      "[Train]Epoch: [1][390/5093]\tLoss_sum:  0.226203( 0.344433)\tCls:  0.041669( 0.067704)\tBox:  0.116054( 0.072116)\tObj:  0.038432( 0.050159)\tRPN  0.030048( 0.154453)\n",
      "[Train]Epoch: [1][400/5093]\tLoss_sum:  0.588773( 0.344457)\tCls:  0.028392( 0.066411)\tBox:  0.002013( 0.070839)\tObj:  0.058655( 0.049632)\tRPN  0.499714( 0.157575)\n",
      "[Train]Epoch: [1][410/5093]\tLoss_sum:  0.695832( 0.352861)\tCls:  0.037579( 0.066014)\tBox:  0.002912( 0.069337)\tObj:  0.027001( 0.050006)\tRPN  0.628341( 0.167503)\n",
      "[Train]Epoch: [1][420/5093]\tLoss_sum:  0.435202( 0.355173)\tCls:  0.068820( 0.065890)\tBox:  0.077730( 0.069174)\tObj:  0.009038( 0.049327)\tRPN  0.279614( 0.170781)\n",
      "[Train]Epoch: [1][430/5093]\tLoss_sum:  0.203905( 0.356983)\tCls:  0.052268( 0.066255)\tBox:  0.075089( 0.071084)\tObj:  0.016065( 0.049062)\tRPN  0.060482( 0.170583)\n",
      "[Train]Epoch: [1][440/5093]\tLoss_sum:  0.271666( 0.356002)\tCls:  0.044517( 0.065790)\tBox:  0.099203( 0.070588)\tObj:  0.027265( 0.048682)\tRPN  0.100680( 0.170941)\n",
      "[Train]Epoch: [1][450/5093]\tLoss_sum:  0.127956( 0.354995)\tCls:  0.033418( 0.065626)\tBox:  0.062829( 0.071403)\tObj:  0.009689( 0.048411)\tRPN  0.022020( 0.169555)\n",
      "[Train]Epoch: [1][460/5093]\tLoss_sum:  0.115286( 0.350810)\tCls:  0.012884( 0.064783)\tBox:  0.025574( 0.070521)\tObj:  0.012249( 0.047847)\tRPN  0.064579( 0.167658)\n",
      "[Train]Epoch: [1][470/5093]\tLoss_sum:  0.111392( 0.346029)\tCls:  0.038924( 0.063981)\tBox:  0.043513( 0.069858)\tObj:  0.012543( 0.047187)\tRPN  0.016413( 0.165003)\n",
      "[Train]Epoch: [1][480/5093]\tLoss_sum:  0.181025( 0.343307)\tCls:  0.041008( 0.063657)\tBox:  0.041092( 0.069019)\tObj:  0.024149( 0.046726)\tRPN  0.074775( 0.163905)\n",
      "[Train]Epoch: [1][490/5093]\tLoss_sum:  0.153888( 0.341288)\tCls:  0.000690( 0.063316)\tBox:  0.000000( 0.068672)\tObj:  0.006313( 0.046226)\tRPN  0.146884( 0.163073)\n",
      "[Train]Epoch: [1][500/5093]\tLoss_sum:  0.421309( 0.344227)\tCls:  0.054569( 0.062996)\tBox:  0.051609( 0.067666)\tObj:  0.021785( 0.046506)\tRPN  0.293346( 0.167059)\n",
      "[Train]Epoch: [1][510/5093]\tLoss_sum:  0.499353( 0.347019)\tCls:  0.188814( 0.064947)\tBox:  0.169191( 0.068722)\tObj:  0.062145( 0.046806)\tRPN  0.079203( 0.166544)\n",
      "[Train]Epoch: [1][520/5093]\tLoss_sum:  0.317600( 0.347382)\tCls:  0.002968( 0.065350)\tBox:  0.000000( 0.068821)\tObj:  0.013552( 0.046819)\tRPN  0.301080( 0.166392)\n",
      "[Train]Epoch: [1][530/5093]\tLoss_sum:  0.068565( 0.343365)\tCls:  0.002847( 0.064187)\tBox:  0.000000( 0.067522)\tObj:  0.005458( 0.046108)\tRPN  0.060260( 0.165547)\n",
      "[Train]Epoch: [1][540/5093]\tLoss_sum:  0.135088( 0.339066)\tCls:  0.000175( 0.063026)\tBox:  0.000000( 0.066272)\tObj:  0.003809( 0.045401)\tRPN  0.131104( 0.164366)\n",
      "[Train]Epoch: [1][550/5093]\tLoss_sum:  0.554394( 0.339508)\tCls:  0.054906( 0.063853)\tBox:  0.035015( 0.066830)\tObj:  0.075206( 0.045082)\tRPN  0.389268( 0.163743)\n",
      "[Train]Epoch: [1][560/5093]\tLoss_sum:  0.094474( 0.340133)\tCls:  0.000636( 0.063714)\tBox:  0.000000( 0.067070)\tObj:  0.031772( 0.045927)\tRPN  0.062066( 0.163422)\n",
      "[Train]Epoch: [1][570/5093]\tLoss_sum:  0.048679( 0.335445)\tCls:  0.001850( 0.062623)\tBox:  0.000000( 0.065893)\tObj:  0.022804( 0.045579)\tRPN  0.024025( 0.161349)\n",
      "[Train]Epoch: [1][580/5093]\tLoss_sum:  0.564828( 0.332294)\tCls:  0.231278( 0.062346)\tBox:  0.144527( 0.065215)\tObj:  0.027520( 0.045231)\tRPN  0.161503( 0.159502)\n",
      "[Train]Epoch: [1][590/5093]\tLoss_sum:  0.122218( 0.332418)\tCls:  0.000506( 0.063046)\tBox:  0.000000( 0.066487)\tObj:  0.010160( 0.045003)\tRPN  0.111552( 0.157882)\n",
      "[Train]Epoch: [1][600/5093]\tLoss_sum:  0.151430( 0.332809)\tCls:  0.000831( 0.062967)\tBox:  0.000000( 0.067119)\tObj:  0.011337( 0.044803)\tRPN  0.139262( 0.157920)\n",
      "[Train]Epoch: [1][610/5093]\tLoss_sum:  0.058658( 0.328872)\tCls:  0.000604( 0.061967)\tBox:  0.000000( 0.066019)\tObj:  0.015321( 0.044293)\tRPN  0.042733( 0.156593)\n",
      "[Train]Epoch: [1][620/5093]\tLoss_sum:  0.510797( 0.326823)\tCls:  0.072551( 0.061461)\tBox:  0.130794( 0.065813)\tObj:  0.029100( 0.043970)\tRPN  0.278351( 0.155580)\n",
      "[Train]Epoch: [1][630/5093]\tLoss_sum:  0.489579( 0.328264)\tCls:  0.164863( 0.061991)\tBox:  0.109741( 0.066045)\tObj:  0.031048( 0.044103)\tRPN  0.183927( 0.156126)\n",
      "[Train]Epoch: [1][640/5093]\tLoss_sum:  0.191416( 0.327821)\tCls:  0.000450( 0.062093)\tBox:  0.000000( 0.066143)\tObj:  0.012792( 0.043914)\tRPN  0.178174( 0.155671)\n",
      "[Train]Epoch: [1][650/5093]\tLoss_sum:  0.610721( 0.327015)\tCls:  0.205190( 0.061990)\tBox:  0.215184( 0.066049)\tObj:  0.016988( 0.043590)\tRPN  0.173360( 0.155386)\n",
      "[Train]Epoch: [1][660/5093]\tLoss_sum:  0.316010( 0.327977)\tCls:  0.101675( 0.062961)\tBox:  0.155168( 0.067157)\tObj:  0.034333( 0.043350)\tRPN  0.024834( 0.154508)\n",
      "[Train]Epoch: [1][670/5093]\tLoss_sum:  0.305187( 0.329410)\tCls:  0.005153( 0.063978)\tBox:  0.000000( 0.068354)\tObj:  0.032234( 0.043266)\tRPN  0.267800( 0.153812)\n",
      "[Train]Epoch: [1][680/5093]\tLoss_sum:  0.093403( 0.328499)\tCls:  0.001586( 0.063803)\tBox:  0.000000( 0.068234)\tObj:  0.006300( 0.043111)\tRPN  0.085517( 0.153352)\n",
      "[Train]Epoch: [1][690/5093]\tLoss_sum:  0.264191( 0.329504)\tCls:  0.148683( 0.064458)\tBox:  0.103464( 0.068442)\tObj:  0.010235( 0.044022)\tRPN  0.001809( 0.152583)\n",
      "[Train]Epoch: [1][700/5093]\tLoss_sum:  0.345455( 0.329848)\tCls:  0.067419( 0.064215)\tBox:  0.117208( 0.067914)\tObj:  0.031617( 0.044040)\tRPN  0.129211( 0.153678)\n",
      "[Train]Epoch: [1][710/5093]\tLoss_sum:  0.248695( 0.330186)\tCls:  0.110135( 0.064582)\tBox:  0.087273( 0.068471)\tObj:  0.044557( 0.044217)\tRPN  0.006730( 0.152916)\n",
      "[Train]Epoch: [1][720/5093]\tLoss_sum:  0.446048( 0.330734)\tCls:  0.005022( 0.064462)\tBox:  0.000000( 0.068495)\tObj:  0.030787( 0.044479)\tRPN  0.410238( 0.153298)\n",
      "[Train]Epoch: [1][730/5093]\tLoss_sum:  0.643361( 0.333676)\tCls:  0.318799( 0.064513)\tBox:  0.183631( 0.068379)\tObj:  0.119686( 0.044778)\tRPN  0.021245( 0.156006)\n",
      "[Train]Epoch: [1][740/5093]\tLoss_sum:  0.603276( 0.335493)\tCls:  0.089929( 0.064889)\tBox:  0.072990( 0.068790)\tObj:  0.061075( 0.044900)\tRPN  0.379282( 0.156915)\n",
      "[Train]Epoch: [1][750/5093]\tLoss_sum:  0.168612( 0.335493)\tCls:  0.001041( 0.065394)\tBox:  0.000000( 0.069410)\tObj:  0.015181( 0.044863)\tRPN  0.152390( 0.155827)\n",
      "[Train]Epoch: [1][760/5093]\tLoss_sum:  0.073534( 0.331932)\tCls:  0.000431( 0.064549)\tBox:  0.000000( 0.068497)\tObj:  0.004507( 0.044363)\tRPN  0.068595( 0.154523)\n",
      "[Train]Epoch: [1][770/5093]\tLoss_sum:  0.038968( 0.328209)\tCls:  0.000119( 0.063719)\tBox:  0.000000( 0.067607)\tObj:  0.009861( 0.043908)\tRPN  0.028988( 0.152974)\n",
      "[Train]Epoch: [1][780/5093]\tLoss_sum:  0.022132( 0.324518)\tCls:  0.000367( 0.062908)\tBox:  0.000000( 0.066740)\tObj:  0.009661( 0.043498)\tRPN  0.012104( 0.151373)\n",
      "[Train]Epoch: [1][790/5093]\tLoss_sum:  1.192470( 0.323622)\tCls:  0.141234( 0.062648)\tBox:  0.170903( 0.066578)\tObj:  0.611019( 0.043956)\tRPN  0.269315( 0.150440)\n",
      "[Train]Epoch: [1][800/5093]\tLoss_sum:  0.049549( 0.320756)\tCls:  0.000262( 0.062063)\tBox:  0.000000( 0.066012)\tObj:  0.006048( 0.043509)\tRPN  0.043239( 0.149172)\n",
      "[Train]Epoch: [1][810/5093]\tLoss_sum:  0.656982( 0.320658)\tCls:  0.110161( 0.061964)\tBox:  0.104950( 0.065839)\tObj:  0.072688( 0.043318)\tRPN  0.369183( 0.149538)\n",
      "[Train]Epoch: [1][820/5093]\tLoss_sum:  0.034636( 0.320743)\tCls:  0.000262( 0.062527)\tBox:  0.000000( 0.066548)\tObj:  0.009477( 0.043089)\tRPN  0.024897( 0.148579)\n",
      "[Train]Epoch: [1][830/5093]\tLoss_sum:  0.022801( 0.317230)\tCls:  0.000353( 0.061778)\tBox:  0.000000( 0.065746)\tObj:  0.009144( 0.042664)\tRPN  0.013304( 0.147041)\n",
      "[Train]Epoch: [1][840/5093]\tLoss_sum:  0.022559( 0.313893)\tCls:  0.000980( 0.061052)\tBox:  0.000000( 0.064963)\tObj:  0.014002( 0.042287)\tRPN  0.007577( 0.145591)\n",
      "[Train]Epoch: [1][850/5093]\tLoss_sum:  0.036612( 0.310506)\tCls:  0.000257( 0.060335)\tBox:  0.000000( 0.064199)\tObj:  0.005580( 0.041843)\tRPN  0.030774( 0.144129)\n",
      "[Train]Epoch: [1][860/5093]\tLoss_sum:  0.018927( 0.307202)\tCls:  0.000073( 0.059640)\tBox:  0.000000( 0.063452)\tObj:  0.003509( 0.041437)\tRPN  0.015345( 0.142673)\n",
      "[Train]Epoch: [1][870/5093]\tLoss_sum:  0.021613( 0.303900)\tCls:  0.000226( 0.058956)\tBox:  0.000000( 0.062723)\tObj:  0.003750( 0.041021)\tRPN  0.017637( 0.141201)\n",
      "[Train]Epoch: [1][880/5093]\tLoss_sum:  0.008870( 0.301016)\tCls:  0.000081( 0.058322)\tBox:  0.000000( 0.062011)\tObj:  0.003967( 0.040964)\tRPN  0.004822( 0.139720)\n",
      "[Train]Epoch: [1][890/5093]\tLoss_sum:  0.675407( 0.303391)\tCls:  0.105307( 0.059579)\tBox:  0.131769( 0.062982)\tObj:  0.034746( 0.041154)\tRPN  0.403586( 0.139676)\n",
      "[Train]Epoch: [1][900/5093]\tLoss_sum:  0.039708( 0.303403)\tCls:  0.004073( 0.059851)\tBox:  0.000000( 0.063152)\tObj:  0.023818( 0.041520)\tRPN  0.011817( 0.138880)\n",
      "[Train]Epoch: [1][910/5093]\tLoss_sum:  0.478588( 0.304507)\tCls:  0.101342( 0.059818)\tBox:  0.152384( 0.063139)\tObj:  0.110380( 0.041569)\tRPN  0.114482( 0.139981)\n",
      "[Train]Epoch: [1][920/5093]\tLoss_sum:  0.252394( 0.303812)\tCls:  0.069496( 0.059513)\tBox:  0.102474( 0.062885)\tObj:  0.058577( 0.041775)\tRPN  0.021847( 0.139638)\n",
      "[Train]Epoch: [1][930/5093]\tLoss_sum:  0.070229( 0.303127)\tCls:  0.001295( 0.059158)\tBox:  0.000000( 0.062487)\tObj:  0.014894( 0.041917)\tRPN  0.054040( 0.139565)\n",
      "[Train]Epoch: [1][940/5093]\tLoss_sum:  0.444909( 0.303297)\tCls:  0.146339( 0.059305)\tBox:  0.241843( 0.062644)\tObj:  0.016179( 0.042208)\tRPN  0.040548( 0.139140)\n",
      "[Train]Epoch: [1][950/5093]\tLoss_sum:  0.354626( 0.305134)\tCls:  0.053645( 0.059418)\tBox:  0.103208( 0.062693)\tObj:  0.101441( 0.043086)\tRPN  0.096333( 0.139937)\n",
      "[Train]Epoch: [1][960/5093]\tLoss_sum:  0.288263( 0.305916)\tCls:  0.088593( 0.059901)\tBox:  0.089378( 0.063101)\tObj:  0.056751( 0.043361)\tRPN  0.053541( 0.139554)\n",
      "[Train]Epoch: [1][970/5093]\tLoss_sum:  0.038044( 0.304261)\tCls:  0.013258( 0.059625)\tBox:  0.000000( 0.062873)\tObj:  0.014452( 0.043276)\tRPN  0.010334( 0.138488)\n",
      "[Train]Epoch: [1][980/5093]\tLoss_sum:  0.040467( 0.304229)\tCls:  0.002917( 0.059760)\tBox:  0.000000( 0.062878)\tObj:  0.008542( 0.043652)\tRPN  0.029008( 0.137940)\n",
      "[Train]Epoch: [1][990/5093]\tLoss_sum:  0.432458( 0.303924)\tCls:  0.021125( 0.059983)\tBox:  0.000056( 0.062871)\tObj:  0.054820( 0.043802)\tRPN  0.356458( 0.137268)\n",
      "[Train]Epoch: [1][1000/5093]\tLoss_sum:  0.477063( 0.304760)\tCls:  0.093531( 0.060347)\tBox:  0.103711( 0.063333)\tObj:  0.051553( 0.043989)\tRPN  0.228268( 0.137091)\n",
      "[Train]Epoch: [1][1010/5093]\tLoss_sum:  0.038251( 0.304270)\tCls:  0.007014( 0.060334)\tBox:  0.000000( 0.063288)\tObj:  0.012069( 0.043889)\tRPN  0.019167( 0.136758)\n",
      "[Train]Epoch: [1][1020/5093]\tLoss_sum:  0.439347( 0.305407)\tCls:  0.201498( 0.061183)\tBox:  0.183757( 0.063991)\tObj:  0.043714( 0.044063)\tRPN  0.010379( 0.136169)\n",
      "[Train]Epoch: [1][1030/5093]\tLoss_sum:  0.591687( 0.306215)\tCls:  0.061500( 0.061249)\tBox:  0.104332( 0.064172)\tObj:  0.039507( 0.043862)\tRPN  0.386349( 0.136933)\n",
      "[Train]Epoch: [1][1040/5093]\tLoss_sum:  0.487472( 0.307321)\tCls:  0.041531( 0.061764)\tBox:  0.053206( 0.064849)\tObj:  0.022031( 0.043824)\tRPN  0.370704( 0.136884)\n",
      "[Train]Epoch: [1][1050/5093]\tLoss_sum:  0.053122( 0.307711)\tCls:  0.000996( 0.061499)\tBox:  0.000000( 0.064833)\tObj:  0.006975( 0.043554)\tRPN  0.045151( 0.137825)\n",
      "[Train]Epoch: [1][1060/5093]\tLoss_sum:  0.088046( 0.306428)\tCls:  0.003020( 0.060938)\tBox:  0.000000( 0.064221)\tObj:  0.005655( 0.043233)\tRPN  0.079371( 0.138037)\n",
      "[Train]Epoch: [1][1070/5093]\tLoss_sum:  0.428652( 0.306104)\tCls:  0.172927( 0.061351)\tBox:  0.239638( 0.064508)\tObj:  0.006857( 0.043037)\tRPN  0.009229( 0.137208)\n",
      "[Train]Epoch: [1][1080/5093]\tLoss_sum:  0.919710( 0.305906)\tCls:  0.041512( 0.061017)\tBox:  0.000796( 0.064152)\tObj:  0.370830( 0.043090)\tRPN  0.506572( 0.137647)\n",
      "[Train]Epoch: [1][1090/5093]\tLoss_sum:  0.219897( 0.306468)\tCls:  0.000597( 0.061100)\tBox:  0.000000( 0.064226)\tObj:  0.029454( 0.043003)\tRPN  0.189846( 0.138138)\n",
      "[Train]Epoch: [1][1100/5093]\tLoss_sum:  0.488388( 0.306273)\tCls:  0.068280( 0.060875)\tBox:  0.071984( 0.063834)\tObj:  0.039701( 0.042940)\tRPN  0.308422( 0.138624)\n",
      "[Train]Epoch: [1][1110/5093]\tLoss_sum:  0.107467( 0.305768)\tCls:  0.005557( 0.060750)\tBox:  0.000000( 0.063650)\tObj:  0.023284( 0.042900)\tRPN  0.078625( 0.138469)\n",
      "[Train]Epoch: [1][1120/5093]\tLoss_sum:  0.275629( 0.305934)\tCls:  0.081687( 0.060887)\tBox:  0.077748( 0.063730)\tObj:  0.037452( 0.042804)\tRPN  0.078743( 0.138512)\n",
      "[Train]Epoch: [1][1130/5093]\tLoss_sum:  0.223235( 0.306139)\tCls:  0.002839( 0.061062)\tBox:  0.000000( 0.064193)\tObj:  0.037550( 0.042657)\tRPN  0.182846( 0.138227)\n",
      "[Train]Epoch: [1][1140/5093]\tLoss_sum:  0.082634( 0.304285)\tCls:  0.002208( 0.060547)\tBox:  0.000000( 0.063630)\tObj:  0.004041( 0.042423)\tRPN  0.076386( 0.137685)\n",
      "[Train]Epoch: [1][1150/5093]\tLoss_sum:  0.115535( 0.303117)\tCls:  0.000255( 0.060342)\tBox:  0.000000( 0.063454)\tObj:  0.004791( 0.042175)\tRPN  0.110488( 0.137145)\n",
      "[Train]Epoch: [1][1160/5093]\tLoss_sum:  0.603456( 0.301415)\tCls:  0.065775( 0.059889)\tBox:  0.032109( 0.062935)\tObj:  0.117129( 0.041973)\tRPN  0.388442( 0.136617)\n",
      "[Train]Epoch: [1][1170/5093]\tLoss_sum:  0.117584( 0.300835)\tCls:  0.032086( 0.059692)\tBox:  0.023219( 0.062682)\tObj:  0.010753( 0.042021)\tRPN  0.051526( 0.136440)\n",
      "[Train]Epoch: [1][1180/5093]\tLoss_sum:  0.478382( 0.300565)\tCls:  0.166910( 0.059722)\tBox:  0.094173( 0.062681)\tObj:  0.032995( 0.041909)\tRPN  0.184303( 0.136253)\n",
      "[Train]Epoch: [1][1190/5093]\tLoss_sum:  0.035808( 0.299296)\tCls:  0.001142( 0.059437)\tBox:  0.000000( 0.062405)\tObj:  0.008546( 0.041834)\tRPN  0.026120( 0.135620)\n",
      "[Train]Epoch: [1][1200/5093]\tLoss_sum:  0.480560( 0.298562)\tCls:  0.129638( 0.059349)\tBox:  0.081971( 0.062173)\tObj:  0.042918( 0.041661)\tRPN  0.226034( 0.135379)\n",
      "[Train]Epoch: [1][1210/5093]\tLoss_sum:  0.029433( 0.297955)\tCls:  0.006351( 0.059339)\tBox:  0.000000( 0.062326)\tObj:  0.010937( 0.041546)\tRPN  0.012145( 0.134745)\n",
      "[Train]Epoch: [1][1220/5093]\tLoss_sum:  0.036014( 0.296688)\tCls:  0.008146( 0.059150)\tBox:  0.000000( 0.062175)\tObj:  0.013101( 0.041370)\tRPN  0.014767( 0.133993)\n",
      "[Train]Epoch: [1][1230/5093]\tLoss_sum:  0.236393( 0.296132)\tCls:  0.064918( 0.059110)\tBox:  0.046205( 0.062086)\tObj:  0.027240( 0.041566)\tRPN  0.098030( 0.133370)\n",
      "[Train]Epoch: [1][1240/5093]\tLoss_sum:  0.011767( 0.295442)\tCls:  0.000425( 0.059301)\tBox:  0.000000( 0.062295)\tObj:  0.003049( 0.041337)\tRPN  0.008294( 0.132509)\n",
      "[Train]Epoch: [1][1250/5093]\tLoss_sum:  0.009580( 0.293224)\tCls:  0.000390( 0.058858)\tBox:  0.000000( 0.061797)\tObj:  0.004245( 0.041062)\tRPN  0.004945( 0.131508)\n",
      "[Train]Epoch: [1][1260/5093]\tLoss_sum:  0.027142( 0.292290)\tCls:  0.000286( 0.058619)\tBox:  0.000000( 0.061707)\tObj:  0.019995( 0.040884)\tRPN  0.006860( 0.131080)\n",
      "[Train]Epoch: [1][1270/5093]\tLoss_sum:  0.265542( 0.292005)\tCls:  0.077096( 0.058628)\tBox:  0.097334( 0.061837)\tObj:  0.041632( 0.040739)\tRPN  0.049481( 0.130801)\n",
      "[Train]Epoch: [1][1280/5093]\tLoss_sum:  0.010757( 0.290333)\tCls:  0.000193( 0.058317)\tBox:  0.000000( 0.061604)\tObj:  0.002831( 0.040462)\tRPN  0.007733( 0.129951)\n",
      "[Train]Epoch: [1][1290/5093]\tLoss_sum:  0.544431( 0.290228)\tCls:  0.049315( 0.058289)\tBox:  0.045152( 0.061568)\tObj:  0.123107( 0.040447)\tRPN  0.326856( 0.129924)\n",
      "[Train]Epoch: [1][1300/5093]\tLoss_sum:  0.079921( 0.290664)\tCls:  0.001161( 0.058394)\tBox:  0.000000( 0.061793)\tObj:  0.011322( 0.040329)\tRPN  0.067438( 0.130147)\n",
      "[Train]Epoch: [1][1310/5093]\tLoss_sum:  0.412890( 0.290356)\tCls:  0.094911( 0.058277)\tBox:  0.071245( 0.061625)\tObj:  0.013350( 0.040237)\tRPN  0.233385( 0.130218)\n",
      "[Train]Epoch: [1][1320/5093]\tLoss_sum:  0.156599( 0.291013)\tCls:  0.032813( 0.058588)\tBox:  0.055621( 0.061973)\tObj:  0.034429( 0.040252)\tRPN  0.033736( 0.130200)\n",
      "[Train]Epoch: [1][1330/5093]\tLoss_sum:  0.314897( 0.291397)\tCls:  0.063206( 0.058584)\tBox:  0.152035( 0.062309)\tObj:  0.030038( 0.040801)\tRPN  0.069618( 0.129702)\n",
      "[Train]Epoch: [1][1340/5093]\tLoss_sum:  0.283481( 0.292054)\tCls:  0.081310( 0.058967)\tBox:  0.143652( 0.062833)\tObj:  0.032615( 0.040869)\tRPN  0.025904( 0.129385)\n",
      "[Train]Epoch: [1][1350/5093]\tLoss_sum:  0.572437( 0.292274)\tCls:  0.162573( 0.058918)\tBox:  0.219549( 0.062768)\tObj:  0.025610( 0.040743)\tRPN  0.164705( 0.129845)\n",
      "[Train]Epoch: [1][1360/5093]\tLoss_sum:  0.238719( 0.293477)\tCls:  0.023321( 0.059414)\tBox:  0.000000( 0.063341)\tObj:  0.026593( 0.040753)\tRPN  0.188805( 0.129969)\n",
      "[Train]Epoch: [1][1370/5093]\tLoss_sum:  0.069571( 0.293391)\tCls:  0.000210( 0.059477)\tBox:  0.000000( 0.063589)\tObj:  0.015012( 0.040660)\tRPN  0.054349( 0.129665)\n",
      "[Train]Epoch: [1][1380/5093]\tLoss_sum:  0.331195( 0.293563)\tCls:  0.078798( 0.059410)\tBox:  0.069353( 0.063302)\tObj:  0.074614( 0.040669)\tRPN  0.108430( 0.130182)\n",
      "[Train]Epoch: [1][1390/5093]\tLoss_sum:  0.354497( 0.293727)\tCls:  0.106265( 0.059721)\tBox:  0.147668( 0.063719)\tObj:  0.075597( 0.040672)\tRPN  0.024968( 0.129615)\n",
      "[Train]Epoch: [1][1400/5093]\tLoss_sum:  0.750251( 0.294222)\tCls:  0.136413( 0.059781)\tBox:  0.180493( 0.063729)\tObj:  0.169350( 0.040826)\tRPN  0.263995( 0.129886)\n",
      "[Train]Epoch: [1][1410/5093]\tLoss_sum:  0.177027( 0.293508)\tCls:  0.006246( 0.059520)\tBox:  0.000000( 0.063537)\tObj:  0.026829( 0.040749)\tRPN  0.143952( 0.129703)\n",
      "[Train]Epoch: [1][1420/5093]\tLoss_sum:  0.344918( 0.293997)\tCls:  0.089812( 0.059507)\tBox:  0.167264( 0.063656)\tObj:  0.036375( 0.040859)\tRPN  0.051467( 0.129975)\n",
      "[Train]Epoch: [1][1430/5093]\tLoss_sum:  0.372396( 0.294315)\tCls:  0.055924( 0.059661)\tBox:  0.110879( 0.063795)\tObj:  0.036279( 0.040815)\tRPN  0.169314( 0.130043)\n",
      "[Train]Epoch: [1][1440/5093]\tLoss_sum:  0.277188( 0.294274)\tCls:  0.058157( 0.059818)\tBox:  0.042486( 0.064273)\tObj:  0.016007( 0.040689)\tRPN  0.160537( 0.129495)\n",
      "[Train]Epoch: [1][1450/5093]\tLoss_sum:  0.486188( 0.294854)\tCls:  0.133156( 0.059944)\tBox:  0.141955( 0.064694)\tObj:  0.016707( 0.040625)\tRPN  0.194370( 0.129591)\n",
      "[Train]Epoch: [1][1460/5093]\tLoss_sum:  0.042183( 0.294340)\tCls:  0.000427( 0.059879)\tBox:  0.000000( 0.064677)\tObj:  0.025109( 0.040553)\tRPN  0.016648( 0.129231)\n",
      "[Train]Epoch: [1][1470/5093]\tLoss_sum:  0.255561( 0.295100)\tCls:  0.034726( 0.059869)\tBox:  0.109209( 0.064631)\tObj:  0.070371( 0.040590)\tRPN  0.041255( 0.130009)\n",
      "[Train]Epoch: [1][1480/5093]\tLoss_sum:  0.098599( 0.295029)\tCls:  0.004420( 0.060060)\tBox:  0.000000( 0.064682)\tObj:  0.021958( 0.040556)\tRPN  0.072221( 0.129731)\n",
      "[Train]Epoch: [1][1490/5093]\tLoss_sum:  0.358437( 0.295964)\tCls:  0.076135( 0.060398)\tBox:  0.111660( 0.065179)\tObj:  0.048445( 0.040591)\tRPN  0.122197( 0.129796)\n",
      "[Train]Epoch: [1][1500/5093]\tLoss_sum:  0.420527( 0.296953)\tCls:  0.084549( 0.060585)\tBox:  0.089570( 0.065628)\tObj:  0.071418( 0.040552)\tRPN  0.174990( 0.130187)\n",
      "[Train]Epoch: [1][1510/5093]\tLoss_sum:  0.369094( 0.296849)\tCls:  0.086407( 0.060644)\tBox:  0.061092( 0.065616)\tObj:  0.054301( 0.040528)\tRPN  0.167293( 0.130061)\n",
      "[Train]Epoch: [1][1520/5093]\tLoss_sum:  0.245920( 0.297594)\tCls:  0.025842( 0.060743)\tBox:  0.000000( 0.065711)\tObj:  0.087409( 0.041068)\tRPN  0.132670( 0.130072)\n",
      "[Train]Epoch: [1][1530/5093]\tLoss_sum:  0.319121( 0.298752)\tCls:  0.059599( 0.060988)\tBox:  0.127230( 0.065775)\tObj:  0.042150( 0.041167)\tRPN  0.090142( 0.130822)\n",
      "[Train]Epoch: [1][1540/5093]\tLoss_sum:  0.508924( 0.299378)\tCls:  0.135085( 0.060958)\tBox:  0.148094( 0.065691)\tObj:  0.024502( 0.041166)\tRPN  0.201242( 0.131563)\n",
      "[Train]Epoch: [1][1550/5093]\tLoss_sum:  0.863948( 0.300712)\tCls:  0.013422( 0.061347)\tBox:  0.000000( 0.066178)\tObj:  0.078534( 0.041270)\tRPN  0.771993( 0.131916)\n",
      "[Train]Epoch: [1][1560/5093]\tLoss_sum:  1.057282( 0.303193)\tCls:  0.065632( 0.061064)\tBox:  0.002714( 0.065756)\tObj:  0.245294( 0.041410)\tRPN  0.743642( 0.134962)\n",
      "[Train]Epoch: [1][1570/5093]\tLoss_sum:  0.246402( 0.303795)\tCls:  0.056631( 0.061321)\tBox:  0.076040( 0.066092)\tObj:  0.057999( 0.041432)\tRPN  0.055733( 0.134951)\n",
      "[Train]Epoch: [1][1580/5093]\tLoss_sum:  0.800043( 0.306770)\tCls:  0.001624( 0.061494)\tBox:  0.000000( 0.066338)\tObj:  0.007929( 0.041376)\tRPN  0.790490( 0.137562)\n",
      "[Train]Epoch: [1][1590/5093]\tLoss_sum:  0.494303( 0.307658)\tCls:  0.153308( 0.061791)\tBox:  0.268138( 0.066876)\tObj:  0.041438( 0.041395)\tRPN  0.031420( 0.137595)\n",
      "[Train]Epoch: [1][1600/5093]\tLoss_sum:  0.470521( 0.308449)\tCls:  0.081210( 0.061963)\tBox:  0.093684( 0.067043)\tObj:  0.115783( 0.041547)\tRPN  0.179845( 0.137896)\n",
      "[Train]Epoch: [1][1610/5093]\tLoss_sum:  0.525247( 0.309428)\tCls:  0.092838( 0.062267)\tBox:  0.110515( 0.067480)\tObj:  0.085451( 0.041583)\tRPN  0.236443( 0.138099)\n",
      "[Train]Epoch: [1][1620/5093]\tLoss_sum:  0.231817( 0.309027)\tCls:  0.005182( 0.062289)\tBox:  0.000000( 0.067459)\tObj:  0.027135( 0.041782)\tRPN  0.199500( 0.137498)\n",
      "[Train]Epoch: [1][1630/5093]\tLoss_sum:  0.259441( 0.307846)\tCls:  0.070680( 0.061966)\tBox:  0.075634( 0.067091)\tObj:  0.013915( 0.041644)\tRPN  0.099212( 0.137145)\n",
      "[Train]Epoch: [1][1640/5093]\tLoss_sum:  0.616616( 0.308464)\tCls:  0.050271( 0.062212)\tBox:  0.022939( 0.067248)\tObj:  0.103654( 0.041789)\tRPN  0.439752( 0.137216)\n",
      "[Train]Epoch: [1][1650/5093]\tLoss_sum:  0.262807( 0.308417)\tCls:  0.067950( 0.062218)\tBox:  0.133922( 0.067322)\tObj:  0.039216( 0.041777)\tRPN  0.021719( 0.137100)\n",
      "[Train]Epoch: [1][1660/5093]\tLoss_sum:  0.052027( 0.307282)\tCls:  0.000800( 0.061900)\tBox:  0.000000( 0.066972)\tObj:  0.005133( 0.041685)\tRPN  0.046094( 0.136725)\n",
      "[Train]Epoch: [1][1670/5093]\tLoss_sum:  0.183855( 0.307179)\tCls:  0.001343( 0.061772)\tBox:  0.000000( 0.066812)\tObj:  0.005259( 0.041616)\tRPN  0.177252( 0.136979)\n",
      "[Train]Epoch: [1][1680/5093]\tLoss_sum:  0.331669( 0.307201)\tCls:  0.125357( 0.061933)\tBox:  0.131975( 0.067010)\tObj:  0.012492( 0.041495)\tRPN  0.061845( 0.136763)\n",
      "[Train]Epoch: [1][1690/5093]\tLoss_sum:  0.081126( 0.306990)\tCls:  0.000802( 0.061706)\tBox:  0.000000( 0.066798)\tObj:  0.015046( 0.041309)\tRPN  0.065278( 0.137176)\n",
      "[Train]Epoch: [1][1700/5093]\tLoss_sum:  0.091721( 0.305902)\tCls:  0.001170( 0.061359)\tBox:  0.000000( 0.066405)\tObj:  0.017159( 0.041135)\tRPN  0.073392( 0.137002)\n",
      "[Train]Epoch: [1][1710/5093]\tLoss_sum:  0.302580( 0.305811)\tCls:  0.105327( 0.061348)\tBox:  0.077624( 0.066443)\tObj:  0.034930( 0.041043)\tRPN  0.084699( 0.136977)\n",
      "[Train]Epoch: [1][1720/5093]\tLoss_sum:  0.102248( 0.305318)\tCls:  0.000660( 0.061208)\tBox:  0.000000( 0.066422)\tObj:  0.004268( 0.040865)\tRPN  0.097320( 0.136823)\n",
      "[Train]Epoch: [1][1730/5093]\tLoss_sum:  0.176068( 0.305187)\tCls:  0.001391( 0.061152)\tBox:  0.000000( 0.066381)\tObj:  0.014797( 0.040768)\tRPN  0.159879( 0.136885)\n",
      "[Train]Epoch: [1][1740/5093]\tLoss_sum:  0.243040( 0.305483)\tCls:  0.028021( 0.061040)\tBox:  0.070617( 0.066420)\tObj:  0.045065( 0.040789)\tRPN  0.099336( 0.137234)\n",
      "[Train]Epoch: [1][1750/5093]\tLoss_sum:  0.271541( 0.304870)\tCls:  0.060257( 0.060825)\tBox:  0.073581( 0.066190)\tObj:  0.037669( 0.040702)\tRPN  0.100034( 0.137152)\n",
      "[Train]Epoch: [1][1760/5093]\tLoss_sum:  0.346017( 0.304642)\tCls:  0.002686( 0.060699)\tBox:  0.000000( 0.066075)\tObj:  0.012522( 0.040684)\tRPN  0.330809( 0.137184)\n",
      "[Train]Epoch: [1][1770/5093]\tLoss_sum:  0.056780( 0.304043)\tCls:  0.022842( 0.060600)\tBox:  0.024324( 0.066045)\tObj:  0.002002( 0.040633)\tRPN  0.007612( 0.136765)\n",
      "[Train]Epoch: [1][1780/5093]\tLoss_sum:  0.639101( 0.304921)\tCls:  0.001470( 0.060494)\tBox:  0.000000( 0.065959)\tObj:  0.014389( 0.040550)\tRPN  0.623241( 0.137919)\n",
      "[Train]Epoch: [1][1790/5093]\tLoss_sum:  0.439335( 0.305160)\tCls:  0.066856( 0.060260)\tBox:  0.035158( 0.065668)\tObj:  0.066620( 0.040451)\tRPN  0.270700( 0.138781)\n",
      "[Train]Epoch: [1][1800/5093]\tLoss_sum:  0.364677( 0.305446)\tCls:  0.064988( 0.060087)\tBox:  0.055803( 0.065501)\tObj:  0.069972( 0.040355)\tRPN  0.173913( 0.139502)\n",
      "[Train]Epoch: [1][1810/5093]\tLoss_sum:  0.485502( 0.305076)\tCls:  0.076887( 0.059950)\tBox:  0.129851( 0.065498)\tObj:  0.043113( 0.040270)\tRPN  0.235651( 0.139358)\n",
      "[Train]Epoch: [1][1820/5093]\tLoss_sum:  0.154224( 0.304791)\tCls:  0.001155( 0.059883)\tBox:  0.000000( 0.065593)\tObj:  0.005947( 0.040185)\tRPN  0.147121( 0.139130)\n",
      "[Train]Epoch: [1][1830/5093]\tLoss_sum:  0.041560( 0.303519)\tCls:  0.000488( 0.059565)\tBox:  0.000000( 0.065234)\tObj:  0.011113( 0.040065)\tRPN  0.029959( 0.138654)\n",
      "[Train]Epoch: [1][1840/5093]\tLoss_sum:  0.214290( 0.303484)\tCls:  0.058594( 0.059468)\tBox:  0.134570( 0.065280)\tObj:  0.014151( 0.040032)\tRPN  0.006975( 0.138705)\n",
      "[Train]Epoch: [1][1850/5093]\tLoss_sum:  0.036211( 0.302017)\tCls:  0.000892( 0.059154)\tBox:  0.000000( 0.064927)\tObj:  0.020572( 0.039890)\tRPN  0.014747( 0.138047)\n",
      "[Train]Epoch: [1][1860/5093]\tLoss_sum:  0.157434( 0.300686)\tCls:  0.029682( 0.058862)\tBox:  0.025054( 0.064592)\tObj:  0.015942( 0.039725)\tRPN  0.086756( 0.137508)\n",
      "[Train]Epoch: [1][1870/5093]\tLoss_sum:  0.524835( 0.299563)\tCls:  0.074275( 0.058606)\tBox:  0.083358( 0.064318)\tObj:  0.144192( 0.039627)\tRPN  0.223011( 0.137012)\n",
      "[Train]Epoch: [1][1880/5093]\tLoss_sum:  0.019128( 0.298996)\tCls:  0.000378( 0.058524)\tBox:  0.000000( 0.064406)\tObj:  0.010105( 0.039512)\tRPN  0.008644( 0.136554)\n",
      "[Train]Epoch: [1][1890/5093]\tLoss_sum:  0.022294( 0.298180)\tCls:  0.000274( 0.058348)\tBox:  0.000000( 0.064286)\tObj:  0.007310( 0.039426)\tRPN  0.014711( 0.136120)\n",
      "[Train]Epoch: [1][1900/5093]\tLoss_sum:  0.032858( 0.296756)\tCls:  0.016890( 0.058056)\tBox:  0.000000( 0.063948)\tObj:  0.009673( 0.039315)\tRPN  0.006295( 0.135437)\n",
      "[Train]Epoch: [1][1910/5093]\tLoss_sum:  0.008654( 0.296026)\tCls:  0.000665( 0.057927)\tBox:  0.000000( 0.063877)\tObj:  0.003904( 0.039239)\tRPN  0.004085( 0.134983)\n",
      "[Train]Epoch: [1][1920/5093]\tLoss_sum:  0.022970( 0.295163)\tCls:  0.000159( 0.057774)\tBox:  0.000000( 0.063712)\tObj:  0.018798( 0.039123)\tRPN  0.004013( 0.134555)\n",
      "[Train]Epoch: [1][1930/5093]\tLoss_sum:  0.009501( 0.293702)\tCls:  0.000116( 0.057476)\tBox:  0.000000( 0.063382)\tObj:  0.006173( 0.038967)\tRPN  0.003212( 0.133878)\n",
      "[Train]Epoch: [1][1940/5093]\tLoss_sum:  0.748658( 0.293405)\tCls:  0.115025( 0.057580)\tBox:  0.038976( 0.063324)\tObj:  0.236037( 0.038974)\tRPN  0.358619( 0.133526)\n",
      "[Train]Epoch: [1][1950/5093]\tLoss_sum:  0.504825( 0.294394)\tCls:  0.077801( 0.057772)\tBox:  0.193596( 0.063804)\tObj:  0.104057( 0.039216)\tRPN  0.129372( 0.133603)\n",
      "[Train]Epoch: [1][1960/5093]\tLoss_sum:  0.302881( 0.293917)\tCls:  0.045916( 0.057645)\tBox:  0.055128( 0.063653)\tObj:  0.063431( 0.039419)\tRPN  0.138406( 0.133200)\n",
      "[Train]Epoch: [1][1970/5093]\tLoss_sum:  0.264877( 0.293837)\tCls:  0.011320( 0.057591)\tBox:  0.017910( 0.063626)\tObj:  0.042608( 0.039433)\tRPN  0.193040( 0.133186)\n",
      "[Train]Epoch: [1][1980/5093]\tLoss_sum:  0.152100( 0.293496)\tCls:  0.041357( 0.057555)\tBox:  0.081294( 0.063731)\tObj:  0.022921( 0.039408)\tRPN  0.006528( 0.132802)\n",
      "[Train]Epoch: [1][1990/5093]\tLoss_sum:  0.336315( 0.293873)\tCls:  0.101921( 0.057654)\tBox:  0.148460( 0.063937)\tObj:  0.023417( 0.039382)\tRPN  0.062517( 0.132901)\n",
      "[Train]Epoch: [1][2000/5093]\tLoss_sum:  0.207553( 0.294155)\tCls:  0.058379( 0.057816)\tBox:  0.103333( 0.064312)\tObj:  0.023655( 0.039340)\tRPN  0.022186( 0.132686)\n",
      "[Train]Epoch: [1][2010/5093]\tLoss_sum:  0.072455( 0.293279)\tCls:  0.024116( 0.057638)\tBox:  0.026015( 0.064064)\tObj:  0.014973( 0.039272)\tRPN  0.007350( 0.132305)\n",
      "[Train]Epoch: [1][2020/5093]\tLoss_sum:  0.042051( 0.293450)\tCls:  0.002801( 0.057842)\tBox:  0.000000( 0.064385)\tObj:  0.005658( 0.039252)\tRPN  0.033592( 0.131971)\n",
      "[Train]Epoch: [1][2030/5093]\tLoss_sum:  0.431875( 0.293544)\tCls:  0.107182( 0.057819)\tBox:  0.209418( 0.064493)\tObj:  0.027660( 0.039172)\tRPN  0.087614( 0.132060)\n",
      "[Train]Epoch: [1][2040/5093]\tLoss_sum:  0.241135( 0.293348)\tCls:  0.057213( 0.057798)\tBox:  0.054555( 0.064546)\tObj:  0.011927( 0.039140)\tRPN  0.117439( 0.131864)\n",
      "[Train]Epoch: [1][2050/5093]\tLoss_sum:  0.071131( 0.292883)\tCls:  0.002193( 0.057679)\tBox:  0.000000( 0.064484)\tObj:  0.020845( 0.039075)\tRPN  0.048094( 0.131646)\n",
      "[Train]Epoch: [1][2060/5093]\tLoss_sum:  0.305215( 0.292507)\tCls:  0.128457( 0.057628)\tBox:  0.114535( 0.064486)\tObj:  0.024114( 0.038978)\tRPN  0.038110( 0.131416)\n",
      "[Train]Epoch: [1][2070/5093]\tLoss_sum:  0.083289( 0.291815)\tCls:  0.004261( 0.057482)\tBox:  0.000000( 0.064243)\tObj:  0.010676( 0.038840)\tRPN  0.068352( 0.131249)\n",
      "[Train]Epoch: [1][2080/5093]\tLoss_sum:  0.224670( 0.291619)\tCls:  0.063709( 0.057361)\tBox:  0.144392( 0.064148)\tObj:  0.011885( 0.038844)\tRPN  0.004683( 0.131265)\n",
      "[Train]Epoch: [1][2090/5093]\tLoss_sum:  0.285765( 0.292015)\tCls:  0.091080( 0.057384)\tBox:  0.141760( 0.064386)\tObj:  0.035650( 0.038821)\tRPN  0.017275( 0.131425)\n",
      "[Train]Epoch: [1][2100/5093]\tLoss_sum:  0.039269( 0.291500)\tCls:  0.000514( 0.057347)\tBox:  0.000000( 0.064335)\tObj:  0.004472( 0.038721)\tRPN  0.034283( 0.131096)\n",
      "[Train]Epoch: [1][2110/5093]\tLoss_sum:  0.586526( 0.291272)\tCls:  0.097464( 0.057259)\tBox:  0.116555( 0.064245)\tObj:  0.057841( 0.038671)\tRPN  0.314667( 0.131098)\n",
      "[Train]Epoch: [1][2120/5093]\tLoss_sum:  0.753342( 0.292764)\tCls:  0.201463( 0.057625)\tBox:  0.377647( 0.065027)\tObj:  0.040527( 0.038679)\tRPN  0.133704( 0.131433)\n",
      "[Train]Epoch: [1][2130/5093]\tLoss_sum:  0.091541( 0.292511)\tCls:  0.022327( 0.057661)\tBox:  0.049373( 0.065156)\tObj:  0.016880( 0.038595)\tRPN  0.002961( 0.131098)\n",
      "[Train]Epoch: [1][2140/5093]\tLoss_sum:  0.077238( 0.291772)\tCls:  0.001448( 0.057530)\tBox:  0.000000( 0.065021)\tObj:  0.003734( 0.038475)\tRPN  0.072056( 0.130747)\n",
      "[Train]Epoch: [1][2150/5093]\tLoss_sum:  0.020113( 0.290604)\tCls:  0.001925( 0.057274)\tBox:  0.000000( 0.064718)\tObj:  0.004296( 0.038339)\tRPN  0.013891( 0.130272)\n",
      "[Train]Epoch: [1][2160/5093]\tLoss_sum:  0.292364( 0.290614)\tCls:  0.100423( 0.057287)\tBox:  0.127561( 0.064833)\tObj:  0.010221( 0.038376)\tRPN  0.054159( 0.130118)\n",
      "[Train]Epoch: [1][2170/5093]\tLoss_sum:  0.289410( 0.291058)\tCls:  0.099654( 0.057421)\tBox:  0.137542( 0.065017)\tObj:  0.047379( 0.038573)\tRPN  0.004835( 0.130047)\n",
      "[Train]Epoch: [1][2180/5093]\tLoss_sum:  0.044392( 0.290426)\tCls:  0.002468( 0.057295)\tBox:  0.000000( 0.064841)\tObj:  0.004100( 0.038548)\tRPN  0.037824( 0.129742)\n",
      "[Train]Epoch: [1][2190/5093]\tLoss_sum:  0.486963( 0.290410)\tCls:  0.151738( 0.057362)\tBox:  0.202959( 0.064975)\tObj:  0.057003( 0.038536)\tRPN  0.075263( 0.129537)\n",
      "[Train]Epoch: [1][2200/5093]\tLoss_sum:  0.176037( 0.290259)\tCls:  0.047889( 0.057284)\tBox:  0.015462( 0.064817)\tObj:  0.040647( 0.038557)\tRPN  0.072040( 0.129602)\n",
      "[Train]Epoch: [1][2210/5093]\tLoss_sum:  0.287151( 0.290505)\tCls:  0.078903( 0.057451)\tBox:  0.126919( 0.065040)\tObj:  0.022777( 0.038510)\tRPN  0.058552( 0.129504)\n",
      "[Train]Epoch: [1][2220/5093]\tLoss_sum:  0.536884( 0.290780)\tCls:  0.097964( 0.057563)\tBox:  0.144067( 0.065213)\tObj:  0.070408( 0.038510)\tRPN  0.224444( 0.129494)\n",
      "[Train]Epoch: [1][2230/5093]\tLoss_sum:  0.108587( 0.291250)\tCls:  0.001384( 0.057744)\tBox:  0.000000( 0.065662)\tObj:  0.011102( 0.038478)\tRPN  0.096101( 0.129366)\n",
      "[Train]Epoch: [1][2240/5093]\tLoss_sum:  0.147568( 0.290893)\tCls:  0.000904( 0.057591)\tBox:  0.000000( 0.065503)\tObj:  0.012292( 0.038387)\tRPN  0.134372( 0.129411)\n",
      "[Train]Epoch: [1][2250/5093]\tLoss_sum:  0.284724( 0.290655)\tCls:  0.001086( 0.057425)\tBox:  0.000000( 0.065392)\tObj:  0.010865( 0.038359)\tRPN  0.272773( 0.129479)\n",
      "[Train]Epoch: [1][2260/5093]\tLoss_sum:  0.185747( 0.290087)\tCls:  0.002194( 0.057177)\tBox:  0.000000( 0.065103)\tObj:  0.042900( 0.038245)\tRPN  0.140653( 0.129562)\n",
      "[Train]Epoch: [1][2270/5093]\tLoss_sum:  0.287697( 0.290271)\tCls:  0.150488( 0.057353)\tBox:  0.095898( 0.065265)\tObj:  0.021206( 0.038268)\tRPN  0.020105( 0.129385)\n",
      "[Train]Epoch: [1][2280/5093]\tLoss_sum:  0.234931( 0.290556)\tCls:  0.057576( 0.057432)\tBox:  0.106876( 0.065366)\tObj:  0.024416( 0.038207)\tRPN  0.046063( 0.129551)\n",
      "[Train]Epoch: [1][2290/5093]\tLoss_sum:  0.018537( 0.290063)\tCls:  0.001044( 0.057396)\tBox:  0.000000( 0.065470)\tObj:  0.005660( 0.038137)\tRPN  0.011833( 0.129060)\n",
      "[Train]Epoch: [1][2300/5093]\tLoss_sum:  0.327315( 0.289573)\tCls:  0.046064( 0.057251)\tBox:  0.165091( 0.065374)\tObj:  0.008341( 0.038083)\tRPN  0.107820( 0.128865)\n",
      "[Train]Epoch: [1][2310/5093]\tLoss_sum:  0.037954( 0.289557)\tCls:  0.008950( 0.057298)\tBox:  0.000000( 0.065439)\tObj:  0.009215( 0.038124)\tRPN  0.019789( 0.128696)\n",
      "[Train]Epoch: [1][2320/5093]\tLoss_sum:  0.544036( 0.290316)\tCls:  0.155001( 0.057463)\tBox:  0.256925( 0.065876)\tObj:  0.041553( 0.038083)\tRPN  0.090556( 0.128894)\n",
      "[Train]Epoch: [1][2330/5093]\tLoss_sum:  0.050310( 0.290085)\tCls:  0.000249( 0.057512)\tBox:  0.000000( 0.065951)\tObj:  0.004310( 0.038036)\tRPN  0.045751( 0.128586)\n",
      "[Train]Epoch: [1][2340/5093]\tLoss_sum:  0.238310( 0.289822)\tCls:  0.018628( 0.057420)\tBox:  0.019173( 0.065937)\tObj:  0.015735( 0.037927)\tRPN  0.184774( 0.128537)\n",
      "[Train]Epoch: [1][2350/5093]\tLoss_sum:  0.552032( 0.290238)\tCls:  0.165115( 0.057482)\tBox:  0.215087( 0.066124)\tObj:  0.021404( 0.037925)\tRPN  0.150427( 0.128708)\n",
      "[Train]Epoch: [1][2360/5093]\tLoss_sum:  0.771575( 0.290978)\tCls:  0.180645( 0.057776)\tBox:  0.287083( 0.066554)\tObj:  0.070224( 0.037876)\tRPN  0.233622( 0.128771)\n",
      "[Train]Epoch: [1][2370/5093]\tLoss_sum:  0.332005( 0.291646)\tCls:  0.057675( 0.057933)\tBox:  0.101695( 0.066937)\tObj:  0.049055( 0.037869)\tRPN  0.123580( 0.128908)\n",
      "[Train]Epoch: [1][2380/5093]\tLoss_sum:  0.049220( 0.291108)\tCls:  0.005853( 0.057842)\tBox:  0.000000( 0.066842)\tObj:  0.014929( 0.037764)\tRPN  0.028438( 0.128660)\n",
      "[Train]Epoch: [1][2390/5093]\tLoss_sum:  0.340437( 0.291218)\tCls:  0.065930( 0.057826)\tBox:  0.141152( 0.066930)\tObj:  0.004079( 0.037694)\tRPN  0.129276( 0.128767)\n",
      "[Train]Epoch: [1][2400/5093]\tLoss_sum:  0.044991( 0.290939)\tCls:  0.000851( 0.057740)\tBox:  0.000000( 0.067003)\tObj:  0.004346( 0.037627)\tRPN  0.039794( 0.128569)\n",
      "[Train]Epoch: [1][2410/5093]\tLoss_sum:  0.022204( 0.289875)\tCls:  0.001302( 0.057509)\tBox:  0.000000( 0.066725)\tObj:  0.004746( 0.037521)\tRPN  0.016156( 0.128120)\n",
      "[Train]Epoch: [1][2420/5093]\tLoss_sum:  0.015024( 0.288957)\tCls:  0.003285( 0.057307)\tBox:  0.000000( 0.066472)\tObj:  0.003604( 0.037407)\tRPN  0.008134( 0.127770)\n",
      "[Train]Epoch: [1][2430/5093]\tLoss_sum:  0.163018( 0.289061)\tCls:  0.021536( 0.057201)\tBox:  0.075130( 0.066366)\tObj:  0.033456( 0.037567)\tRPN  0.032896( 0.127928)\n",
      "[Train]Epoch: [1][2440/5093]\tLoss_sum:  0.076928( 0.288538)\tCls:  0.004636( 0.057083)\tBox:  0.000000( 0.066283)\tObj:  0.042741( 0.037560)\tRPN  0.029552( 0.127613)\n",
      "[Train]Epoch: [1][2450/5093]\tLoss_sum:  0.029198( 0.287529)\tCls:  0.002643( 0.056860)\tBox:  0.000000( 0.066012)\tObj:  0.017216( 0.037489)\tRPN  0.009340( 0.127168)\n",
      "[Train]Epoch: [1][2460/5093]\tLoss_sum:  0.245746( 0.287054)\tCls:  0.036485( 0.056710)\tBox:  0.046346( 0.065805)\tObj:  0.032610( 0.037444)\tRPN  0.130305( 0.127095)\n",
      "[Train]Epoch: [1][2470/5093]\tLoss_sum:  0.015565( 0.286293)\tCls:  0.000626( 0.056533)\tBox:  0.000000( 0.065669)\tObj:  0.003928( 0.037355)\tRPN  0.011011( 0.126735)\n",
      "[Train]Epoch: [1][2480/5093]\tLoss_sum:  0.143037( 0.285576)\tCls:  0.050513( 0.056399)\tBox:  0.058980( 0.065497)\tObj:  0.008862( 0.037255)\tRPN  0.024683( 0.126424)\n",
      "[Train]Epoch: [1][2490/5093]\tLoss_sum:  0.076281( 0.285340)\tCls:  0.000335( 0.056387)\tBox:  0.000000( 0.065585)\tObj:  0.003973( 0.037223)\tRPN  0.071973( 0.126145)\n",
      "[Train]Epoch: [1][2500/5093]\tLoss_sum:  0.479004( 0.284530)\tCls:  0.067135( 0.056191)\tBox:  0.027290( 0.065333)\tObj:  0.056951( 0.037147)\tRPN  0.327628( 0.125859)\n",
      "[Train]Epoch: [1][2510/5093]\tLoss_sum:  0.191171( 0.284784)\tCls:  0.063155( 0.056223)\tBox:  0.079698( 0.065502)\tObj:  0.039745( 0.037109)\tRPN  0.008574( 0.125950)\n",
      "[Train]Epoch: [1][2520/5093]\tLoss_sum:  0.277613( 0.284659)\tCls:  0.001309( 0.056186)\tBox:  0.000000( 0.065536)\tObj:  0.021480( 0.037092)\tRPN  0.254824( 0.125845)\n",
      "[Train]Epoch: [1][2530/5093]\tLoss_sum:  0.524576( 0.284490)\tCls:  0.150686( 0.056125)\tBox:  0.184997( 0.065477)\tObj:  0.013079( 0.036994)\tRPN  0.175814( 0.125895)\n",
      "[Train]Epoch: [1][2540/5093]\tLoss_sum:  0.362413( 0.284544)\tCls:  0.038298( 0.056167)\tBox:  0.093021( 0.065711)\tObj:  0.011211( 0.036951)\tRPN  0.219883( 0.125714)\n",
      "[Train]Epoch: [1][2550/5093]\tLoss_sum:  0.053543( 0.284470)\tCls:  0.007843( 0.056160)\tBox:  0.019101( 0.065895)\tObj:  0.017357( 0.036887)\tRPN  0.009241( 0.125528)\n",
      "[Train]Epoch: [1][2560/5093]\tLoss_sum:  0.239338( 0.283957)\tCls:  0.012947( 0.055984)\tBox:  0.000100( 0.065706)\tObj:  0.017694( 0.036834)\tRPN  0.208597( 0.125433)\n",
      "[Train]Epoch: [1][2570/5093]\tLoss_sum:  0.135978( 0.284068)\tCls:  0.000216( 0.055972)\tBox:  0.000000( 0.065796)\tObj:  0.003569( 0.036777)\tRPN  0.132193( 0.125521)\n",
      "[Train]Epoch: [1][2580/5093]\tLoss_sum:  0.340967( 0.284540)\tCls:  0.138863( 0.056108)\tBox:  0.148991( 0.066027)\tObj:  0.008413( 0.036816)\tRPN  0.044700( 0.125590)\n",
      "[Train]Epoch: [1][2590/5093]\tLoss_sum:  0.172930( 0.284505)\tCls:  0.015812( 0.056094)\tBox:  0.058481( 0.066086)\tObj:  0.004706( 0.036772)\tRPN  0.093931( 0.125553)\n",
      "[Train]Epoch: [1][2600/5093]\tLoss_sum:  0.053683( 0.284439)\tCls:  0.010089( 0.056086)\tBox:  0.000000( 0.066254)\tObj:  0.011969( 0.036736)\tRPN  0.031625( 0.125363)\n",
      "[Train]Epoch: [1][2610/5093]\tLoss_sum:  0.360088( 0.284353)\tCls:  0.075406( 0.056107)\tBox:  0.145663( 0.066295)\tObj:  0.017830( 0.036689)\tRPN  0.121189( 0.125263)\n",
      "[Train]Epoch: [1][2620/5093]\tLoss_sum:  0.375232( 0.284416)\tCls:  0.086669( 0.056127)\tBox:  0.064680( 0.066464)\tObj:  0.088581( 0.036647)\tRPN  0.135303( 0.125178)\n",
      "[Train]Epoch: [1][2630/5093]\tLoss_sum:  0.038281( 0.284093)\tCls:  0.004194( 0.056079)\tBox:  0.000000( 0.066544)\tObj:  0.004991( 0.036611)\tRPN  0.029096( 0.124860)\n",
      "[Train]Epoch: [1][2640/5093]\tLoss_sum:  0.017893( 0.283122)\tCls:  0.001439( 0.055875)\tBox:  0.000000( 0.066292)\tObj:  0.005864( 0.036528)\tRPN  0.010590( 0.124427)\n",
      "[Train]Epoch: [1][2650/5093]\tLoss_sum:  0.362312( 0.283089)\tCls:  0.159732( 0.055954)\tBox:  0.155557( 0.066388)\tObj:  0.006637( 0.036475)\tRPN  0.040385( 0.124271)\n",
      "[Train]Epoch: [1][2660/5093]\tLoss_sum:  0.020567( 0.282384)\tCls:  0.000780( 0.055848)\tBox:  0.000000( 0.066282)\tObj:  0.003459( 0.036376)\tRPN  0.016327( 0.123878)\n",
      "[Train]Epoch: [1][2670/5093]\tLoss_sum:  0.822409( 0.282162)\tCls:  0.370267( 0.055937)\tBox:  0.301828( 0.066345)\tObj:  0.059500( 0.036307)\tRPN  0.090814( 0.123573)\n",
      "[Train]Epoch: [1][2680/5093]\tLoss_sum:  0.226372( 0.282039)\tCls:  0.085105( 0.056031)\tBox:  0.129406( 0.066454)\tObj:  0.006444( 0.036269)\tRPN  0.005417( 0.123285)\n",
      "[Train]Epoch: [1][2690/5093]\tLoss_sum:  0.200007( 0.281482)\tCls:  0.043663( 0.055973)\tBox:  0.056815( 0.066396)\tObj:  0.013343( 0.036182)\tRPN  0.086187( 0.122931)\n",
      "[Train]Epoch: [1][2700/5093]\tLoss_sum:  0.026553( 0.281052)\tCls:  0.000366( 0.055876)\tBox:  0.000000( 0.066385)\tObj:  0.020141( 0.036104)\tRPN  0.006047( 0.122687)\n",
      "[Train]Epoch: [1][2710/5093]\tLoss_sum:  0.172839( 0.280306)\tCls:  0.044244( 0.055732)\tBox:  0.041993( 0.066200)\tObj:  0.006971( 0.036027)\tRPN  0.079631( 0.122347)\n",
      "[Train]Epoch: [1][2720/5093]\tLoss_sum:  0.063841( 0.280067)\tCls:  0.008084( 0.055716)\tBox:  0.000000( 0.066225)\tObj:  0.004928( 0.035966)\tRPN  0.050830( 0.122160)\n",
      "[Train]Epoch: [1][2730/5093]\tLoss_sum:  0.086871( 0.279938)\tCls:  0.004672( 0.055685)\tBox:  0.000000( 0.066304)\tObj:  0.011340( 0.035985)\tRPN  0.070859( 0.121963)\n",
      "[Train]Epoch: [1][2740/5093]\tLoss_sum:  0.206140( 0.279202)\tCls:  0.037936( 0.055524)\tBox:  0.079792( 0.066097)\tObj:  0.015364( 0.035882)\tRPN  0.073048( 0.121698)\n",
      "[Train]Epoch: [1][2750/5093]\tLoss_sum:  0.061117( 0.278608)\tCls:  0.002341( 0.055395)\tBox:  0.000000( 0.065997)\tObj:  0.010979( 0.035770)\tRPN  0.047797( 0.121446)\n",
      "[Train]Epoch: [1][2760/5093]\tLoss_sum:  0.308152( 0.278104)\tCls:  0.117967( 0.055304)\tBox:  0.129119( 0.065915)\tObj:  0.013368( 0.035671)\tRPN  0.047698( 0.121214)\n",
      "[Train]Epoch: [1][2770/5093]\tLoss_sum:  0.237831( 0.278360)\tCls:  0.060118( 0.055417)\tBox:  0.150770( 0.066264)\tObj:  0.012085( 0.035635)\tRPN  0.014859( 0.121045)\n",
      "[Train]Epoch: [1][2780/5093]\tLoss_sum:  0.502170( 0.278243)\tCls:  0.123854( 0.055391)\tBox:  0.306080( 0.066359)\tObj:  0.056860( 0.035574)\tRPN  0.015376( 0.120919)\n",
      "[Train]Epoch: [1][2790/5093]\tLoss_sum:  0.680054( 0.278076)\tCls:  0.338036( 0.055415)\tBox:  0.264525( 0.066409)\tObj:  0.016352( 0.035525)\tRPN  0.061140( 0.120728)\n",
      "[Train]Epoch: [1][2800/5093]\tLoss_sum:  0.079089( 0.278217)\tCls:  0.000293( 0.055514)\tBox:  0.000000( 0.066594)\tObj:  0.003913( 0.035454)\tRPN  0.074883( 0.120655)\n",
      "[Train]Epoch: [1][2810/5093]\tLoss_sum:  0.018456( 0.277339)\tCls:  0.000408( 0.055327)\tBox:  0.000000( 0.066357)\tObj:  0.002521( 0.035340)\tRPN  0.015526( 0.120315)\n",
      "[Train]Epoch: [1][2820/5093]\tLoss_sum:  0.066465( 0.277212)\tCls:  0.001576( 0.055376)\tBox:  0.000000( 0.066418)\tObj:  0.011146( 0.035322)\tRPN  0.053743( 0.120096)\n",
      "[Train]Epoch: [1][2830/5093]\tLoss_sum:  0.022563( 0.276354)\tCls:  0.002622( 0.055194)\tBox:  0.000000( 0.066184)\tObj:  0.009496( 0.035241)\tRPN  0.010445( 0.119735)\n",
      "[Train]Epoch: [1][2840/5093]\tLoss_sum:  0.346623( 0.276436)\tCls:  0.153602( 0.055260)\tBox:  0.124605( 0.066225)\tObj:  0.011407( 0.035190)\tRPN  0.057009( 0.119761)\n",
      "[Train]Epoch: [1][2850/5093]\tLoss_sum:  0.098178( 0.276673)\tCls:  0.012135( 0.055389)\tBox:  0.000000( 0.066489)\tObj:  0.014408( 0.035182)\tRPN  0.071635( 0.119613)\n",
      "[Train]Epoch: [1][2860/5093]\tLoss_sum:  0.253546( 0.276220)\tCls:  0.048380( 0.055298)\tBox:  0.078297( 0.066325)\tObj:  0.022894( 0.035125)\tRPN  0.103975( 0.119473)\n",
      "[Train]Epoch: [1][2870/5093]\tLoss_sum:  0.154906( 0.276155)\tCls:  0.000748( 0.055249)\tBox:  0.000000( 0.066497)\tObj:  0.002468( 0.035051)\tRPN  0.151691( 0.119357)\n",
      "[Train]Epoch: [1][2880/5093]\tLoss_sum:  0.219305( 0.275752)\tCls:  0.000089( 0.055115)\tBox:  0.000000( 0.066337)\tObj:  0.010112( 0.034991)\tRPN  0.209103( 0.119309)\n",
      "[Train]Epoch: [1][2890/5093]\tLoss_sum:  0.506478( 0.276082)\tCls:  0.104484( 0.055132)\tBox:  0.218128( 0.066540)\tObj:  0.033085( 0.034938)\tRPN  0.150781( 0.119472)\n",
      "[Train]Epoch: [1][2900/5093]\tLoss_sum:  0.502301( 0.276230)\tCls:  0.061403( 0.055135)\tBox:  0.058262( 0.066642)\tObj:  0.072048( 0.034909)\tRPN  0.310588( 0.119544)\n",
      "[Train]Epoch: [1][2910/5093]\tLoss_sum:  0.490984( 0.276779)\tCls:  0.077394( 0.055238)\tBox:  0.223906( 0.066969)\tObj:  0.014530( 0.034874)\tRPN  0.175153( 0.119698)\n",
      "[Train]Epoch: [1][2920/5093]\tLoss_sum:  0.212134( 0.276643)\tCls:  0.071689( 0.055221)\tBox:  0.061149( 0.066947)\tObj:  0.029728( 0.034810)\tRPN  0.049568( 0.119666)\n",
      "[Train]Epoch: [1][2930/5093]\tLoss_sum:  0.310541( 0.276720)\tCls:  0.002650( 0.055273)\tBox:  0.000000( 0.067097)\tObj:  0.038523( 0.034761)\tRPN  0.269367( 0.119589)\n",
      "[Train]Epoch: [1][2940/5093]\tLoss_sum:  0.113675( 0.276226)\tCls:  0.008684( 0.055089)\tBox:  0.059727( 0.066889)\tObj:  0.006648( 0.034671)\tRPN  0.038616( 0.119578)\n",
      "[Train]Epoch: [1][2950/5093]\tLoss_sum:  0.083969( 0.276345)\tCls:  0.000383( 0.055193)\tBox:  0.000000( 0.067088)\tObj:  0.005302( 0.034596)\tRPN  0.078284( 0.119467)\n",
      "[Train]Epoch: [1][2960/5093]\tLoss_sum:  0.265333( 0.275906)\tCls:  0.044479( 0.055055)\tBox:  0.063889( 0.066907)\tObj:  0.020715( 0.034551)\tRPN  0.136249( 0.119394)\n",
      "[Train]Epoch: [1][2970/5093]\tLoss_sum:  0.154030( 0.275674)\tCls:  0.077017( 0.055015)\tBox:  0.072147( 0.066893)\tObj:  0.003415( 0.034505)\tRPN  0.001451( 0.119260)\n",
      "[Train]Epoch: [1][2980/5093]\tLoss_sum:  0.136473( 0.275469)\tCls:  0.000332( 0.054870)\tBox:  0.000000( 0.066743)\tObj:  0.005250( 0.034413)\tRPN  0.130891( 0.119444)\n",
      "[Train]Epoch: [1][2990/5093]\tLoss_sum:  0.363761( 0.275368)\tCls:  0.043813( 0.054811)\tBox:  0.089052( 0.066819)\tObj:  0.026803( 0.034359)\tRPN  0.204093( 0.119380)\n",
      "[Train]Epoch: [1][3000/5093]\tLoss_sum:  0.143558( 0.275132)\tCls:  0.000212( 0.054673)\tBox:  0.000000( 0.066680)\tObj:  0.015668( 0.034283)\tRPN  0.127678( 0.119496)\n",
      "[Train]Epoch: [1][3010/5093]\tLoss_sum:  0.178433( 0.274905)\tCls:  0.053433( 0.054603)\tBox:  0.016994( 0.066636)\tObj:  0.027771( 0.034254)\tRPN  0.080235( 0.119411)\n",
      "[Train]Epoch: [1][3020/5093]\tLoss_sum:  0.679820( 0.275385)\tCls:  0.196943( 0.054759)\tBox:  0.234385( 0.066861)\tObj:  0.045475( 0.034261)\tRPN  0.203017( 0.119505)\n",
      "[Train]Epoch: [1][3030/5093]\tLoss_sum:  0.431725( 0.275943)\tCls:  0.045148( 0.054891)\tBox:  0.103667( 0.067211)\tObj:  0.050317( 0.034261)\tRPN  0.232594( 0.119579)\n",
      "[Train]Epoch: [1][3040/5093]\tLoss_sum:  0.261972( 0.276505)\tCls:  0.090707( 0.055087)\tBox:  0.109672( 0.067502)\tObj:  0.011622( 0.034231)\tRPN  0.049971( 0.119685)\n",
      "[Train]Epoch: [1][3050/5093]\tLoss_sum:  0.359719( 0.276560)\tCls:  0.049428( 0.055050)\tBox:  0.085750( 0.067579)\tObj:  0.010959( 0.034181)\tRPN  0.213581( 0.119750)\n",
      "[Train]Epoch: [1][3060/5093]\tLoss_sum:  0.073446( 0.276096)\tCls:  0.000150( 0.054943)\tBox:  0.000000( 0.067500)\tObj:  0.003807( 0.034100)\tRPN  0.069490( 0.119553)\n",
      "[Train]Epoch: [1][3070/5093]\tLoss_sum:  0.270380( 0.276151)\tCls:  0.029721( 0.054836)\tBox:  0.103714( 0.067447)\tObj:  0.008793( 0.034028)\tRPN  0.128152( 0.119839)\n",
      "[Train]Epoch: [1][3080/5093]\tLoss_sum:  0.056998( 0.275998)\tCls:  0.004037( 0.054791)\tBox:  0.000000( 0.067377)\tObj:  0.008927( 0.033960)\tRPN  0.044034( 0.119869)\n",
      "[Train]Epoch: [1][3090/5093]\tLoss_sum:  0.267194( 0.275986)\tCls:  0.001185( 0.054671)\tBox:  0.000000( 0.067280)\tObj:  0.006241( 0.033902)\tRPN  0.259768( 0.120133)\n",
      "[Train]Epoch: [1][3100/5093]\tLoss_sum:  0.194839( 0.275671)\tCls:  0.026347( 0.054529)\tBox:  0.043713( 0.067116)\tObj:  0.024587( 0.033849)\tRPN  0.100192( 0.120177)\n",
      "[Train]Epoch: [1][3110/5093]\tLoss_sum:  0.204530( 0.275562)\tCls:  0.028161( 0.054481)\tBox:  0.059902( 0.067162)\tObj:  0.017490( 0.033783)\tRPN  0.098977( 0.120136)\n",
      "[Train]Epoch: [1][3120/5093]\tLoss_sum:  0.028653( 0.275221)\tCls:  0.006492( 0.054354)\tBox:  0.000000( 0.067029)\tObj:  0.005365( 0.033928)\tRPN  0.016796( 0.119911)\n",
      "[Train]Epoch: [1][3130/5093]\tLoss_sum:  0.251659( 0.275200)\tCls:  0.010084( 0.054298)\tBox:  0.038301( 0.067068)\tObj:  0.136861( 0.033963)\tRPN  0.066413( 0.119870)\n",
      "[Train]Epoch: [1][3140/5093]\tLoss_sum:  0.197733( 0.275042)\tCls:  0.002635( 0.054227)\tBox:  0.000000( 0.067032)\tObj:  0.019149( 0.033974)\tRPN  0.175949( 0.119808)\n",
      "[Train]Epoch: [1][3150/5093]\tLoss_sum:  0.475520( 0.274780)\tCls:  0.044640( 0.054108)\tBox:  0.136990( 0.066937)\tObj:  0.025508( 0.033915)\tRPN  0.268383( 0.119819)\n",
      "[Train]Epoch: [1][3160/5093]\tLoss_sum:  0.058647( 0.274561)\tCls:  0.000205( 0.054032)\tBox:  0.000000( 0.066953)\tObj:  0.005464( 0.033866)\tRPN  0.052978( 0.119711)\n",
      "[Train]Epoch: [1][3170/5093]\tLoss_sum:  0.080903( 0.273828)\tCls:  0.008900( 0.053872)\tBox:  0.019261( 0.066761)\tObj:  0.009188( 0.033786)\tRPN  0.043554( 0.119409)\n",
      "[Train]Epoch: [1][3180/5093]\tLoss_sum:  0.117318( 0.273593)\tCls:  0.020617( 0.053837)\tBox:  0.060531( 0.066723)\tObj:  0.005845( 0.033734)\tRPN  0.030324( 0.119299)\n",
      "[Train]Epoch: [1][3190/5093]\tLoss_sum:  0.269467( 0.273646)\tCls:  0.022122( 0.053825)\tBox:  0.057492( 0.066751)\tObj:  0.010405( 0.033807)\tRPN  0.179448( 0.119263)\n",
      "[Train]Epoch: [1][3200/5093]\tLoss_sum:  0.162990( 0.273273)\tCls:  0.019175( 0.053714)\tBox:  0.060918( 0.066686)\tObj:  0.032999( 0.033783)\tRPN  0.049898( 0.119091)\n",
      "[Train]Epoch: [1][3210/5093]\tLoss_sum:  0.022100( 0.272779)\tCls:  0.002098( 0.053597)\tBox:  0.000000( 0.066609)\tObj:  0.006824( 0.033751)\tRPN  0.013178( 0.118822)\n",
      "[Train]Epoch: [1][3220/5093]\tLoss_sum:  0.142134( 0.272414)\tCls:  0.024704( 0.053488)\tBox:  0.075306( 0.066522)\tObj:  0.011152( 0.033717)\tRPN  0.030973( 0.118687)\n",
      "[Train]Epoch: [1][3230/5093]\tLoss_sum:  0.215604( 0.272108)\tCls:  0.051153( 0.053485)\tBox:  0.158198( 0.066617)\tObj:  0.001480( 0.033643)\tRPN  0.004773( 0.118363)\n",
      "[Train]Epoch: [1][3240/5093]\tLoss_sum:  0.142827( 0.271943)\tCls:  0.021258( 0.053428)\tBox:  0.075681( 0.066583)\tObj:  0.007187( 0.033616)\tRPN  0.038700( 0.118316)\n",
      "[Train]Epoch: [1][3250/5093]\tLoss_sum:  0.069671( 0.271742)\tCls:  0.009832( 0.053326)\tBox:  0.017433( 0.066487)\tObj:  0.024976( 0.033552)\tRPN  0.017430( 0.118377)\n",
      "[Train]Epoch: [1][3260/5093]\tLoss_sum:  0.260082( 0.271823)\tCls:  0.034802( 0.053228)\tBox:  0.077522( 0.066453)\tObj:  0.107531( 0.033827)\tRPN  0.040228( 0.118314)\n",
      "[Train]Epoch: [1][3270/5093]\tLoss_sum:  0.045421( 0.271337)\tCls:  0.002803( 0.053083)\tBox:  0.000000( 0.066277)\tObj:  0.025550( 0.033816)\tRPN  0.017068( 0.118161)\n",
      "[Train]Epoch: [1][3280/5093]\tLoss_sum:  0.320437( 0.271738)\tCls:  0.081208( 0.053127)\tBox:  0.154057( 0.066394)\tObj:  0.026679( 0.034003)\tRPN  0.058493( 0.118213)\n",
      "[Train]Epoch: [1][3290/5093]\tLoss_sum:  0.292994( 0.271518)\tCls:  0.065896( 0.053102)\tBox:  0.066291( 0.066350)\tObj:  0.048919( 0.034028)\tRPN  0.111888( 0.118038)\n",
      "[Train]Epoch: [1][3300/5093]\tLoss_sum:  0.182683( 0.271940)\tCls:  0.038028( 0.053227)\tBox:  0.080305( 0.066556)\tObj:  0.047753( 0.034055)\tRPN  0.016597( 0.118102)\n",
      "[Train]Epoch: [1][3310/5093]\tLoss_sum:  0.225298( 0.271632)\tCls:  0.056800( 0.053188)\tBox:  0.104105( 0.066521)\tObj:  0.051236( 0.034053)\tRPN  0.013157( 0.117870)\n",
      "[Train]Epoch: [1][3320/5093]\tLoss_sum:  0.285838( 0.271629)\tCls:  0.046183( 0.053134)\tBox:  0.143569( 0.066538)\tObj:  0.048891( 0.034125)\tRPN  0.047195( 0.117833)\n",
      "[Train]Epoch: [1][3330/5093]\tLoss_sum:  0.218828( 0.271604)\tCls:  0.046266( 0.053112)\tBox:  0.085638( 0.066578)\tObj:  0.028064( 0.034107)\tRPN  0.058860( 0.117806)\n",
      "[Train]Epoch: [1][3340/5093]\tLoss_sum:  0.795467( 0.271561)\tCls:  0.021288( 0.053072)\tBox:  0.001552( 0.066588)\tObj:  0.110730( 0.034109)\tRPN  0.661897( 0.117792)\n",
      "[Train]Epoch: [1][3350/5093]\tLoss_sum:  0.291553( 0.271778)\tCls:  0.049626( 0.053006)\tBox:  0.077084( 0.066522)\tObj:  0.094765( 0.034300)\tRPN  0.070078( 0.117950)\n",
      "[Train]Epoch: [1][3360/5093]\tLoss_sum:  0.331768( 0.271674)\tCls:  0.099950( 0.052966)\tBox:  0.070363( 0.066456)\tObj:  0.113019( 0.034398)\tRPN  0.048436( 0.117854)\n",
      "[Train]Epoch: [1][3370/5093]\tLoss_sum:  0.269532( 0.271520)\tCls:  0.007365( 0.052913)\tBox:  0.002606( 0.066457)\tObj:  0.016795( 0.034395)\tRPN  0.242767( 0.117755)\n",
      "[Train]Epoch: [1][3380/5093]\tLoss_sum:  0.045470( 0.271264)\tCls:  0.000321( 0.052853)\tBox:  0.000000( 0.066416)\tObj:  0.020884( 0.034349)\tRPN  0.024266( 0.117646)\n",
      "[Train]Epoch: [1][3390/5093]\tLoss_sum:  0.030773( 0.270576)\tCls:  0.000685( 0.052702)\tBox:  0.000000( 0.066220)\tObj:  0.005690( 0.034279)\tRPN  0.024397( 0.117375)\n",
      "[Train]Epoch: [1][3400/5093]\tLoss_sum:  0.319437( 0.270436)\tCls:  0.051528( 0.052627)\tBox:  0.155117( 0.066152)\tObj:  0.040131( 0.034271)\tRPN  0.072661( 0.117386)\n",
      "[Train]Epoch: [1][3410/5093]\tLoss_sum:  0.111034( 0.270062)\tCls:  0.009073( 0.052542)\tBox:  0.000000( 0.066030)\tObj:  0.026302( 0.034251)\tRPN  0.075659( 0.117240)\n",
      "[Train]Epoch: [1][3420/5093]\tLoss_sum:  0.400733( 0.270056)\tCls:  0.048754( 0.052512)\tBox:  0.051780( 0.065990)\tObj:  0.049283( 0.034330)\tRPN  0.250916( 0.117224)\n",
      "[Train]Epoch: [1][3430/5093]\tLoss_sum:  0.185690( 0.269989)\tCls:  0.030139( 0.052503)\tBox:  0.064978( 0.066002)\tObj:  0.077810( 0.034373)\tRPN  0.012763( 0.117111)\n",
      "[Train]Epoch: [1][3440/5093]\tLoss_sum:  0.065430( 0.269746)\tCls:  0.000289( 0.052445)\tBox:  0.000000( 0.065968)\tObj:  0.017166( 0.034365)\tRPN  0.047975( 0.116967)\n",
      "[Train]Epoch: [1][3450/5093]\tLoss_sum:  0.075037( 0.269410)\tCls:  0.000425( 0.052335)\tBox:  0.000000( 0.065892)\tObj:  0.007165( 0.034346)\tRPN  0.067447( 0.116838)\n",
      "[Train]Epoch: [1][3460/5093]\tLoss_sum:  0.387090( 0.269116)\tCls:  0.080999( 0.052297)\tBox:  0.170202( 0.065842)\tObj:  0.021091( 0.034304)\tRPN  0.114798( 0.116673)\n",
      "[Train]Epoch: [1][3470/5093]\tLoss_sum:  0.097429( 0.269162)\tCls:  0.001164( 0.052357)\tBox:  0.000000( 0.066019)\tObj:  0.004986( 0.034252)\tRPN  0.091279( 0.116534)\n",
      "[Train]Epoch: [1][3480/5093]\tLoss_sum:  0.403168( 0.269636)\tCls:  0.034254( 0.052404)\tBox:  0.120950( 0.066092)\tObj:  0.022180( 0.034414)\tRPN  0.225785( 0.116727)\n",
      "[Train]Epoch: [1][3490/5093]\tLoss_sum:  0.343359( 0.269595)\tCls:  0.098582( 0.052451)\tBox:  0.125236( 0.066131)\tObj:  0.036498( 0.034469)\tRPN  0.083043( 0.116545)\n",
      "[Train]Epoch: [1][3500/5093]\tLoss_sum:  0.274012( 0.269603)\tCls:  0.072474( 0.052479)\tBox:  0.117538( 0.066212)\tObj:  0.049988( 0.034524)\tRPN  0.034012( 0.116388)\n",
      "[Train]Epoch: [1][3510/5093]\tLoss_sum:  0.109372( 0.269371)\tCls:  0.020067( 0.052454)\tBox:  0.027822( 0.066183)\tObj:  0.039488( 0.034512)\tRPN  0.021995( 0.116222)\n",
      "[Train]Epoch: [1][3520/5093]\tLoss_sum:  0.163185( 0.268735)\tCls:  0.020495( 0.052319)\tBox:  0.032633( 0.066009)\tObj:  0.019047( 0.034453)\tRPN  0.091011( 0.115954)\n",
      "[Train]Epoch: [1][3530/5093]\tLoss_sum:  0.015286( 0.268427)\tCls:  0.003040( 0.052262)\tBox:  0.000000( 0.065923)\tObj:  0.005132( 0.034436)\tRPN  0.007114( 0.115806)\n",
      "[Train]Epoch: [1][3540/5093]\tLoss_sum:  0.128282( 0.268028)\tCls:  0.032506( 0.052169)\tBox:  0.041798( 0.065830)\tObj:  0.007488( 0.034396)\tRPN  0.046490( 0.115633)\n",
      "[Train]Epoch: [1][3550/5093]\tLoss_sum:  0.238293( 0.268009)\tCls:  0.016021( 0.052184)\tBox:  0.070509( 0.065861)\tObj:  0.027144( 0.034356)\tRPN  0.124619( 0.115608)\n",
      "[Train]Epoch: [1][3560/5093]\tLoss_sum:  0.080252( 0.267900)\tCls:  0.000605( 0.052137)\tBox:  0.000000( 0.065840)\tObj:  0.010874( 0.034378)\tRPN  0.068773( 0.115545)\n",
      "[Train]Epoch: [1][3570/5093]\tLoss_sum:  0.044390( 0.267295)\tCls:  0.001177( 0.051998)\tBox:  0.000000( 0.065655)\tObj:  0.020875( 0.034346)\tRPN  0.022337( 0.115296)\n",
      "[Train]Epoch: [1][3580/5093]\tLoss_sum:  0.129239( 0.267347)\tCls:  0.052846( 0.052128)\tBox:  0.060533( 0.065741)\tObj:  0.011940( 0.034357)\tRPN  0.003921( 0.115121)\n",
      "[Train]Epoch: [1][3590/5093]\tLoss_sum:  0.048871( 0.267125)\tCls:  0.006325( 0.052113)\tBox:  0.000000( 0.065721)\tObj:  0.012872( 0.034332)\tRPN  0.029674( 0.114959)\n",
      "[Train]Epoch: [1][3600/5093]\tLoss_sum:  0.151964( 0.266844)\tCls:  0.024852( 0.052064)\tBox:  0.105957( 0.065724)\tObj:  0.009520( 0.034272)\tRPN  0.011635( 0.114784)\n",
      "[Train]Epoch: [1][3610/5093]\tLoss_sum:  0.048800( 0.266313)\tCls:  0.000161( 0.051947)\tBox:  0.000000( 0.065608)\tObj:  0.006130( 0.034212)\tRPN  0.042509( 0.114546)\n",
      "[Train]Epoch: [1][3620/5093]\tLoss_sum:  0.076626( 0.266031)\tCls:  0.000190( 0.051944)\tBox:  0.000000( 0.065576)\tObj:  0.018450( 0.034160)\tRPN  0.057986( 0.114350)\n",
      "[Train]Epoch: [1][3630/5093]\tLoss_sum:  0.230016( 0.265924)\tCls:  0.046413( 0.051925)\tBox:  0.124020( 0.065640)\tObj:  0.014484( 0.034111)\tRPN  0.045099( 0.114248)\n",
      "[Train]Epoch: [1][3640/5093]\tLoss_sum:  0.384377( 0.265932)\tCls:  0.124726( 0.051940)\tBox:  0.225553( 0.065756)\tObj:  0.007803( 0.034062)\tRPN  0.026296( 0.114174)\n",
      "[Train]Epoch: [1][3650/5093]\tLoss_sum:  0.181258( 0.265566)\tCls:  0.047754( 0.051858)\tBox:  0.053510( 0.065645)\tObj:  0.040244( 0.034070)\tRPN  0.039749( 0.113993)\n",
      "[Train]Epoch: [1][3660/5093]\tLoss_sum:  0.070416( 0.265330)\tCls:  0.001810( 0.051927)\tBox:  0.000000( 0.065596)\tObj:  0.004359( 0.034020)\tRPN  0.064246( 0.113787)\n",
      "[Train]Epoch: [1][3670/5093]\tLoss_sum:  0.030563( 0.265163)\tCls:  0.000341( 0.051907)\tBox:  0.000000( 0.065670)\tObj:  0.003638( 0.033977)\tRPN  0.026584( 0.113608)\n",
      "[Train]Epoch: [1][3680/5093]\tLoss_sum:  0.019528( 0.264580)\tCls:  0.001073( 0.051796)\tBox:  0.000000( 0.065545)\tObj:  0.003631( 0.033909)\tRPN  0.014823( 0.113330)\n",
      "[Train]Epoch: [1][3690/5093]\tLoss_sum:  0.366080( 0.264471)\tCls:  0.125117( 0.051800)\tBox:  0.187639( 0.065584)\tObj:  0.009901( 0.033880)\tRPN  0.043424( 0.113207)\n",
      "[Train]Epoch: [1][3700/5093]\tLoss_sum:  0.226842( 0.264485)\tCls:  0.051463( 0.051792)\tBox:  0.123540( 0.065602)\tObj:  0.011194( 0.033843)\tRPN  0.040646( 0.113247)\n",
      "[Train]Epoch: [1][3710/5093]\tLoss_sum:  0.165752( 0.264390)\tCls:  0.050150( 0.051846)\tBox:  0.055023( 0.065627)\tObj:  0.022182( 0.033819)\tRPN  0.038397( 0.113099)\n",
      "[Train]Epoch: [1][3720/5093]\tLoss_sum:  0.043409( 0.264006)\tCls:  0.001430( 0.051777)\tBox:  0.000000( 0.065550)\tObj:  0.026644( 0.033809)\tRPN  0.015335( 0.112870)\n",
      "[Train]Epoch: [1][3730/5093]\tLoss_sum:  0.172250( 0.263823)\tCls:  0.042703( 0.051772)\tBox:  0.055224( 0.065528)\tObj:  0.009292( 0.033768)\tRPN  0.065031( 0.112755)\n",
      "[Train]Epoch: [1][3740/5093]\tLoss_sum:  0.038677( 0.263927)\tCls:  0.000578( 0.051921)\tBox:  0.000000( 0.065709)\tObj:  0.004437( 0.033717)\tRPN  0.033661( 0.112581)\n",
      "[Train]Epoch: [1][3750/5093]\tLoss_sum:  0.011359( 0.263622)\tCls:  0.000257( 0.051847)\tBox:  0.000000( 0.065647)\tObj:  0.004662( 0.033672)\tRPN  0.006440( 0.112456)\n",
      "[Train]Epoch: [1][3760/5093]\tLoss_sum:  0.118079( 0.263145)\tCls:  0.063713( 0.051753)\tBox:  0.035762( 0.065526)\tObj:  0.006376( 0.033611)\tRPN  0.012228( 0.112254)\n",
      "[Train]Epoch: [1][3770/5093]\tLoss_sum:  0.074495( 0.262988)\tCls:  0.000963( 0.051773)\tBox:  0.000000( 0.065544)\tObj:  0.004206( 0.033564)\tRPN  0.069327( 0.112107)\n",
      "[Train]Epoch: [1][3780/5093]\tLoss_sum:  0.261903( 0.263101)\tCls:  0.007399( 0.051728)\tBox:  0.000000( 0.065463)\tObj:  0.056476( 0.033798)\tRPN  0.198028( 0.112112)\n",
      "[Train]Epoch: [1][3790/5093]\tLoss_sum:  0.431362( 0.263043)\tCls:  0.109168( 0.051690)\tBox:  0.094278( 0.065373)\tObj:  0.061789( 0.033887)\tRPN  0.166126( 0.112094)\n",
      "[Train]Epoch: [1][3800/5093]\tLoss_sum:  0.118988( 0.262806)\tCls:  0.012676( 0.051593)\tBox:  0.000000( 0.065276)\tObj:  0.020098( 0.033905)\tRPN  0.086214( 0.112032)\n",
      "[Train]Epoch: [1][3810/5093]\tLoss_sum:  0.341691( 0.262840)\tCls:  0.063982( 0.051601)\tBox:  0.081889( 0.065267)\tObj:  0.080031( 0.033920)\tRPN  0.115789( 0.112053)\n",
      "[Train]Epoch: [1][3820/5093]\tLoss_sum:  0.420924( 0.263091)\tCls:  0.025834( 0.051693)\tBox:  0.000000( 0.065345)\tObj:  0.030143( 0.033966)\tRPN  0.364947( 0.112088)\n",
      "[Train]Epoch: [1][3830/5093]\tLoss_sum:  0.813250( 0.263211)\tCls:  0.047423( 0.051701)\tBox:  0.011060( 0.065382)\tObj:  0.345436( 0.034080)\tRPN  0.409331( 0.112048)\n",
      "[Train]Epoch: [1][3840/5093]\tLoss_sum:  0.271146( 0.263308)\tCls:  0.047605( 0.051665)\tBox:  0.103643( 0.065398)\tObj:  0.037251( 0.034143)\tRPN  0.082646( 0.112102)\n",
      "[Train]Epoch: [1][3850/5093]\tLoss_sum:  0.034976( 0.263194)\tCls:  0.005480( 0.051625)\tBox:  0.000000( 0.065458)\tObj:  0.010039( 0.034153)\tRPN  0.019457( 0.111958)\n",
      "[Train]Epoch: [1][3860/5093]\tLoss_sum:  0.178583( 0.263292)\tCls:  0.042843( 0.051666)\tBox:  0.084249( 0.065519)\tObj:  0.035589( 0.034187)\tRPN  0.015903( 0.111920)\n",
      "[Train]Epoch: [1][3870/5093]\tLoss_sum:  0.204204( 0.263106)\tCls:  0.029951( 0.051602)\tBox:  0.054720( 0.065448)\tObj:  0.028285( 0.034157)\tRPN  0.091248( 0.111899)\n",
      "[Train]Epoch: [1][3880/5093]\tLoss_sum:  0.218929( 0.263169)\tCls:  0.033447( 0.051586)\tBox:  0.036484( 0.065547)\tObj:  0.057909( 0.034136)\tRPN  0.091088( 0.111899)\n",
      "[Train]Epoch: [1][3890/5093]\tLoss_sum:  0.030624( 0.263188)\tCls:  0.008685( 0.051588)\tBox:  0.011140( 0.065559)\tObj:  0.003437( 0.034109)\tRPN  0.007361( 0.111932)\n",
      "[Train]Epoch: [1][3900/5093]\tLoss_sum:  0.386384( 0.263247)\tCls:  0.060264( 0.051606)\tBox:  0.200434( 0.065691)\tObj:  0.034871( 0.034078)\tRPN  0.090815( 0.111872)\n",
      "[Train]Epoch: [1][3910/5093]\tLoss_sum:  0.053449( 0.263025)\tCls:  0.000751( 0.051536)\tBox:  0.000000( 0.065716)\tObj:  0.017067( 0.034047)\tRPN  0.035631( 0.111725)\n",
      "[Train]Epoch: [1][3920/5093]\tLoss_sum:  0.054827( 0.262909)\tCls:  0.002188( 0.051511)\tBox:  0.000000( 0.065705)\tObj:  0.021060( 0.034008)\tRPN  0.031579( 0.111685)\n",
      "[Train]Epoch: [1][3930/5093]\tLoss_sum:  0.424078( 0.262409)\tCls:  0.101301( 0.051411)\tBox:  0.019387( 0.065542)\tObj:  0.180643( 0.033997)\tRPN  0.122747( 0.111458)\n",
      "[Train]Epoch: [1][3940/5093]\tLoss_sum:  0.024387( 0.262337)\tCls:  0.000729( 0.051426)\tBox:  0.000000( 0.065629)\tObj:  0.009264( 0.033951)\tRPN  0.014394( 0.111331)\n",
      "[Train]Epoch: [1][3950/5093]\tLoss_sum:  0.026759( 0.261741)\tCls:  0.001585( 0.051298)\tBox:  0.000000( 0.065463)\tObj:  0.013923( 0.033903)\tRPN  0.011252( 0.111077)\n",
      "[Train]Epoch: [1][3960/5093]\tLoss_sum:  0.196596( 0.261162)\tCls:  0.041148( 0.051181)\tBox:  0.073929( 0.065316)\tObj:  0.028895( 0.033842)\tRPN  0.052624( 0.110823)\n",
      "[Train]Epoch: [1][3970/5093]\tLoss_sum:  0.229093( 0.260962)\tCls:  0.070310( 0.051145)\tBox:  0.124300( 0.065334)\tObj:  0.006934( 0.033787)\tRPN  0.027550( 0.110695)\n",
      "[Train]Epoch: [1][3980/5093]\tLoss_sum:  0.134520( 0.260709)\tCls:  0.027501( 0.051114)\tBox:  0.038697( 0.065302)\tObj:  0.013845( 0.033733)\tRPN  0.054477( 0.110559)\n",
      "[Train]Epoch: [1][3990/5093]\tLoss_sum:  0.022613( 0.260385)\tCls:  0.000120( 0.051044)\tBox:  0.000000( 0.065233)\tObj:  0.012028( 0.033673)\tRPN  0.010465( 0.110436)\n",
      "[Train]Epoch: [1][4000/5093]\tLoss_sum:  0.139497( 0.260149)\tCls:  0.055440( 0.051051)\tBox:  0.077145( 0.065222)\tObj:  0.001027( 0.033615)\tRPN  0.005886( 0.110260)\n",
      "[Train]Epoch: [1][4010/5093]\tLoss_sum:  0.140137( 0.260019)\tCls:  0.023529( 0.051000)\tBox:  0.079578( 0.065215)\tObj:  0.030181( 0.033602)\tRPN  0.006849( 0.110200)\n",
      "[Train]Epoch: [1][4020/5093]\tLoss_sum:  0.195467( 0.259969)\tCls:  0.042555( 0.050970)\tBox:  0.048608( 0.065182)\tObj:  0.012279( 0.033556)\tRPN  0.092024( 0.110261)\n",
      "[Train]Epoch: [1][4030/5093]\tLoss_sum:  0.037934( 0.259833)\tCls:  0.002140( 0.051025)\tBox:  0.000000( 0.065244)\tObj:  0.022822( 0.033509)\tRPN  0.012972( 0.110056)\n",
      "[Train]Epoch: [1][4040/5093]\tLoss_sum:  0.213483( 0.259766)\tCls:  0.054761( 0.051024)\tBox:  0.096697( 0.065269)\tObj:  0.034544( 0.033533)\tRPN  0.027481( 0.109940)\n",
      "[Train]Epoch: [1][4050/5093]\tLoss_sum:  0.394319( 0.259950)\tCls:  0.082297( 0.051074)\tBox:  0.100270( 0.065368)\tObj:  0.052567( 0.033532)\tRPN  0.159186( 0.109976)\n",
      "[Train]Epoch: [1][4060/5093]\tLoss_sum:  0.105794( 0.259801)\tCls:  0.000198( 0.051065)\tBox:  0.000000( 0.065373)\tObj:  0.013782( 0.033499)\tRPN  0.091814( 0.109864)\n",
      "[Train]Epoch: [1][4070/5093]\tLoss_sum:  0.232823( 0.259318)\tCls:  0.042310( 0.050950)\tBox:  0.045883( 0.065224)\tObj:  0.039110( 0.033439)\tRPN  0.105519( 0.109705)\n",
      "[Train]Epoch: [1][4080/5093]\tLoss_sum:  0.037723( 0.259316)\tCls:  0.001911( 0.050888)\tBox:  0.000000( 0.065221)\tObj:  0.006790( 0.033564)\tRPN  0.029021( 0.109643)\n",
      "[Train]Epoch: [1][4090/5093]\tLoss_sum:  0.170325( 0.259124)\tCls:  0.025989( 0.050830)\tBox:  0.065040( 0.065197)\tObj:  0.024407( 0.033575)\tRPN  0.054890( 0.109523)\n",
      "[Train]Epoch: [1][4100/5093]\tLoss_sum:  0.319797( 0.258923)\tCls:  0.059235( 0.050770)\tBox:  0.051256( 0.065098)\tObj:  0.029314( 0.033548)\tRPN  0.179992( 0.109507)\n",
      "[Train]Epoch: [1][4110/5093]\tLoss_sum:  0.258301( 0.258633)\tCls:  0.066895( 0.050707)\tBox:  0.155232( 0.065036)\tObj:  0.005457( 0.033497)\tRPN  0.030716( 0.109394)\n",
      "[Train]Epoch: [1][4120/5093]\tLoss_sum:  0.203138( 0.258314)\tCls:  0.037233( 0.050656)\tBox:  0.124287( 0.065025)\tObj:  0.002481( 0.033444)\tRPN  0.039137( 0.109190)\n",
      "[Train]Epoch: [1][4130/5093]\tLoss_sum:  0.151540( 0.258294)\tCls:  0.010671( 0.050609)\tBox:  0.066330( 0.065028)\tObj:  0.023785( 0.033530)\tRPN  0.050753( 0.109127)\n",
      "[Train]Epoch: [1][4140/5093]\tLoss_sum:  0.056086( 0.258089)\tCls:  0.000731( 0.050540)\tBox:  0.000000( 0.064968)\tObj:  0.038716( 0.033510)\tRPN  0.016639( 0.109071)\n",
      "[Train]Epoch: [1][4150/5093]\tLoss_sum:  0.332923( 0.258082)\tCls:  0.051236( 0.050528)\tBox:  0.133471( 0.064986)\tObj:  0.060796( 0.033558)\tRPN  0.087420( 0.109009)\n",
      "[Train]Epoch: [1][4160/5093]\tLoss_sum:  0.094606( 0.258061)\tCls:  0.007404( 0.050524)\tBox:  0.000000( 0.065037)\tObj:  0.029830( 0.033588)\tRPN  0.057372( 0.108911)\n",
      "[Train]Epoch: [1][4170/5093]\tLoss_sum:  0.259952( 0.257839)\tCls:  0.096956( 0.050543)\tBox:  0.059288( 0.065015)\tObj:  0.065477( 0.033570)\tRPN  0.038231( 0.108710)\n",
      "[Train]Epoch: [1][4180/5093]\tLoss_sum:  0.023127( 0.257449)\tCls:  0.000501( 0.050448)\tBox:  0.000000( 0.064909)\tObj:  0.019088( 0.033550)\tRPN  0.003538( 0.108542)\n",
      "[Train]Epoch: [1][4190/5093]\tLoss_sum:  0.214507( 0.257251)\tCls:  0.056412( 0.050391)\tBox:  0.116539( 0.064858)\tObj:  0.027336( 0.033519)\tRPN  0.014219( 0.108483)\n",
      "[Train]Epoch: [1][4200/5093]\tLoss_sum:  0.489206( 0.257241)\tCls:  0.082885( 0.050357)\tBox:  0.215567( 0.064899)\tObj:  0.014866( 0.033503)\tRPN  0.175887( 0.108482)\n",
      "[Train]Epoch: [1][4210/5093]\tLoss_sum:  0.260681( 0.256958)\tCls:  0.041500( 0.050278)\tBox:  0.086641( 0.064838)\tObj:  0.045059( 0.033473)\tRPN  0.087480( 0.108370)\n",
      "[Train]Epoch: [1][4220/5093]\tLoss_sum:  0.649171( 0.256978)\tCls:  0.124128( 0.050257)\tBox:  0.300107( 0.064912)\tObj:  0.062498( 0.033442)\tRPN  0.162438( 0.108367)\n",
      "[Train]Epoch: [1][4230/5093]\tLoss_sum:  0.423343( 0.257598)\tCls:  0.087837( 0.050411)\tBox:  0.213401( 0.065323)\tObj:  0.010118( 0.033433)\tRPN  0.111986( 0.108431)\n",
      "[Train]Epoch: [1][4240/5093]\tLoss_sum:  0.231476( 0.257615)\tCls:  0.018734( 0.050435)\tBox:  0.044494( 0.065370)\tObj:  0.038206( 0.033410)\tRPN  0.130043( 0.108400)\n",
      "[Train]Epoch: [1][4250/5093]\tLoss_sum:  0.069834( 0.257461)\tCls:  0.001260( 0.050383)\tBox:  0.000000( 0.065347)\tObj:  0.008487( 0.033388)\tRPN  0.060087( 0.108342)\n",
      "[Train]Epoch: [1][4260/5093]\tLoss_sum:  0.234098( 0.257301)\tCls:  0.083911( 0.050387)\tBox:  0.105811( 0.065313)\tObj:  0.019403( 0.033342)\tRPN  0.024973( 0.108258)\n",
      "[Train]Epoch: [1][4270/5093]\tLoss_sum:  0.243534( 0.257110)\tCls:  0.050445( 0.050387)\tBox:  0.132461( 0.065360)\tObj:  0.012931( 0.033285)\tRPN  0.047697( 0.108079)\n",
      "[Train]Epoch: [1][4280/5093]\tLoss_sum:  0.455769( 0.257252)\tCls:  0.210116( 0.050455)\tBox:  0.225893( 0.065420)\tObj:  0.012598( 0.033251)\tRPN  0.007161( 0.108127)\n",
      "[Train]Epoch: [1][4290/5093]\tLoss_sum:  0.074686( 0.257010)\tCls:  0.000209( 0.050413)\tBox:  0.000000( 0.065404)\tObj:  0.005918( 0.033191)\tRPN  0.068559( 0.108003)\n",
      "[Train]Epoch: [1][4300/5093]\tLoss_sum:  0.292806( 0.257177)\tCls:  0.127059( 0.050482)\tBox:  0.135341( 0.065501)\tObj:  0.016368( 0.033240)\tRPN  0.014039( 0.107954)\n",
      "[Train]Epoch: [1][4310/5093]\tLoss_sum:  0.097225( 0.257024)\tCls:  0.007930( 0.050450)\tBox:  0.000000( 0.065417)\tObj:  0.027680( 0.033205)\tRPN  0.061614( 0.107952)\n",
      "[Train]Epoch: [1][4320/5093]\tLoss_sum:  0.252094( 0.257111)\tCls:  0.071206( 0.050507)\tBox:  0.141977( 0.065439)\tObj:  0.023041( 0.033198)\tRPN  0.015870( 0.107968)\n",
      "[Train]Epoch: [1][4330/5093]\tLoss_sum:  0.566104( 0.257746)\tCls:  0.143210( 0.050684)\tBox:  0.200356( 0.065653)\tObj:  0.063323( 0.033216)\tRPN  0.159215( 0.108192)\n",
      "[Train]Epoch: [1][4340/5093]\tLoss_sum:  0.120235( 0.257824)\tCls:  0.012098( 0.050734)\tBox:  0.000000( 0.065678)\tObj:  0.028372( 0.033264)\tRPN  0.079765( 0.108149)\n",
      "[Train]Epoch: [1][4350/5093]\tLoss_sum:  0.238863( 0.258042)\tCls:  0.036088( 0.050791)\tBox:  0.087660( 0.065776)\tObj:  0.111070( 0.033286)\tRPN  0.004046( 0.108190)\n",
      "[Train]Epoch: [1][4360/5093]\tLoss_sum:  0.121521( 0.257736)\tCls:  0.004237( 0.050688)\tBox:  0.000000( 0.065639)\tObj:  0.009947( 0.033266)\tRPN  0.107337( 0.108143)\n",
      "[Train]Epoch: [1][4370/5093]\tLoss_sum:  0.170888( 0.257894)\tCls:  0.053546( 0.050811)\tBox:  0.101104( 0.065765)\tObj:  0.009467( 0.033265)\tRPN  0.006770( 0.108053)\n",
      "[Train]Epoch: [1][4380/5093]\tLoss_sum:  0.038133( 0.257401)\tCls:  0.002535( 0.050710)\tBox:  0.000000( 0.065634)\tObj:  0.018317( 0.033216)\tRPN  0.017282( 0.107841)\n",
      "[Train]Epoch: [1][4390/5093]\tLoss_sum:  0.345238( 0.257324)\tCls:  0.060286( 0.050682)\tBox:  0.097566( 0.065632)\tObj:  0.067678( 0.033202)\tRPN  0.119707( 0.107808)\n",
      "[Train]Epoch: [1][4400/5093]\tLoss_sum:  0.145290( 0.257346)\tCls:  0.002029( 0.050706)\tBox:  0.000000( 0.065636)\tObj:  0.023286( 0.033288)\tRPN  0.119974( 0.107716)\n",
      "[Train]Epoch: [1][4410/5093]\tLoss_sum:  0.020032( 0.256903)\tCls:  0.004004( 0.050597)\tBox:  0.000000( 0.065487)\tObj:  0.004639( 0.033258)\tRPN  0.011388( 0.107561)\n",
      "[Train]Epoch: [1][4420/5093]\tLoss_sum:  0.106961( 0.256847)\tCls:  0.005346( 0.050610)\tBox:  0.000000( 0.065497)\tObj:  0.010585( 0.033241)\tRPN  0.091030( 0.107499)\n",
      "[Train]Epoch: [1][4430/5093]\tLoss_sum:  0.041203( 0.256385)\tCls:  0.007238( 0.050501)\tBox:  0.000000( 0.065349)\tObj:  0.023912( 0.033194)\tRPN  0.010052( 0.107340)\n",
      "[Train]Epoch: [1][4440/5093]\tLoss_sum:  0.106394( 0.256605)\tCls:  0.001172( 0.050591)\tBox:  0.000000( 0.065460)\tObj:  0.021340( 0.033173)\tRPN  0.083881( 0.107381)\n",
      "[Train]Epoch: [1][4450/5093]\tLoss_sum:  0.401381( 0.256587)\tCls:  0.076868( 0.050586)\tBox:  0.140601( 0.065464)\tObj:  0.043132( 0.033172)\tRPN  0.140780( 0.107366)\n",
      "[Train]Epoch: [1][4460/5093]\tLoss_sum:  0.220810( 0.256458)\tCls:  0.032855( 0.050582)\tBox:  0.110267( 0.065465)\tObj:  0.026915( 0.033183)\tRPN  0.050773( 0.107228)\n",
      "[Train]Epoch: [1][4470/5093]\tLoss_sum:  0.015862( 0.255996)\tCls:  0.000399( 0.050489)\tBox:  0.000000( 0.065367)\tObj:  0.010409( 0.033131)\tRPN  0.005054( 0.107009)\n",
      "[Train]Epoch: [1][4480/5093]\tLoss_sum:  0.032303( 0.255565)\tCls:  0.000150( 0.050398)\tBox:  0.000000( 0.065276)\tObj:  0.027300( 0.033078)\tRPN  0.004853( 0.106814)\n",
      "[Train]Epoch: [1][4490/5093]\tLoss_sum:  0.090586( 0.255070)\tCls:  0.013779( 0.050302)\tBox:  0.034385( 0.065148)\tObj:  0.024580( 0.033032)\tRPN  0.017842( 0.106589)\n",
      "[Train]Epoch: [1][4500/5093]\tLoss_sum:  0.013473( 0.254959)\tCls:  0.001987( 0.050292)\tBox:  0.000000( 0.065170)\tObj:  0.005951( 0.033093)\tRPN  0.005534( 0.106405)\n",
      "[Train]Epoch: [1][4510/5093]\tLoss_sum:  0.043907( 0.254622)\tCls:  0.001598( 0.050253)\tBox:  0.000000( 0.065093)\tObj:  0.039207( 0.033078)\tRPN  0.003101( 0.106198)\n",
      "[Train]Epoch: [1][4520/5093]\tLoss_sum:  0.293084( 0.254631)\tCls:  0.107804( 0.050299)\tBox:  0.137734( 0.065101)\tObj:  0.030003( 0.033079)\tRPN  0.017542( 0.106152)\n",
      "[Train]Epoch: [1][4530/5093]\tLoss_sum:  0.043881( 0.254454)\tCls:  0.016460( 0.050287)\tBox:  0.000000( 0.065049)\tObj:  0.015434( 0.033079)\tRPN  0.011987( 0.106039)\n",
      "[Train]Epoch: [1][4540/5093]\tLoss_sum:  0.022661( 0.254257)\tCls:  0.003246( 0.050256)\tBox:  0.000000( 0.065028)\tObj:  0.013228( 0.033084)\tRPN  0.006188( 0.105890)\n",
      "[Train]Epoch: [1][4550/5093]\tLoss_sum:  0.275256( 0.253937)\tCls:  0.018398( 0.050174)\tBox:  0.067392( 0.064935)\tObj:  0.011037( 0.033052)\tRPN  0.178428( 0.105776)\n",
      "[Train]Epoch: [1][4560/5093]\tLoss_sum:  0.044229( 0.253608)\tCls:  0.000172( 0.050106)\tBox:  0.000000( 0.064884)\tObj:  0.016033( 0.033006)\tRPN  0.028023( 0.105612)\n",
      "[Train]Epoch: [1][4570/5093]\tLoss_sum:  0.021139( 0.253096)\tCls:  0.014404( 0.050002)\tBox:  0.000000( 0.064742)\tObj:  0.004269( 0.032949)\tRPN  0.002466( 0.105404)\n",
      "[Train]Epoch: [1][4580/5093]\tLoss_sum:  0.286424( 0.253012)\tCls:  0.080169( 0.050005)\tBox:  0.128328( 0.064735)\tObj:  0.011988( 0.032950)\tRPN  0.065939( 0.105322)\n",
      "[Train]Epoch: [1][4590/5093]\tLoss_sum:  0.224538( 0.252969)\tCls:  0.039533( 0.050001)\tBox:  0.089006( 0.064788)\tObj:  0.006039( 0.032929)\tRPN  0.089960( 0.105250)\n",
      "[Train]Epoch: [1][4600/5093]\tLoss_sum:  0.239052( 0.252914)\tCls:  0.056834( 0.049995)\tBox:  0.045815( 0.064837)\tObj:  0.027208( 0.032918)\tRPN  0.109194( 0.105165)\n",
      "[Train]Epoch: [1][4610/5093]\tLoss_sum:  0.327708( 0.252935)\tCls:  0.085694( 0.050014)\tBox:  0.117513( 0.064890)\tObj:  0.015579( 0.032899)\tRPN  0.108922( 0.105131)\n",
      "[Train]Epoch: [1][4620/5093]\tLoss_sum:  0.193293( 0.252953)\tCls:  0.037927( 0.050025)\tBox:  0.085883( 0.064958)\tObj:  0.003829( 0.032874)\tRPN  0.065654( 0.105096)\n",
      "[Train]Epoch: [1][4630/5093]\tLoss_sum:  0.203001( 0.252792)\tCls:  0.027576( 0.049993)\tBox:  0.064247( 0.064955)\tObj:  0.004565( 0.032841)\tRPN  0.106613( 0.105003)\n",
      "[Train]Epoch: [1][4640/5093]\tLoss_sum:  0.277182( 0.252809)\tCls:  0.084525( 0.050051)\tBox:  0.093201( 0.064968)\tObj:  0.036045( 0.032872)\tRPN  0.063412( 0.104917)\n",
      "[Train]Epoch: [1][4650/5093]\tLoss_sum:  0.399101( 0.252621)\tCls:  0.006673( 0.050015)\tBox:  0.003041( 0.064915)\tObj:  0.027167( 0.032851)\tRPN  0.362220( 0.104839)\n",
      "[Train]Epoch: [1][4660/5093]\tLoss_sum:  0.501637( 0.252644)\tCls:  0.051532( 0.050009)\tBox:  0.125058( 0.064918)\tObj:  0.047772( 0.032838)\tRPN  0.277275( 0.104879)\n",
      "[Train]Epoch: [1][4670/5093]\tLoss_sum:  0.433626( 0.252928)\tCls:  0.118440( 0.050113)\tBox:  0.185507( 0.065055)\tObj:  0.028248( 0.032836)\tRPN  0.101431( 0.104924)\n",
      "[Train]Epoch: [1][4680/5093]\tLoss_sum:  0.310277( 0.253346)\tCls:  0.076302( 0.050311)\tBox:  0.104566( 0.065288)\tObj:  0.012507( 0.032801)\tRPN  0.116902( 0.104946)\n",
      "[Train]Epoch: [1][4690/5093]\tLoss_sum:  0.249727( 0.253222)\tCls:  0.067297( 0.050321)\tBox:  0.163923( 0.065320)\tObj:  0.011942( 0.032769)\tRPN  0.006565( 0.104811)\n",
      "[Train]Epoch: [1][4700/5093]\tLoss_sum:  0.360282( 0.253086)\tCls:  0.078391( 0.050240)\tBox:  0.054589( 0.065208)\tObj:  0.030271( 0.032732)\tRPN  0.197031( 0.104906)\n",
      "[Train]Epoch: [1][4710/5093]\tLoss_sum:  0.154588( 0.253114)\tCls:  0.027751( 0.050313)\tBox:  0.111066( 0.065242)\tObj:  0.006229( 0.032737)\tRPN  0.009541( 0.104822)\n",
      "[Train]Epoch: [1][4720/5093]\tLoss_sum:  0.323995( 0.253012)\tCls:  0.006661( 0.050215)\tBox:  0.002731( 0.065105)\tObj:  0.016207( 0.032694)\tRPN  0.298396( 0.104998)\n",
      "[Train]Epoch: [1][4730/5093]\tLoss_sum:  0.154264( 0.253063)\tCls:  0.000912( 0.050173)\tBox:  0.000000( 0.065095)\tObj:  0.005538( 0.032678)\tRPN  0.147813( 0.105118)\n",
      "[Train]Epoch: [1][4740/5093]\tLoss_sum:  0.027006( 0.252868)\tCls:  0.000360( 0.050117)\tBox:  0.000000( 0.065033)\tObj:  0.009430( 0.032659)\tRPN  0.017216( 0.105059)\n",
      "[Train]Epoch: [1][4750/5093]\tLoss_sum:  0.193045( 0.252525)\tCls:  0.005562( 0.050025)\tBox:  0.001183( 0.064917)\tObj:  0.003855( 0.032611)\tRPN  0.182446( 0.104973)\n",
      "[Train]Epoch: [1][4760/5093]\tLoss_sum:  0.009065( 0.252224)\tCls:  0.000342( 0.049943)\tBox:  0.000000( 0.064822)\tObj:  0.004207( 0.032573)\tRPN  0.004517( 0.104887)\n",
      "[Train]Epoch: [1][4770/5093]\tLoss_sum:  0.344071( 0.252102)\tCls:  0.086979( 0.049902)\tBox:  0.128925( 0.064761)\tObj:  0.031664( 0.032549)\tRPN  0.096503( 0.104890)\n",
      "[Train]Epoch: [1][4780/5093]\tLoss_sum:  0.294576( 0.251871)\tCls:  0.072363( 0.049854)\tBox:  0.119104( 0.064730)\tObj:  0.025345( 0.032519)\tRPN  0.077765( 0.104768)\n",
      "[Train]Epoch: [1][4790/5093]\tLoss_sum:  0.414902( 0.251900)\tCls:  0.072166( 0.049856)\tBox:  0.127165( 0.064783)\tObj:  0.020508( 0.032501)\tRPN  0.195064( 0.104760)\n",
      "[Train]Epoch: [1][4800/5093]\tLoss_sum:  0.255874( 0.252223)\tCls:  0.028564( 0.049904)\tBox:  0.003240( 0.064892)\tObj:  0.027686( 0.032507)\tRPN  0.196384( 0.104920)\n",
      "[Train]Epoch: [1][4810/5093]\tLoss_sum:  0.103928( 0.252161)\tCls:  0.019051( 0.049858)\tBox:  0.015994( 0.064864)\tObj:  0.027227( 0.032507)\tRPN  0.041656( 0.104932)\n",
      "[Train]Epoch: [1][4820/5093]\tLoss_sum:  0.195925( 0.251914)\tCls:  0.037379( 0.049792)\tBox:  0.093651( 0.064792)\tObj:  0.005916( 0.032481)\tRPN  0.058979( 0.104848)\n",
      "[Train]Epoch: [1][4830/5093]\tLoss_sum:  0.111704( 0.251843)\tCls:  0.029314( 0.049769)\tBox:  0.015563( 0.064783)\tObj:  0.011370( 0.032474)\tRPN  0.055457( 0.104818)\n",
      "[Train]Epoch: [1][4840/5093]\tLoss_sum:  0.021903( 0.251724)\tCls:  0.004304( 0.049762)\tBox:  0.000000( 0.064778)\tObj:  0.010535( 0.032475)\tRPN  0.007063( 0.104708)\n",
      "[Train]Epoch: [1][4850/5093]\tLoss_sum:  0.230404( 0.251464)\tCls:  0.064369( 0.049750)\tBox:  0.127701( 0.064746)\tObj:  0.036577( 0.032441)\tRPN  0.001757( 0.104527)\n",
      "[Train]Epoch: [1][4860/5093]\tLoss_sum:  0.172717( 0.251095)\tCls:  0.017015( 0.049679)\tBox:  0.034858( 0.064667)\tObj:  0.010133( 0.032405)\tRPN  0.110711( 0.104345)\n",
      "[Train]Epoch: [1][4870/5093]\tLoss_sum:  0.673365( 0.251366)\tCls:  0.109656( 0.049779)\tBox:  0.197726( 0.064776)\tObj:  0.137257( 0.032413)\tRPN  0.228726( 0.104398)\n",
      "[Train]Epoch: [1][4880/5093]\tLoss_sum:  0.030318( 0.251001)\tCls:  0.001430( 0.049719)\tBox:  0.000000( 0.064704)\tObj:  0.021314( 0.032376)\tRPN  0.007574( 0.104202)\n",
      "[Train]Epoch: [1][4890/5093]\tLoss_sum:  0.034220( 0.251081)\tCls:  0.000771( 0.049705)\tBox:  0.000000( 0.064680)\tObj:  0.004892( 0.032362)\tRPN  0.028557( 0.104335)\n",
      "[Train]Epoch: [1][4900/5093]\tLoss_sum:  0.028855( 0.250632)\tCls:  0.000456( 0.049605)\tBox:  0.000000( 0.064548)\tObj:  0.002535( 0.032306)\tRPN  0.025864( 0.104173)\n",
      "[Train]Epoch: [1][4910/5093]\tLoss_sum:  0.062199( 0.250424)\tCls:  0.000703( 0.049546)\tBox:  0.000000( 0.064506)\tObj:  0.003543( 0.032264)\tRPN  0.057953( 0.104108)\n",
      "[Train]Epoch: [1][4920/5093]\tLoss_sum:  0.136392( 0.250488)\tCls:  0.000188( 0.049565)\tBox:  0.000000( 0.064544)\tObj:  0.002785( 0.032308)\tRPN  0.133419( 0.104071)\n",
      "[Train]Epoch: [1][4930/5093]\tLoss_sum:  0.277917( 0.250655)\tCls:  0.120242( 0.049640)\tBox:  0.140271( 0.064635)\tObj:  0.008887( 0.032297)\tRPN  0.008517( 0.104084)\n",
      "[Train]Epoch: [1][4940/5093]\tLoss_sum:  0.541347( 0.250520)\tCls:  0.195500( 0.049618)\tBox:  0.101082( 0.064587)\tObj:  0.062464( 0.032283)\tRPN  0.182302( 0.104032)\n",
      "[Train]Epoch: [1][4950/5093]\tLoss_sum:  0.290063( 0.250836)\tCls:  0.137229( 0.049776)\tBox:  0.092827( 0.064745)\tObj:  0.010190( 0.032291)\tRPN  0.049817( 0.104024)\n",
      "[Train]Epoch: [1][4960/5093]\tLoss_sum:  0.109414( 0.250843)\tCls:  0.002191( 0.049776)\tBox:  0.000000( 0.064795)\tObj:  0.012544( 0.032266)\tRPN  0.094680( 0.104006)\n",
      "[Train]Epoch: [1][4970/5093]\tLoss_sum:  0.338175( 0.250806)\tCls:  0.125933( 0.049796)\tBox:  0.158980( 0.064835)\tObj:  0.027256( 0.032236)\tRPN  0.026005( 0.103940)\n",
      "[Train]Epoch: [1][4980/5093]\tLoss_sum:  0.078179( 0.250575)\tCls:  0.003202( 0.049761)\tBox:  0.000000( 0.064750)\tObj:  0.005490( 0.032190)\tRPN  0.069488( 0.103874)\n",
      "[Train]Epoch: [1][4990/5093]\tLoss_sum:  0.049501( 0.250605)\tCls:  0.015823( 0.049794)\tBox:  0.000000( 0.064761)\tObj:  0.019793( 0.032277)\tRPN  0.013885( 0.103773)\n",
      "[Train]Epoch: [1][5000/5093]\tLoss_sum:  0.072684( 0.250638)\tCls:  0.001637( 0.049776)\tBox:  0.000000( 0.064771)\tObj:  0.013885( 0.032286)\tRPN  0.057163( 0.103805)\n",
      "[Train]Epoch: [1][5010/5093]\tLoss_sum:  0.321221( 0.250812)\tCls:  0.027712( 0.049819)\tBox:  0.085809( 0.064847)\tObj:  0.014056( 0.032314)\tRPN  0.193644( 0.103832)\n",
      "[Train]Epoch: [1][5020/5093]\tLoss_sum:  0.251932( 0.250940)\tCls:  0.048622( 0.049878)\tBox:  0.149537( 0.064967)\tObj:  0.043218( 0.032312)\tRPN  0.010555( 0.103783)\n",
      "[Train]Epoch: [1][5030/5093]\tLoss_sum:  0.034024( 0.250732)\tCls:  0.000418( 0.049797)\tBox:  0.000000( 0.064865)\tObj:  0.004293( 0.032288)\tRPN  0.029314( 0.103782)\n",
      "[Train]Epoch: [1][5040/5093]\tLoss_sum:  0.304105( 0.250496)\tCls:  0.061832( 0.049743)\tBox:  0.111142( 0.064795)\tObj:  0.018475( 0.032264)\tRPN  0.112656( 0.103694)\n",
      "[Train]Epoch: [1][5050/5093]\tLoss_sum:  0.166266( 0.250456)\tCls:  0.000820( 0.049762)\tBox:  0.000000( 0.064867)\tObj:  0.005550( 0.032235)\tRPN  0.159896( 0.103593)\n",
      "[Train]Epoch: [1][5060/5093]\tLoss_sum:  0.035085( 0.250525)\tCls:  0.000341( 0.049816)\tBox:  0.000000( 0.064957)\tObj:  0.005389( 0.032211)\tRPN  0.029355( 0.103541)\n",
      "[Train]Epoch: [1][5070/5093]\tLoss_sum:  0.379585( 0.250337)\tCls:  0.079727( 0.049754)\tBox:  0.206098( 0.064909)\tObj:  0.010654( 0.032186)\tRPN  0.083106( 0.103487)\n",
      "[Train]Epoch: [1][5080/5093]\tLoss_sum:  0.083087( 0.250399)\tCls:  0.000218( 0.049758)\tBox:  0.000000( 0.064969)\tObj:  0.008506( 0.032152)\tRPN  0.074364( 0.103521)\n",
      "[Train]Epoch: [1][5090/5093]\tLoss_sum:  0.232155( 0.250114)\tCls:  0.062906( 0.049701)\tBox:  0.113406( 0.064912)\tObj:  0.008536( 0.032109)\tRPN  0.047308( 0.103392)\n",
      "[Train]Epoch: [2][10/5093]\tLoss_sum:  0.322589( 0.392849)\tCls:  0.063928( 0.073238)\tBox:  0.098177( 0.061358)\tObj:  0.005200( 0.054777)\tRPN  0.155284( 0.203476)\n",
      "[Train]Epoch: [2][20/5093]\tLoss_sum:  0.401464( 0.429217)\tCls:  0.144648( 0.090479)\tBox:  0.144001( 0.103470)\tObj:  0.042050( 0.044665)\tRPN  0.070765( 0.190604)\n",
      "[Train]Epoch: [2][30/5093]\tLoss_sum:  0.465330( 0.463615)\tCls:  0.205318( 0.130114)\tBox:  0.191431( 0.146010)\tObj:  0.034463( 0.048187)\tRPN  0.034118( 0.139303)\n",
      "[Train]Epoch: [2][40/5093]\tLoss_sum:  0.129265( 0.443667)\tCls:  0.000934( 0.133926)\tBox:  0.000000( 0.149066)\tObj:  0.008494( 0.040439)\tRPN  0.119836( 0.120236)\n",
      "[Train]Epoch: [2][50/5093]\tLoss_sum:  0.087112( 0.373078)\tCls:  0.000102( 0.107196)\tBox:  0.000000( 0.119253)\tObj:  0.008681( 0.034241)\tRPN  0.078328( 0.112388)\n",
      "[Train]Epoch: [2][60/5093]\tLoss_sum:  0.090658( 0.328867)\tCls:  0.000184( 0.089345)\tBox:  0.000000( 0.099377)\tObj:  0.004929( 0.029828)\tRPN  0.085545( 0.110317)\n",
      "[Train]Epoch: [2][70/5093]\tLoss_sum:  0.040644( 0.293141)\tCls:  0.000052( 0.076591)\tBox:  0.000000( 0.085181)\tObj:  0.001875( 0.026052)\tRPN  0.038717( 0.105318)\n",
      "[Train]Epoch: [2][80/5093]\tLoss_sum:  0.058966( 0.261874)\tCls:  0.000420( 0.067052)\tBox:  0.000000( 0.074533)\tObj:  0.004861( 0.023424)\tRPN  0.053685( 0.096865)\n",
      "[Train]Epoch: [2][90/5093]\tLoss_sum:  0.022289( 0.238097)\tCls:  0.000065( 0.059628)\tBox:  0.000000( 0.066252)\tObj:  0.003037( 0.021532)\tRPN  0.019187( 0.090686)\n",
      "[Train]Epoch: [2][100/5093]\tLoss_sum:  0.426821( 0.244955)\tCls:  0.160055( 0.064377)\tBox:  0.159727( 0.069880)\tObj:  0.021179( 0.022083)\tRPN  0.085860( 0.088614)\n",
      "[Train]Epoch: [2][110/5093]\tLoss_sum:  0.414040( 0.270075)\tCls:  0.188383( 0.079018)\tBox:  0.205609( 0.084617)\tObj:  0.007273( 0.022212)\tRPN  0.012776( 0.084229)\n",
      "[Train]Epoch: [2][120/5093]\tLoss_sum:  0.061282( 0.272162)\tCls:  0.004355( 0.080213)\tBox:  0.000000( 0.084583)\tObj:  0.002573( 0.021860)\tRPN  0.054354( 0.085506)\n",
      "[Train]Epoch: [2][130/5093]\tLoss_sum:  0.507442( 0.267217)\tCls:  0.099725( 0.076085)\tBox:  0.158101( 0.080763)\tObj:  0.037149( 0.021312)\tRPN  0.212467( 0.089057)\n",
      "[Train]Epoch: [2][140/5093]\tLoss_sum:  0.239532( 0.275656)\tCls:  0.103285( 0.080158)\tBox:  0.088183( 0.086149)\tObj:  0.027934( 0.021439)\tRPN  0.020130( 0.087910)\n",
      "[Train]Epoch: [2][150/5093]\tLoss_sum:  0.158576( 0.274104)\tCls:  0.004571( 0.076070)\tBox:  0.000000( 0.082148)\tObj:  0.005093( 0.020274)\tRPN  0.148912( 0.095613)\n",
      "[Train]Epoch: [2][160/5093]\tLoss_sum:  0.082541( 0.262992)\tCls:  0.001757( 0.071577)\tBox:  0.000000( 0.077013)\tObj:  0.002649( 0.019414)\tRPN  0.078136( 0.094988)\n",
      "[Train]Epoch: [2][170/5093]\tLoss_sum:  0.014822( 0.249689)\tCls:  0.000479( 0.067464)\tBox:  0.000000( 0.072483)\tObj:  0.002903( 0.018629)\tRPN  0.011440( 0.091112)\n",
      "[Train]Epoch: [2][180/5093]\tLoss_sum:  0.039513( 0.237281)\tCls:  0.000353( 0.063738)\tBox:  0.000000( 0.068456)\tObj:  0.003001( 0.017844)\tRPN  0.036160( 0.087243)\n",
      "[Train]Epoch: [2][190/5093]\tLoss_sum:  0.020627( 0.225868)\tCls:  0.000135( 0.060441)\tBox:  0.000000( 0.064853)\tObj:  0.002593( 0.017125)\tRPN  0.017899( 0.083449)\n",
      "[Train]Epoch: [2][200/5093]\tLoss_sum:  0.415798( 0.227516)\tCls:  0.083146( 0.059777)\tBox:  0.039347( 0.063503)\tObj:  0.026665( 0.017714)\tRPN  0.266640( 0.086523)\n",
      "[Train]Epoch: [2][210/5093]\tLoss_sum:  0.589161( 0.240759)\tCls:  0.228508( 0.064344)\tBox:  0.237203( 0.070030)\tObj:  0.075710( 0.018245)\tRPN  0.047740( 0.088140)\n",
      "[Train]Epoch: [2][220/5093]\tLoss_sum:  0.281632( 0.247235)\tCls:  0.003944( 0.065225)\tBox:  0.000000( 0.070477)\tObj:  0.003719( 0.018066)\tRPN  0.273969( 0.093466)\n",
      "[Train]Epoch: [2][230/5093]\tLoss_sum:  0.054286( 0.242506)\tCls:  0.006515( 0.062599)\tBox:  0.000000( 0.067413)\tObj:  0.012176( 0.017837)\tRPN  0.035595( 0.094657)\n",
      "[Train]Epoch: [2][240/5093]\tLoss_sum:  0.350143( 0.243334)\tCls:  0.111414( 0.062264)\tBox:  0.118319( 0.067124)\tObj:  0.043221( 0.018675)\tRPN  0.077189( 0.095270)\n",
      "[Train]Epoch: [2][250/5093]\tLoss_sum:  0.456789( 0.254534)\tCls:  0.115599( 0.063617)\tBox:  0.123694( 0.069797)\tObj:  0.053067( 0.020080)\tRPN  0.164429( 0.101039)\n",
      "[Train]Epoch: [2][260/5093]\tLoss_sum:  0.545176( 0.263061)\tCls:  0.059970( 0.065081)\tBox:  0.002677( 0.069829)\tObj:  0.019424( 0.021670)\tRPN  0.463105( 0.106481)\n",
      "[Train]Epoch: [2][270/5093]\tLoss_sum:  0.373929( 0.266900)\tCls:  0.094333( 0.065539)\tBox:  0.157651( 0.070420)\tObj:  0.005019( 0.022071)\tRPN  0.116925( 0.108870)\n",
      "[Train]Epoch: [2][280/5093]\tLoss_sum:  0.238087( 0.270768)\tCls:  0.076109( 0.067227)\tBox:  0.127089( 0.074239)\tObj:  0.015793( 0.022142)\tRPN  0.019096( 0.107160)\n",
      "[Train]Epoch: [2][290/5093]\tLoss_sum:  0.196274( 0.265486)\tCls:  0.001080( 0.065143)\tBox:  0.000000( 0.071912)\tObj:  0.011916( 0.021719)\tRPN  0.183278( 0.106711)\n",
      "[Train]Epoch: [2][300/5093]\tLoss_sum:  0.083145( 0.259892)\tCls:  0.000834( 0.062994)\tBox:  0.000000( 0.069515)\tObj:  0.003378( 0.021216)\tRPN  0.078932( 0.106167)\n",
      "[Train]Epoch: [2][310/5093]\tLoss_sum:  0.272813( 0.264415)\tCls:  0.048048( 0.062397)\tBox:  0.128963( 0.069562)\tObj:  0.081695( 0.023920)\tRPN  0.014107( 0.108536)\n",
      "[Train]Epoch: [2][320/5093]\tLoss_sum:  0.029737( 0.259915)\tCls:  0.001008( 0.060575)\tBox:  0.000000( 0.067482)\tObj:  0.003197( 0.024007)\tRPN  0.025532( 0.107850)\n",
      "[Train]Epoch: [2][330/5093]\tLoss_sum:  0.031032( 0.253711)\tCls:  0.000426( 0.058771)\tBox:  0.000000( 0.065438)\tObj:  0.009147( 0.023695)\tRPN  0.021459( 0.105807)\n",
      "[Train]Epoch: [2][340/5093]\tLoss_sum:  0.610871( 0.256045)\tCls:  0.152554( 0.058963)\tBox:  0.173009( 0.065105)\tObj:  0.040022( 0.023747)\tRPN  0.245286( 0.108230)\n",
      "[Train]Epoch: [2][350/5093]\tLoss_sum:  0.336720( 0.259387)\tCls:  0.126648( 0.060572)\tBox:  0.153940( 0.067048)\tObj:  0.036604( 0.023997)\tRPN  0.019528( 0.107770)\n",
      "[Train]Epoch: [2][360/5093]\tLoss_sum:  0.327528( 0.262319)\tCls:  0.006900( 0.062035)\tBox:  0.000000( 0.069251)\tObj:  0.010657( 0.023975)\tRPN  0.309971( 0.107058)\n",
      "[Train]Epoch: [2][370/5093]\tLoss_sum:  0.250290( 0.267562)\tCls:  0.002244( 0.061559)\tBox:  0.000000( 0.068395)\tObj:  0.009581( 0.024761)\tRPN  0.238464( 0.112847)\n",
      "[Train]Epoch: [2][380/5093]\tLoss_sum:  0.254147( 0.270559)\tCls:  0.099377( 0.062772)\tBox:  0.094047( 0.069809)\tObj:  0.032294( 0.025281)\tRPN  0.028430( 0.112696)\n",
      "[Train]Epoch: [2][390/5093]\tLoss_sum:  0.186205( 0.271709)\tCls:  0.034778( 0.062763)\tBox:  0.087420( 0.069926)\tObj:  0.035866( 0.025235)\tRPN  0.028140( 0.113786)\n",
      "[Train]Epoch: [2][400/5093]\tLoss_sum:  0.404820( 0.272609)\tCls:  0.046751( 0.061553)\tBox:  0.025819( 0.068707)\tObj:  0.057061( 0.025016)\tRPN  0.275189( 0.117333)\n",
      "[Train]Epoch: [2][410/5093]\tLoss_sum:  0.786025( 0.282235)\tCls:  0.045820( 0.061256)\tBox:  0.004321( 0.067403)\tObj:  0.013145( 0.026468)\tRPN  0.722739( 0.127108)\n",
      "[Train]Epoch: [2][420/5093]\tLoss_sum:  0.634168( 0.287058)\tCls:  0.121648( 0.061377)\tBox:  0.136007( 0.067647)\tObj:  0.040797( 0.026752)\tRPN  0.335716( 0.131282)\n",
      "[Train]Epoch: [2][430/5093]\tLoss_sum:  0.308521( 0.292099)\tCls:  0.058782( 0.061883)\tBox:  0.113010( 0.070048)\tObj:  0.023895( 0.026980)\tRPN  0.112833( 0.133188)\n",
      "[Train]Epoch: [2][440/5093]\tLoss_sum:  0.431572( 0.294115)\tCls:  0.045598( 0.061478)\tBox:  0.071782( 0.069522)\tObj:  0.018115( 0.027696)\tRPN  0.296078( 0.135419)\n",
      "[Train]Epoch: [2][450/5093]\tLoss_sum:  0.139171( 0.293995)\tCls:  0.031813( 0.061238)\tBox:  0.029683( 0.069921)\tObj:  0.032708( 0.027994)\tRPN  0.044966( 0.134842)\n",
      "[Train]Epoch: [2][460/5093]\tLoss_sum:  0.084864( 0.290962)\tCls:  0.019720( 0.060354)\tBox:  0.023602( 0.069036)\tObj:  0.025851( 0.028101)\tRPN  0.015691( 0.133472)\n",
      "[Train]Epoch: [2][470/5093]\tLoss_sum:  0.104804( 0.287021)\tCls:  0.038536( 0.059649)\tBox:  0.039131( 0.068205)\tObj:  0.014052( 0.028022)\tRPN  0.013085( 0.131145)\n",
      "[Train]Epoch: [2][480/5093]\tLoss_sum:  0.135046( 0.285407)\tCls:  0.037799( 0.059316)\tBox:  0.031621( 0.067490)\tObj:  0.013687( 0.027882)\tRPN  0.051938( 0.130719)\n",
      "[Train]Epoch: [2][490/5093]\tLoss_sum:  0.242619( 0.284681)\tCls:  0.001566( 0.058835)\tBox:  0.000000( 0.067206)\tObj:  0.012006( 0.027920)\tRPN  0.229047( 0.130720)\n",
      "[Train]Epoch: [2][500/5093]\tLoss_sum:  0.416950( 0.288622)\tCls:  0.068539( 0.058608)\tBox:  0.073511( 0.066308)\tObj:  0.013726( 0.028479)\tRPN  0.261174( 0.135227)\n",
      "[Train]Epoch: [2][510/5093]\tLoss_sum:  0.376993( 0.291418)\tCls:  0.140640( 0.060395)\tBox:  0.125674( 0.067273)\tObj:  0.037039( 0.028776)\tRPN  0.073639( 0.134975)\n",
      "[Train]Epoch: [2][520/5093]\tLoss_sum:  0.151741( 0.290896)\tCls:  0.001265( 0.060525)\tBox:  0.000000( 0.067143)\tObj:  0.004478( 0.029038)\tRPN  0.145997( 0.134190)\n",
      "[Train]Epoch: [2][530/5093]\tLoss_sum:  0.063695( 0.287035)\tCls:  0.003101( 0.059402)\tBox:  0.000000( 0.065877)\tObj:  0.002313( 0.028593)\tRPN  0.058281( 0.133163)\n",
      "[Train]Epoch: [2][540/5093]\tLoss_sum:  0.024296( 0.282879)\tCls:  0.000152( 0.058352)\tBox:  0.000000( 0.064657)\tObj:  0.003384( 0.028246)\tRPN  0.020761( 0.131625)\n",
      "[Train]Epoch: [2][550/5093]\tLoss_sum:  0.361481( 0.283797)\tCls:  0.037809( 0.059225)\tBox:  0.043960( 0.065482)\tObj:  0.019935( 0.028122)\tRPN  0.259776( 0.130968)\n",
      "[Train]Epoch: [2][560/5093]\tLoss_sum:  0.036666( 0.283226)\tCls:  0.000923( 0.059131)\tBox:  0.000000( 0.065676)\tObj:  0.019822( 0.028116)\tRPN  0.015922( 0.130302)\n",
      "[Train]Epoch: [2][570/5093]\tLoss_sum:  0.022890( 0.279258)\tCls:  0.002056( 0.058135)\tBox:  0.000000( 0.064524)\tObj:  0.007389( 0.027949)\tRPN  0.013444( 0.128650)\n",
      "[Train]Epoch: [2][580/5093]\tLoss_sum:  0.454587( 0.276647)\tCls:  0.160135( 0.057829)\tBox:  0.115114( 0.063784)\tObj:  0.051467( 0.027891)\tRPN  0.127872( 0.127144)\n",
      "[Train]Epoch: [2][590/5093]\tLoss_sum:  0.072592( 0.276688)\tCls:  0.000154( 0.058480)\tBox:  0.000000( 0.064862)\tObj:  0.016035( 0.027814)\tRPN  0.056403( 0.125531)\n",
      "[Train]Epoch: [2][600/5093]\tLoss_sum:  0.106109( 0.276594)\tCls:  0.000319( 0.058260)\tBox:  0.000000( 0.065250)\tObj:  0.008050( 0.027676)\tRPN  0.097740( 0.125409)\n",
      "[Train]Epoch: [2][610/5093]\tLoss_sum:  0.026227( 0.272742)\tCls:  0.000210( 0.057315)\tBox:  0.000000( 0.064180)\tObj:  0.002657( 0.027391)\tRPN  0.023360( 0.123855)\n",
      "[Train]Epoch: [2][620/5093]\tLoss_sum:  0.450916( 0.271033)\tCls:  0.066094( 0.056785)\tBox:  0.112514( 0.063853)\tObj:  0.020016( 0.027256)\tRPN  0.252291( 0.123140)\n",
      "[Train]Epoch: [2][630/5093]\tLoss_sum:  0.470201( 0.272541)\tCls:  0.180114( 0.057280)\tBox:  0.125871( 0.064171)\tObj:  0.031706( 0.027346)\tRPN  0.132510( 0.123744)\n",
      "[Train]Epoch: [2][640/5093]\tLoss_sum:  0.057698( 0.270967)\tCls:  0.000317( 0.057195)\tBox:  0.000000( 0.064054)\tObj:  0.002426( 0.027175)\tRPN  0.054954( 0.122544)\n",
      "[Train]Epoch: [2][650/5093]\tLoss_sum:  0.534457( 0.269756)\tCls:  0.181535( 0.056989)\tBox:  0.185474( 0.064003)\tObj:  0.030358( 0.027012)\tRPN  0.137090( 0.121753)\n",
      "[Train]Epoch: [2][660/5093]\tLoss_sum:  0.236930( 0.270534)\tCls:  0.076214( 0.057620)\tBox:  0.119493( 0.064948)\tObj:  0.024204( 0.026912)\tRPN  0.017020( 0.121055)\n",
      "[Train]Epoch: [2][670/5093]\tLoss_sum:  0.175773( 0.271799)\tCls:  0.002728( 0.058496)\tBox:  0.000000( 0.065886)\tObj:  0.010975( 0.026853)\tRPN  0.162071( 0.120563)\n",
      "[Train]Epoch: [2][680/5093]\tLoss_sum:  0.074361( 0.270759)\tCls:  0.001065( 0.058217)\tBox:  0.000000( 0.065558)\tObj:  0.023787( 0.026966)\tRPN  0.049510( 0.120018)\n",
      "[Train]Epoch: [2][690/5093]\tLoss_sum:  0.302031( 0.271063)\tCls:  0.152742( 0.058779)\tBox:  0.117073( 0.065691)\tObj:  0.029628( 0.027453)\tRPN  0.002588( 0.119140)\n",
      "[Train]Epoch: [2][700/5093]\tLoss_sum:  0.433975( 0.272133)\tCls:  0.066374( 0.058643)\tBox:  0.163831( 0.065291)\tObj:  0.039463( 0.027568)\tRPN  0.164307( 0.120631)\n",
      "[Train]Epoch: [2][710/5093]\tLoss_sum:  0.172323( 0.272637)\tCls:  0.091484( 0.058906)\tBox:  0.059475( 0.065789)\tObj:  0.009285( 0.027854)\tRPN  0.012080( 0.120089)\n",
      "[Train]Epoch: [2][720/5093]\tLoss_sum:  0.370221( 0.273744)\tCls:  0.000315( 0.058902)\tBox:  0.000000( 0.065745)\tObj:  0.013905( 0.027741)\tRPN  0.356002( 0.121355)\n",
      "[Train]Epoch: [2][730/5093]\tLoss_sum:  0.525206( 0.276467)\tCls:  0.285336( 0.058991)\tBox:  0.193597( 0.065889)\tObj:  0.016099( 0.027995)\tRPN  0.030173( 0.123592)\n",
      "[Train]Epoch: [2][740/5093]\tLoss_sum:  0.464659( 0.278105)\tCls:  0.053944( 0.059250)\tBox:  0.082478( 0.066340)\tObj:  0.013565( 0.027920)\tRPN  0.314671( 0.124596)\n",
      "[Train]Epoch: [2][750/5093]\tLoss_sum:  0.070019( 0.278244)\tCls:  0.002140( 0.059674)\tBox:  0.000000( 0.066776)\tObj:  0.010145( 0.028042)\tRPN  0.057734( 0.123753)\n",
      "[Train]Epoch: [2][760/5093]\tLoss_sum:  0.108361( 0.275440)\tCls:  0.001529( 0.058943)\tBox:  0.000000( 0.065897)\tObj:  0.004535( 0.027814)\tRPN  0.102296( 0.122786)\n",
      "[Train]Epoch: [2][770/5093]\tLoss_sum:  0.043324( 0.272668)\tCls:  0.000593( 0.058203)\tBox:  0.000000( 0.065041)\tObj:  0.008850( 0.027544)\tRPN  0.033881( 0.121880)\n",
      "[Train]Epoch: [2][780/5093]\tLoss_sum:  0.024529( 0.269687)\tCls:  0.000416( 0.057461)\tBox:  0.000000( 0.064207)\tObj:  0.004671( 0.027296)\tRPN  0.019442( 0.120724)\n",
      "[Train]Epoch: [2][790/5093]\tLoss_sum:  1.069820( 0.269180)\tCls:  0.129317( 0.057216)\tBox:  0.149474( 0.064050)\tObj:  0.536318( 0.027864)\tRPN  0.254710( 0.120050)\n",
      "[Train]Epoch: [2][800/5093]\tLoss_sum:  0.025701( 0.266822)\tCls:  0.000708( 0.056745)\tBox:  0.000000( 0.063559)\tObj:  0.006771( 0.027652)\tRPN  0.018222( 0.118866)\n",
      "[Train]Epoch: [2][810/5093]\tLoss_sum:  0.714304( 0.267177)\tCls:  0.134912( 0.056665)\tBox:  0.185921( 0.063665)\tObj:  0.083466( 0.027577)\tRPN  0.310005( 0.119270)\n",
      "[Train]Epoch: [2][820/5093]\tLoss_sum:  0.018564( 0.267530)\tCls:  0.000180( 0.057238)\tBox:  0.000000( 0.064400)\tObj:  0.003898( 0.027561)\tRPN  0.014487( 0.118330)\n",
      "[Train]Epoch: [2][830/5093]\tLoss_sum:  0.019251( 0.264635)\tCls:  0.000197( 0.056551)\tBox:  0.000000( 0.063624)\tObj:  0.004449( 0.027326)\tRPN  0.014605( 0.117134)\n",
      "[Train]Epoch: [2][840/5093]\tLoss_sum:  0.011745( 0.261756)\tCls:  0.000655( 0.055882)\tBox:  0.000000( 0.062867)\tObj:  0.003044( 0.027110)\tRPN  0.008047( 0.115897)\n",
      "[Train]Epoch: [2][850/5093]\tLoss_sum:  0.056535( 0.258945)\tCls:  0.000769( 0.055227)\tBox:  0.000000( 0.062127)\tObj:  0.003371( 0.026849)\tRPN  0.052395( 0.114742)\n",
      "[Train]Epoch: [2][860/5093]\tLoss_sum:  0.013564( 0.256189)\tCls:  0.000081( 0.054588)\tBox:  0.000000( 0.061405)\tObj:  0.003175( 0.026583)\tRPN  0.010307( 0.113613)\n",
      "[Train]Epoch: [2][870/5093]\tLoss_sum:  0.012118( 0.253425)\tCls:  0.000221( 0.053963)\tBox:  0.000000( 0.060699)\tObj:  0.002520( 0.026343)\tRPN  0.009376( 0.112420)\n",
      "[Train]Epoch: [2][880/5093]\tLoss_sum:  0.008044( 0.250980)\tCls:  0.000387( 0.053411)\tBox:  0.000000( 0.060023)\tObj:  0.002981( 0.026335)\tRPN  0.004676( 0.111212)\n",
      "[Train]Epoch: [2][890/5093]\tLoss_sum:  0.622000( 0.253445)\tCls:  0.090760( 0.054461)\tBox:  0.123953( 0.061044)\tObj:  0.027113( 0.026594)\tRPN  0.380174( 0.111346)\n",
      "[Train]Epoch: [2][900/5093]\tLoss_sum:  0.035365( 0.253328)\tCls:  0.005740( 0.054482)\tBox:  0.000000( 0.061123)\tObj:  0.024898( 0.026979)\tRPN  0.004727( 0.110744)\n",
      "[Train]Epoch: [2][910/5093]\tLoss_sum:  0.344584( 0.254221)\tCls:  0.100608( 0.054434)\tBox:  0.126201( 0.060979)\tObj:  0.050201( 0.027079)\tRPN  0.067574( 0.111730)\n",
      "[Train]Epoch: [2][920/5093]\tLoss_sum:  0.229664( 0.253740)\tCls:  0.092506( 0.054250)\tBox:  0.093522( 0.060770)\tObj:  0.028010( 0.027129)\tRPN  0.015627( 0.111591)\n",
      "[Train]Epoch: [2][930/5093]\tLoss_sum:  0.056589( 0.253311)\tCls:  0.000345( 0.053973)\tBox:  0.000000( 0.060463)\tObj:  0.023946( 0.027148)\tRPN  0.032298( 0.111727)\n",
      "[Train]Epoch: [2][940/5093]\tLoss_sum:  0.437373( 0.253405)\tCls:  0.148012( 0.054089)\tBox:  0.216106( 0.060646)\tObj:  0.047312( 0.027302)\tRPN  0.025943( 0.111368)\n",
      "[Train]Epoch: [2][950/5093]\tLoss_sum:  0.279726( 0.254958)\tCls:  0.044595( 0.054272)\tBox:  0.084223( 0.060760)\tObj:  0.051053( 0.027635)\tRPN  0.099856( 0.112292)\n",
      "[Train]Epoch: [2][960/5093]\tLoss_sum:  0.274840( 0.255523)\tCls:  0.095767( 0.054674)\tBox:  0.091941( 0.061069)\tObj:  0.033373( 0.027764)\tRPN  0.053758( 0.112017)\n",
      "[Train]Epoch: [2][970/5093]\tLoss_sum:  0.019370( 0.254163)\tCls:  0.003212( 0.054379)\tBox:  0.000000( 0.060887)\tObj:  0.011475( 0.027718)\tRPN  0.004683( 0.111179)\n",
      "[Train]Epoch: [2][980/5093]\tLoss_sum:  0.035371( 0.254120)\tCls:  0.002560( 0.054502)\tBox:  0.000000( 0.060878)\tObj:  0.022444( 0.027962)\tRPN  0.010367( 0.110779)\n",
      "[Train]Epoch: [2][990/5093]\tLoss_sum:  0.395203( 0.254019)\tCls:  0.027899( 0.054742)\tBox:  0.000119( 0.060956)\tObj:  0.038579( 0.027987)\tRPN  0.328606( 0.110335)\n",
      "[Train]Epoch: [2][1000/5093]\tLoss_sum:  0.506405( 0.254719)\tCls:  0.114703( 0.055042)\tBox:  0.162913( 0.061302)\tObj:  0.032576( 0.028069)\tRPN  0.196212( 0.110306)\n",
      "[Train]Epoch: [2][1010/5093]\tLoss_sum:  0.021529( 0.254331)\tCls:  0.010832( 0.055066)\tBox:  0.000000( 0.061265)\tObj:  0.003658( 0.027992)\tRPN  0.007038( 0.110009)\n",
      "[Train]Epoch: [2][1020/5093]\tLoss_sum:  0.370321( 0.255383)\tCls:  0.162755( 0.055764)\tBox:  0.188797( 0.061883)\tObj:  0.008283( 0.028157)\tRPN  0.010486( 0.109580)\n",
      "[Train]Epoch: [2][1030/5093]\tLoss_sum:  0.531782( 0.256530)\tCls:  0.045191( 0.055793)\tBox:  0.093247( 0.062020)\tObj:  0.011189( 0.028021)\tRPN  0.382155( 0.110695)\n",
      "[Train]Epoch: [2][1040/5093]\tLoss_sum:  0.443421( 0.257643)\tCls:  0.036305( 0.056194)\tBox:  0.040882( 0.062622)\tObj:  0.008550( 0.028025)\tRPN  0.357684( 0.110802)\n",
      "[Train]Epoch: [2][1050/5093]\tLoss_sum:  0.044520( 0.257637)\tCls:  0.000603( 0.055925)\tBox:  0.000000( 0.062505)\tObj:  0.005636( 0.027853)\tRPN  0.038281( 0.111354)\n",
      "[Train]Epoch: [2][1060/5093]\tLoss_sum:  0.063305( 0.256160)\tCls:  0.001533( 0.055406)\tBox:  0.000000( 0.061915)\tObj:  0.019768( 0.027697)\tRPN  0.042005( 0.111142)\n",
      "[Train]Epoch: [2][1070/5093]\tLoss_sum:  0.336754( 0.255493)\tCls:  0.108611( 0.055525)\tBox:  0.208722( 0.061960)\tObj:  0.005943( 0.027613)\tRPN  0.013479( 0.110396)\n",
      "[Train]Epoch: [2][1080/5093]\tLoss_sum:  0.645767( 0.254739)\tCls:  0.057712( 0.055236)\tBox:  0.012825( 0.061642)\tObj:  0.187794( 0.027612)\tRPN  0.387436( 0.110249)\n",
      "[Train]Epoch: [2][1090/5093]\tLoss_sum:  0.096753( 0.254995)\tCls:  0.002235( 0.055302)\tBox:  0.000000( 0.061728)\tObj:  0.002988( 0.027565)\tRPN  0.091531( 0.110400)\n",
      "[Train]Epoch: [2][1100/5093]\tLoss_sum:  0.498514( 0.254738)\tCls:  0.080981( 0.055132)\tBox:  0.090660( 0.061395)\tObj:  0.031008( 0.027518)\tRPN  0.295866( 0.110694)\n",
      "[Train]Epoch: [2][1110/5093]\tLoss_sum:  0.035382( 0.254091)\tCls:  0.006012( 0.054980)\tBox:  0.000000( 0.061229)\tObj:  0.014247( 0.027538)\tRPN  0.015123( 0.110344)\n",
      "[Train]Epoch: [2][1120/5093]\tLoss_sum:  0.288640( 0.254355)\tCls:  0.087457( 0.055074)\tBox:  0.097208( 0.061353)\tObj:  0.039318( 0.027504)\tRPN  0.064657( 0.110424)\n",
      "[Train]Epoch: [2][1130/5093]\tLoss_sum:  0.078787( 0.253914)\tCls:  0.001703( 0.055020)\tBox:  0.000000( 0.061549)\tObj:  0.017261( 0.027480)\tRPN  0.059822( 0.109864)\n",
      "[Train]Epoch: [2][1140/5093]\tLoss_sum:  0.026257( 0.252023)\tCls:  0.000275( 0.054545)\tBox:  0.000000( 0.061009)\tObj:  0.011246( 0.027371)\tRPN  0.014737( 0.109098)\n",
      "[Train]Epoch: [2][1150/5093]\tLoss_sum:  0.035732( 0.251092)\tCls:  0.000235( 0.054416)\tBox:  0.000000( 0.060912)\tObj:  0.004817( 0.027259)\tRPN  0.030680( 0.108505)\n",
      "[Train]Epoch: [2][1160/5093]\tLoss_sum:  0.378988( 0.249431)\tCls:  0.073453( 0.054032)\tBox:  0.050737( 0.060431)\tObj:  0.024214( 0.027111)\tRPN  0.230584( 0.107857)\n",
      "[Train]Epoch: [2][1170/5093]\tLoss_sum:  0.089456( 0.249200)\tCls:  0.009877( 0.053928)\tBox:  0.002642( 0.060266)\tObj:  0.015875( 0.027199)\tRPN  0.061062( 0.107807)\n",
      "[Train]Epoch: [2][1180/5093]\tLoss_sum:  0.425172( 0.249459)\tCls:  0.148396( 0.054052)\tBox:  0.097711( 0.060426)\tObj:  0.011041( 0.027135)\tRPN  0.168025( 0.107846)\n",
      "[Train]Epoch: [2][1190/5093]\tLoss_sum:  0.040957( 0.248530)\tCls:  0.001445( 0.053801)\tBox:  0.000000( 0.060129)\tObj:  0.010348( 0.027073)\tRPN  0.029164( 0.107527)\n",
      "[Train]Epoch: [2][1200/5093]\tLoss_sum:  0.499683( 0.248348)\tCls:  0.096677( 0.053689)\tBox:  0.078548( 0.059935)\tObj:  0.094087( 0.027113)\tRPN  0.230371( 0.107611)\n",
      "[Train]Epoch: [2][1210/5093]\tLoss_sum:  0.022069( 0.247867)\tCls:  0.005780( 0.053665)\tBox:  0.000000( 0.060036)\tObj:  0.008857( 0.027016)\tRPN  0.007432( 0.107150)\n",
      "[Train]Epoch: [2][1220/5093]\tLoss_sum:  0.023102( 0.246837)\tCls:  0.006037( 0.053455)\tBox:  0.000000( 0.059813)\tObj:  0.003351( 0.026917)\tRPN  0.013713( 0.106652)\n",
      "[Train]Epoch: [2][1230/5093]\tLoss_sum:  0.228300( 0.246437)\tCls:  0.063041( 0.053422)\tBox:  0.046695( 0.059681)\tObj:  0.033637( 0.027055)\tRPN  0.084927( 0.106279)\n",
      "[Train]Epoch: [2][1240/5093]\tLoss_sum:  0.019849( 0.245867)\tCls:  0.000459( 0.053578)\tBox:  0.000000( 0.059735)\tObj:  0.003584( 0.026931)\tRPN  0.015805( 0.105623)\n",
      "[Train]Epoch: [2][1250/5093]\tLoss_sum:  0.010185( 0.244023)\tCls:  0.000413( 0.053172)\tBox:  0.000000( 0.059257)\tObj:  0.004311( 0.026763)\tRPN  0.005461( 0.104831)\n",
      "[Train]Epoch: [2][1260/5093]\tLoss_sum:  0.007630( 0.243275)\tCls:  0.000309( 0.052955)\tBox:  0.000000( 0.059154)\tObj:  0.003657( 0.026624)\tRPN  0.003664( 0.104542)\n",
      "[Train]Epoch: [2][1270/5093]\tLoss_sum:  0.200051( 0.243266)\tCls:  0.045790( 0.052950)\tBox:  0.070614( 0.059310)\tObj:  0.051355( 0.026573)\tRPN  0.032292( 0.104433)\n",
      "[Train]Epoch: [2][1280/5093]\tLoss_sum:  0.015128( 0.241937)\tCls:  0.000219( 0.052673)\tBox:  0.000000( 0.059055)\tObj:  0.002981( 0.026457)\tRPN  0.011928( 0.103751)\n",
      "[Train]Epoch: [2][1290/5093]\tLoss_sum:  0.522429( 0.242010)\tCls:  0.074851( 0.052703)\tBox:  0.041512( 0.059008)\tObj:  0.123927( 0.026473)\tRPN  0.282138( 0.103826)\n",
      "[Train]Epoch: [2][1300/5093]\tLoss_sum:  0.061467( 0.242488)\tCls:  0.000236( 0.052746)\tBox:  0.000000( 0.059229)\tObj:  0.001783( 0.026412)\tRPN  0.059448( 0.104101)\n",
      "[Train]Epoch: [2][1310/5093]\tLoss_sum:  0.452671( 0.242276)\tCls:  0.087527( 0.052602)\tBox:  0.069510( 0.059052)\tObj:  0.024549( 0.026379)\tRPN  0.271085( 0.104243)\n",
      "[Train]Epoch: [2][1320/5093]\tLoss_sum:  0.119049( 0.242774)\tCls:  0.021899( 0.052894)\tBox:  0.038463( 0.059327)\tObj:  0.016695( 0.026355)\tRPN  0.041991( 0.104198)\n",
      "[Train]Epoch: [2][1330/5093]\tLoss_sum:  0.213886( 0.242450)\tCls:  0.039558( 0.052831)\tBox:  0.123297( 0.059502)\tObj:  0.003851( 0.026363)\tRPN  0.047181( 0.103753)\n",
      "[Train]Epoch: [2][1340/5093]\tLoss_sum:  0.278088( 0.243160)\tCls:  0.075078( 0.053124)\tBox:  0.155160( 0.060014)\tObj:  0.020293( 0.026366)\tRPN  0.027557( 0.103656)\n",
      "[Train]Epoch: [2][1350/5093]\tLoss_sum:  0.477093( 0.243418)\tCls:  0.095743( 0.053016)\tBox:  0.171182( 0.059920)\tObj:  0.038266( 0.026288)\tRPN  0.171902( 0.104194)\n",
      "[Train]Epoch: [2][1360/5093]\tLoss_sum:  0.437247( 0.244968)\tCls:  0.028434( 0.053536)\tBox:  0.000000( 0.060656)\tObj:  0.006758( 0.026300)\tRPN  0.402056( 0.104476)\n",
      "[Train]Epoch: [2][1370/5093]\tLoss_sum:  0.140335( 0.245120)\tCls:  0.000289( 0.053563)\tBox:  0.000000( 0.060789)\tObj:  0.024401( 0.026271)\tRPN  0.115644( 0.104497)\n",
      "[Train]Epoch: [2][1380/5093]\tLoss_sum:  0.251840( 0.245595)\tCls:  0.082405( 0.053552)\tBox:  0.058473( 0.060563)\tObj:  0.011706( 0.026201)\tRPN  0.099255( 0.105279)\n",
      "[Train]Epoch: [2][1390/5093]\tLoss_sum:  0.308576( 0.245863)\tCls:  0.100297( 0.053891)\tBox:  0.151128( 0.060979)\tObj:  0.026388( 0.026169)\tRPN  0.030763( 0.104824)\n",
      "[Train]Epoch: [2][1400/5093]\tLoss_sum:  0.473164( 0.245770)\tCls:  0.082289( 0.053942)\tBox:  0.104862( 0.060918)\tObj:  0.059957( 0.026255)\tRPN  0.226057( 0.104654)\n",
      "[Train]Epoch: [2][1410/5093]\tLoss_sum:  0.034341( 0.244730)\tCls:  0.012096( 0.053721)\tBox:  0.000000( 0.060716)\tObj:  0.003225( 0.026174)\tRPN  0.019020( 0.104119)\n",
      "[Train]Epoch: [2][1420/5093]\tLoss_sum:  0.344290( 0.245326)\tCls:  0.083440( 0.053809)\tBox:  0.184943( 0.060923)\tObj:  0.009712( 0.026184)\tRPN  0.066195( 0.104409)\n",
      "[Train]Epoch: [2][1430/5093]\tLoss_sum:  0.338370( 0.245768)\tCls:  0.071333( 0.053991)\tBox:  0.111341( 0.061120)\tObj:  0.002895( 0.026114)\tRPN  0.152800( 0.104543)\n",
      "[Train]Epoch: [2][1440/5093]\tLoss_sum:  0.272395( 0.246086)\tCls:  0.024616( 0.054113)\tBox:  0.013804( 0.061430)\tObj:  0.005574( 0.026085)\tRPN  0.228401( 0.104458)\n",
      "[Train]Epoch: [2][1450/5093]\tLoss_sum:  0.408368( 0.246853)\tCls:  0.064248( 0.054178)\tBox:  0.093355( 0.061884)\tObj:  0.003559( 0.026025)\tRPN  0.247206( 0.104766)\n",
      "[Train]Epoch: [2][1460/5093]\tLoss_sum:  0.023983( 0.246695)\tCls:  0.000404( 0.054158)\tBox:  0.000000( 0.062113)\tObj:  0.003879( 0.025964)\tRPN  0.019701( 0.104459)\n",
      "[Train]Epoch: [2][1470/5093]\tLoss_sum:  0.242813( 0.247587)\tCls:  0.036987( 0.054097)\tBox:  0.092794( 0.062014)\tObj:  0.088229( 0.026166)\tRPN  0.024803( 0.105310)\n",
      "[Train]Epoch: [2][1480/5093]\tLoss_sum:  0.034593( 0.247209)\tCls:  0.007217( 0.054169)\tBox:  0.000000( 0.061973)\tObj:  0.016932( 0.026329)\tRPN  0.010444( 0.104738)\n",
      "[Train]Epoch: [2][1490/5093]\tLoss_sum:  0.321094( 0.248112)\tCls:  0.065048( 0.054456)\tBox:  0.129306( 0.062349)\tObj:  0.029478( 0.026485)\tRPN  0.097263( 0.104821)\n",
      "[Train]Epoch: [2][1500/5093]\tLoss_sum:  0.297948( 0.248677)\tCls:  0.079640( 0.054677)\tBox:  0.111320( 0.062744)\tObj:  0.027592( 0.026453)\tRPN  0.079396( 0.104804)\n",
      "[Train]Epoch: [2][1510/5093]\tLoss_sum:  0.302137( 0.248402)\tCls:  0.057619( 0.054727)\tBox:  0.069838( 0.062702)\tObj:  0.031546( 0.026506)\tRPN  0.143135( 0.104467)\n",
      "[Train]Epoch: [2][1520/5093]\tLoss_sum:  0.135995( 0.249228)\tCls:  0.028043( 0.054893)\tBox:  0.000000( 0.062908)\tObj:  0.082114( 0.027102)\tRPN  0.025838( 0.104326)\n",
      "[Train]Epoch: [2][1530/5093]\tLoss_sum:  0.405456( 0.250715)\tCls:  0.065867( 0.055222)\tBox:  0.166879( 0.063056)\tObj:  0.037869( 0.027238)\tRPN  0.134841( 0.105199)\n",
      "[Train]Epoch: [2][1540/5093]\tLoss_sum:  0.376111( 0.250612)\tCls:  0.081523( 0.055233)\tBox:  0.099612( 0.063024)\tObj:  0.009196( 0.027300)\tRPN  0.185780( 0.105055)\n",
      "[Train]Epoch: [2][1550/5093]\tLoss_sum:  0.162373( 0.250851)\tCls:  0.004564( 0.055395)\tBox:  0.000000( 0.063282)\tObj:  0.013316( 0.027375)\tRPN  0.144494( 0.104799)\n",
      "[Train]Epoch: [2][1560/5093]\tLoss_sum:  0.727632( 0.250577)\tCls:  0.081749( 0.055130)\tBox:  0.016442( 0.062890)\tObj:  0.181779( 0.027428)\tRPN  0.447661( 0.105130)\n",
      "[Train]Epoch: [2][1570/5093]\tLoss_sum:  0.192062( 0.250967)\tCls:  0.045538( 0.055312)\tBox:  0.094019( 0.063239)\tObj:  0.031972( 0.027467)\tRPN  0.020533( 0.104949)\n",
      "[Train]Epoch: [2][1580/5093]\tLoss_sum:  0.096417( 0.251328)\tCls:  0.000980( 0.055432)\tBox:  0.000000( 0.063380)\tObj:  0.007308( 0.027496)\tRPN  0.088129( 0.105020)\n",
      "[Train]Epoch: [2][1590/5093]\tLoss_sum:  0.276088( 0.251861)\tCls:  0.110131( 0.055626)\tBox:  0.126074( 0.063732)\tObj:  0.011099( 0.027569)\tRPN  0.028783( 0.104934)\n",
      "[Train]Epoch: [2][1600/5093]\tLoss_sum:  0.323618( 0.252396)\tCls:  0.094667( 0.055788)\tBox:  0.102450( 0.063893)\tObj:  0.036499( 0.027651)\tRPN  0.090002( 0.105065)\n",
      "[Train]Epoch: [2][1610/5093]\tLoss_sum:  0.469091( 0.253550)\tCls:  0.115661( 0.056071)\tBox:  0.111499( 0.064375)\tObj:  0.037819( 0.027785)\tRPN  0.204111( 0.105318)\n",
      "[Train]Epoch: [2][1620/5093]\tLoss_sum:  0.206230( 0.253289)\tCls:  0.005987( 0.056099)\tBox:  0.000000( 0.064289)\tObj:  0.081958( 0.028030)\tRPN  0.118285( 0.104870)\n",
      "[Train]Epoch: [2][1630/5093]\tLoss_sum:  0.180913( 0.252213)\tCls:  0.035136( 0.055794)\tBox:  0.046903( 0.063924)\tObj:  0.022984( 0.027975)\tRPN  0.075889( 0.104520)\n",
      "[Train]Epoch: [2][1640/5093]\tLoss_sum:  0.407213( 0.252582)\tCls:  0.066589( 0.056066)\tBox:  0.035287( 0.064048)\tObj:  0.030523( 0.027958)\tRPN  0.274814( 0.104510)\n",
      "[Train]Epoch: [2][1650/5093]\tLoss_sum:  0.315171( 0.252749)\tCls:  0.096066( 0.056124)\tBox:  0.151954( 0.064128)\tObj:  0.045142( 0.028039)\tRPN  0.022008( 0.104458)\n",
      "[Train]Epoch: [2][1660/5093]\tLoss_sum:  0.024625( 0.251436)\tCls:  0.001082( 0.055835)\tBox:  0.000000( 0.063781)\tObj:  0.017094( 0.027947)\tRPN  0.006449( 0.103873)\n",
      "[Train]Epoch: [2][1670/5093]\tLoss_sum:  0.012942( 0.250906)\tCls:  0.000890( 0.055758)\tBox:  0.000000( 0.063678)\tObj:  0.006398( 0.027942)\tRPN  0.005654( 0.103528)\n",
      "[Train]Epoch: [2][1680/5093]\tLoss_sum:  0.384535( 0.250981)\tCls:  0.166383( 0.055918)\tBox:  0.168445( 0.063856)\tObj:  0.007119( 0.027892)\tRPN  0.042587( 0.103315)\n",
      "[Train]Epoch: [2][1690/5093]\tLoss_sum:  0.024031( 0.250070)\tCls:  0.000252( 0.055723)\tBox:  0.000000( 0.063712)\tObj:  0.005202( 0.027805)\tRPN  0.018577( 0.102830)\n",
      "[Train]Epoch: [2][1700/5093]\tLoss_sum:  0.006817( 0.248705)\tCls:  0.000698( 0.055401)\tBox:  0.000000( 0.063337)\tObj:  0.003973( 0.027694)\tRPN  0.002146( 0.102272)\n",
      "[Train]Epoch: [2][1710/5093]\tLoss_sum:  0.258903( 0.248827)\tCls:  0.073911( 0.055396)\tBox:  0.063502( 0.063410)\tObj:  0.018166( 0.027626)\tRPN  0.103325( 0.102395)\n",
      "[Train]Epoch: [2][1720/5093]\tLoss_sum:  0.016509( 0.248252)\tCls:  0.000339( 0.055328)\tBox:  0.000000( 0.063341)\tObj:  0.005972( 0.027535)\tRPN  0.010198( 0.102048)\n",
      "[Train]Epoch: [2][1730/5093]\tLoss_sum:  0.033455( 0.247860)\tCls:  0.000915( 0.055263)\tBox:  0.000000( 0.063300)\tObj:  0.006255( 0.027463)\tRPN  0.026285( 0.101834)\n",
      "[Train]Epoch: [2][1740/5093]\tLoss_sum:  0.195430( 0.248129)\tCls:  0.020844( 0.055166)\tBox:  0.068317( 0.063383)\tObj:  0.004181( 0.027493)\tRPN  0.102088( 0.102087)\n",
      "[Train]Epoch: [2][1750/5093]\tLoss_sum:  0.246405( 0.247524)\tCls:  0.049871( 0.054978)\tBox:  0.108425( 0.063198)\tObj:  0.030108( 0.027545)\tRPN  0.058001( 0.101802)\n",
      "[Train]Epoch: [2][1760/5093]\tLoss_sum:  0.057747( 0.246948)\tCls:  0.001059( 0.054937)\tBox:  0.000000( 0.063131)\tObj:  0.005331( 0.027493)\tRPN  0.051357( 0.101386)\n",
      "[Train]Epoch: [2][1770/5093]\tLoss_sum:  0.061786( 0.246291)\tCls:  0.033566( 0.054799)\tBox:  0.020214( 0.063008)\tObj:  0.004777( 0.027473)\tRPN  0.003229( 0.101010)\n",
      "[Train]Epoch: [2][1780/5093]\tLoss_sum:  0.052838( 0.245774)\tCls:  0.002811( 0.054706)\tBox:  0.000000( 0.062958)\tObj:  0.011919( 0.027397)\tRPN  0.038108( 0.100713)\n",
      "[Train]Epoch: [2][1790/5093]\tLoss_sum:  0.385867( 0.245036)\tCls:  0.091198( 0.054522)\tBox:  0.078203( 0.062716)\tObj:  0.034911( 0.027303)\tRPN  0.181555( 0.100495)\n",
      "[Train]Epoch: [2][1800/5093]\tLoss_sum:  0.267561( 0.244462)\tCls:  0.038930( 0.054350)\tBox:  0.042385( 0.062599)\tObj:  0.029731( 0.027233)\tRPN  0.156515( 0.100280)\n",
      "[Train]Epoch: [2][1810/5093]\tLoss_sum:  0.371553( 0.244202)\tCls:  0.060600( 0.054218)\tBox:  0.146637( 0.062637)\tObj:  0.016970( 0.027197)\tRPN  0.147346( 0.100150)\n",
      "[Train]Epoch: [2][1820/5093]\tLoss_sum:  0.068784( 0.244042)\tCls:  0.000616( 0.054178)\tBox:  0.000000( 0.062734)\tObj:  0.021041( 0.027160)\tRPN  0.047127( 0.099970)\n",
      "[Train]Epoch: [2][1830/5093]\tLoss_sum:  0.022483( 0.242870)\tCls:  0.000215( 0.053890)\tBox:  0.000000( 0.062391)\tObj:  0.014478( 0.027079)\tRPN  0.007790( 0.099510)\n",
      "[Train]Epoch: [2][1840/5093]\tLoss_sum:  0.176463( 0.243120)\tCls:  0.054585( 0.053831)\tBox:  0.087049( 0.062440)\tObj:  0.024421( 0.027154)\tRPN  0.010408( 0.099695)\n",
      "[Train]Epoch: [2][1850/5093]\tLoss_sum:  0.052942( 0.241947)\tCls:  0.001257( 0.053552)\tBox:  0.000000( 0.062102)\tObj:  0.044509( 0.027080)\tRPN  0.007176( 0.099213)\n",
      "[Train]Epoch: [2][1860/5093]\tLoss_sum:  0.107416( 0.240880)\tCls:  0.022530( 0.053289)\tBox:  0.028652( 0.061795)\tObj:  0.007358( 0.026985)\tRPN  0.048877( 0.098811)\n",
      "[Train]Epoch: [2][1870/5093]\tLoss_sum:  0.350207( 0.239944)\tCls:  0.064047( 0.053059)\tBox:  0.067893( 0.061526)\tObj:  0.057830( 0.026924)\tRPN  0.160437( 0.098435)\n",
      "[Train]Epoch: [2][1880/5093]\tLoss_sum:  0.009008( 0.239549)\tCls:  0.000163( 0.052987)\tBox:  0.000000( 0.061563)\tObj:  0.005353( 0.026885)\tRPN  0.003492( 0.098115)\n",
      "[Train]Epoch: [2][1890/5093]\tLoss_sum:  0.019780( 0.238863)\tCls:  0.000146( 0.052813)\tBox:  0.000000( 0.061394)\tObj:  0.007718( 0.026839)\tRPN  0.011916( 0.097817)\n",
      "[Train]Epoch: [2][1900/5093]\tLoss_sum:  0.019502( 0.237692)\tCls:  0.010723( 0.052546)\tBox:  0.000000( 0.061071)\tObj:  0.006219( 0.026746)\tRPN  0.002560( 0.097329)\n",
      "[Train]Epoch: [2][1910/5093]\tLoss_sum:  0.021432( 0.237154)\tCls:  0.000655( 0.052428)\tBox:  0.000000( 0.061009)\tObj:  0.017916( 0.026690)\tRPN  0.002861( 0.097027)\n",
      "[Train]Epoch: [2][1920/5093]\tLoss_sum:  0.005319( 0.236556)\tCls:  0.000260( 0.052303)\tBox:  0.000000( 0.060879)\tObj:  0.002367( 0.026619)\tRPN  0.002692( 0.096755)\n",
      "[Train]Epoch: [2][1930/5093]\tLoss_sum:  0.011677( 0.235374)\tCls:  0.000537( 0.052034)\tBox:  0.000000( 0.060564)\tObj:  0.008692( 0.026510)\tRPN  0.002448( 0.096267)\n",
      "[Train]Epoch: [2][1940/5093]\tLoss_sum:  0.660655( 0.235256)\tCls:  0.140962( 0.052115)\tBox:  0.092800( 0.060509)\tObj:  0.117884( 0.026537)\tRPN  0.309009( 0.096095)\n",
      "[Train]Epoch: [2][1950/5093]\tLoss_sum:  0.319194( 0.236020)\tCls:  0.064325( 0.052233)\tBox:  0.130965( 0.060874)\tObj:  0.024041( 0.026620)\tRPN  0.099863( 0.096293)\n",
      "[Train]Epoch: [2][1960/5093]\tLoss_sum:  0.271396( 0.235407)\tCls:  0.029765( 0.052090)\tBox:  0.016771( 0.060709)\tObj:  0.049195( 0.026601)\tRPN  0.175665( 0.096007)\n",
      "[Train]Epoch: [2][1970/5093]\tLoss_sum:  0.206289( 0.235527)\tCls:  0.012778( 0.052085)\tBox:  0.020183( 0.060770)\tObj:  0.009640( 0.026562)\tRPN  0.163689( 0.096110)\n",
      "[Train]Epoch: [2][1980/5093]\tLoss_sum:  0.126779( 0.235486)\tCls:  0.030898( 0.052117)\tBox:  0.078544( 0.061012)\tObj:  0.012590( 0.026533)\tRPN  0.004747( 0.095824)\n",
      "[Train]Epoch: [2][1990/5093]\tLoss_sum:  0.385587( 0.236118)\tCls:  0.114011( 0.052254)\tBox:  0.168319( 0.061273)\tObj:  0.045374( 0.026531)\tRPN  0.057883( 0.096060)\n",
      "[Train]Epoch: [2][2000/5093]\tLoss_sum:  0.150802( 0.236526)\tCls:  0.047035( 0.052409)\tBox:  0.063084( 0.061653)\tObj:  0.009878( 0.026482)\tRPN  0.030805( 0.095981)\n",
      "[Train]Epoch: [2][2010/5093]\tLoss_sum:  0.092988( 0.235874)\tCls:  0.028774( 0.052236)\tBox:  0.021577( 0.061424)\tObj:  0.038075( 0.026438)\tRPN  0.004562( 0.095776)\n",
      "[Train]Epoch: [2][2020/5093]\tLoss_sum:  0.132559( 0.236373)\tCls:  0.001599( 0.052401)\tBox:  0.000000( 0.061736)\tObj:  0.008584( 0.026482)\tRPN  0.122376( 0.095754)\n",
      "[Train]Epoch: [2][2030/5093]\tLoss_sum:  0.423001( 0.236723)\tCls:  0.104462( 0.052409)\tBox:  0.221163( 0.061907)\tObj:  0.017809( 0.026474)\tRPN  0.079568( 0.095932)\n",
      "[Train]Epoch: [2][2040/5093]\tLoss_sum:  0.282001( 0.236875)\tCls:  0.046551( 0.052408)\tBox:  0.040147( 0.061985)\tObj:  0.049944( 0.026596)\tRPN  0.145359( 0.095885)\n",
      "[Train]Epoch: [2][2050/5093]\tLoss_sum:  0.044272( 0.236958)\tCls:  0.006552( 0.052285)\tBox:  0.000000( 0.061910)\tObj:  0.016811( 0.026562)\tRPN  0.020909( 0.096200)\n",
      "[Train]Epoch: [2][2060/5093]\tLoss_sum:  0.227239( 0.236839)\tCls:  0.080674( 0.052217)\tBox:  0.082044( 0.061872)\tObj:  0.034074( 0.026540)\tRPN  0.030447( 0.096209)\n",
      "[Train]Epoch: [2][2070/5093]\tLoss_sum:  0.077556( 0.236329)\tCls:  0.001855( 0.052156)\tBox:  0.000000( 0.061672)\tObj:  0.003679( 0.026464)\tRPN  0.072022( 0.096038)\n",
      "[Train]Epoch: [2][2080/5093]\tLoss_sum:  0.193491( 0.236278)\tCls:  0.044685( 0.052035)\tBox:  0.125003( 0.061570)\tObj:  0.018883( 0.026502)\tRPN  0.004920( 0.096170)\n",
      "[Train]Epoch: [2][2090/5093]\tLoss_sum:  0.183570( 0.236536)\tCls:  0.068380( 0.052040)\tBox:  0.073644( 0.061737)\tObj:  0.021345( 0.026459)\tRPN  0.020201( 0.096300)\n",
      "[Train]Epoch: [2][2100/5093]\tLoss_sum:  0.008976( 0.235997)\tCls:  0.000225( 0.051999)\tBox:  0.000000( 0.061692)\tObj:  0.003114( 0.026391)\tRPN  0.005637( 0.095915)\n",
      "[Train]Epoch: [2][2110/5093]\tLoss_sum:  0.543178( 0.235783)\tCls:  0.101469( 0.051894)\tBox:  0.144630( 0.061600)\tObj:  0.025968( 0.026353)\tRPN  0.271111( 0.095935)\n",
      "[Train]Epoch: [2][2120/5093]\tLoss_sum:  0.694059( 0.237265)\tCls:  0.190284( 0.052222)\tBox:  0.338108( 0.062417)\tObj:  0.046997( 0.026327)\tRPN  0.118670( 0.096300)\n",
      "[Train]Epoch: [2][2130/5093]\tLoss_sum:  0.093070( 0.237070)\tCls:  0.043158( 0.052242)\tBox:  0.047461( 0.062488)\tObj:  0.000623( 0.026261)\tRPN  0.001828( 0.096080)\n",
      "[Train]Epoch: [2][2140/5093]\tLoss_sum:  0.083322( 0.236529)\tCls:  0.000473( 0.052138)\tBox:  0.000000( 0.062365)\tObj:  0.022514( 0.026212)\tRPN  0.060335( 0.095815)\n",
      "[Train]Epoch: [2][2150/5093]\tLoss_sum:  0.008699( 0.235568)\tCls:  0.002545( 0.051907)\tBox:  0.000000( 0.062075)\tObj:  0.002730( 0.026123)\tRPN  0.003424( 0.095464)\n",
      "[Train]Epoch: [2][2160/5093]\tLoss_sum:  0.239043( 0.235657)\tCls:  0.065173( 0.051902)\tBox:  0.095664( 0.062122)\tObj:  0.042225( 0.026168)\tRPN  0.035981( 0.095465)\n",
      "[Train]Epoch: [2][2170/5093]\tLoss_sum:  0.266663( 0.236017)\tCls:  0.097919( 0.052034)\tBox:  0.141457( 0.062390)\tObj:  0.021669( 0.026156)\tRPN  0.005618( 0.095437)\n",
      "[Train]Epoch: [2][2180/5093]\tLoss_sum:  0.027712( 0.235528)\tCls:  0.001234( 0.051938)\tBox:  0.000000( 0.062224)\tObj:  0.012047( 0.026140)\tRPN  0.014430( 0.095227)\n",
      "[Train]Epoch: [2][2190/5093]\tLoss_sum:  0.416298( 0.235703)\tCls:  0.155338( 0.052025)\tBox:  0.167829( 0.062393)\tObj:  0.033677( 0.026178)\tRPN  0.059453( 0.095107)\n",
      "[Train]Epoch: [2][2200/5093]\tLoss_sum:  0.151764( 0.235508)\tCls:  0.052142( 0.051948)\tBox:  0.032118( 0.062262)\tObj:  0.026746( 0.026156)\tRPN  0.040758( 0.095142)\n",
      "[Train]Epoch: [2][2210/5093]\tLoss_sum:  0.216224( 0.235788)\tCls:  0.054674( 0.052102)\tBox:  0.101040( 0.062488)\tObj:  0.013862( 0.026119)\tRPN  0.046648( 0.095079)\n",
      "[Train]Epoch: [2][2220/5093]\tLoss_sum:  0.429805( 0.236000)\tCls:  0.063107( 0.052141)\tBox:  0.133215( 0.062587)\tObj:  0.033112( 0.026109)\tRPN  0.200372( 0.095164)\n",
      "[Train]Epoch: [2][2230/5093]\tLoss_sum:  0.086456( 0.236573)\tCls:  0.000579( 0.052356)\tBox:  0.000000( 0.063019)\tObj:  0.004943( 0.026079)\tRPN  0.080934( 0.095119)\n",
      "[Train]Epoch: [2][2240/5093]\tLoss_sum:  0.070900( 0.236487)\tCls:  0.000230( 0.052228)\tBox:  0.000000( 0.062909)\tObj:  0.003253( 0.026073)\tRPN  0.067418( 0.095278)\n",
      "[Train]Epoch: [2][2250/5093]\tLoss_sum:  0.152004( 0.236252)\tCls:  0.000411( 0.052073)\tBox:  0.000000( 0.062814)\tObj:  0.012100( 0.026019)\tRPN  0.139492( 0.095345)\n",
      "[Train]Epoch: [2][2260/5093]\tLoss_sum:  0.059176( 0.235519)\tCls:  0.001374( 0.051848)\tBox:  0.000000( 0.062536)\tObj:  0.004084( 0.025922)\tRPN  0.053718( 0.095213)\n",
      "[Train]Epoch: [2][2270/5093]\tLoss_sum:  0.334895( 0.235834)\tCls:  0.140083( 0.052033)\tBox:  0.173234( 0.062768)\tObj:  0.003284( 0.025909)\tRPN  0.018294( 0.095123)\n",
      "[Train]Epoch: [2][2280/5093]\tLoss_sum:  0.174254( 0.236170)\tCls:  0.045711( 0.052128)\tBox:  0.078475( 0.062841)\tObj:  0.005823( 0.025852)\tRPN  0.044245( 0.095349)\n",
      "[Train]Epoch: [2][2290/5093]\tLoss_sum:  0.057102( 0.235876)\tCls:  0.000809( 0.052067)\tBox:  0.000000( 0.062870)\tObj:  0.006648( 0.025790)\tRPN  0.049645( 0.095148)\n",
      "[Train]Epoch: [2][2300/5093]\tLoss_sum:  0.304140( 0.235620)\tCls:  0.037608( 0.051938)\tBox:  0.157445( 0.062790)\tObj:  0.018827( 0.025748)\tRPN  0.090259( 0.095143)\n",
      "[Train]Epoch: [2][2310/5093]\tLoss_sum:  0.071401( 0.235788)\tCls:  0.001773( 0.052000)\tBox:  0.000000( 0.062927)\tObj:  0.004709( 0.025703)\tRPN  0.064918( 0.095158)\n",
      "[Train]Epoch: [2][2320/5093]\tLoss_sum:  0.557965( 0.236513)\tCls:  0.158749( 0.052134)\tBox:  0.229162( 0.063307)\tObj:  0.087741( 0.025697)\tRPN  0.082314( 0.095375)\n",
      "[Train]Epoch: [2][2330/5093]\tLoss_sum:  0.064568( 0.236535)\tCls:  0.000103( 0.052214)\tBox:  0.000000( 0.063429)\tObj:  0.003093( 0.025642)\tRPN  0.061372( 0.095251)\n",
      "[Train]Epoch: [2][2340/5093]\tLoss_sum:  0.212038( 0.236451)\tCls:  0.012595( 0.052122)\tBox:  0.027123( 0.063418)\tObj:  0.005371( 0.025577)\tRPN  0.166949( 0.095335)\n",
      "[Train]Epoch: [2][2350/5093]\tLoss_sum:  0.454853( 0.236981)\tCls:  0.126983( 0.052150)\tBox:  0.160733( 0.063622)\tObj:  0.043174( 0.025594)\tRPN  0.123963( 0.095615)\n",
      "[Train]Epoch: [2][2360/5093]\tLoss_sum:  0.711318( 0.237756)\tCls:  0.166572( 0.052382)\tBox:  0.304493( 0.064020)\tObj:  0.046502( 0.025583)\tRPN  0.193751( 0.095772)\n",
      "[Train]Epoch: [2][2370/5093]\tLoss_sum:  0.290658( 0.238561)\tCls:  0.038356( 0.052596)\tBox:  0.106488( 0.064440)\tObj:  0.037247( 0.025571)\tRPN  0.108566( 0.095955)\n",
      "[Train]Epoch: [2][2380/5093]\tLoss_sum:  0.017839( 0.238106)\tCls:  0.006351( 0.052509)\tBox:  0.000000( 0.064354)\tObj:  0.004185( 0.025524)\tRPN  0.007302( 0.095718)\n",
      "[Train]Epoch: [2][2390/5093]\tLoss_sum:  0.350549( 0.238317)\tCls:  0.061889( 0.052485)\tBox:  0.149228( 0.064462)\tObj:  0.008444( 0.025488)\tRPN  0.130987( 0.095882)\n",
      "[Train]Epoch: [2][2400/5093]\tLoss_sum:  0.042233( 0.238120)\tCls:  0.000399( 0.052390)\tBox:  0.000000( 0.064492)\tObj:  0.021971( 0.025451)\tRPN  0.019862( 0.095787)\n",
      "[Train]Epoch: [2][2410/5093]\tLoss_sum:  0.022996( 0.237224)\tCls:  0.000979( 0.052180)\tBox:  0.000000( 0.064224)\tObj:  0.005518( 0.025365)\tRPN  0.016500( 0.095456)\n",
      "[Train]Epoch: [2][2420/5093]\tLoss_sum:  0.032177( 0.236581)\tCls:  0.004247( 0.052041)\tBox:  0.000000( 0.064015)\tObj:  0.019466( 0.025331)\tRPN  0.008464( 0.095193)\n",
      "[Train]Epoch: [2][2430/5093]\tLoss_sum:  0.122047( 0.236770)\tCls:  0.021655( 0.052006)\tBox:  0.068124( 0.063987)\tObj:  0.002662( 0.025341)\tRPN  0.029606( 0.095436)\n",
      "[Train]Epoch: [2][2440/5093]\tLoss_sum:  0.042869( 0.236476)\tCls:  0.007096( 0.051913)\tBox:  0.000000( 0.063938)\tObj:  0.008150( 0.025392)\tRPN  0.027623( 0.095233)\n",
      "[Train]Epoch: [2][2450/5093]\tLoss_sum:  0.053423( 0.235681)\tCls:  0.005438( 0.051719)\tBox:  0.000000( 0.063677)\tObj:  0.033200( 0.025385)\tRPN  0.014785( 0.094899)\n",
      "[Train]Epoch: [2][2460/5093]\tLoss_sum:  0.208319( 0.235367)\tCls:  0.028081( 0.051595)\tBox:  0.044144( 0.063486)\tObj:  0.009970( 0.025375)\tRPN  0.126124( 0.094910)\n",
      "[Train]Epoch: [2][2470/5093]\tLoss_sum:  0.025742( 0.234805)\tCls:  0.000228( 0.051437)\tBox:  0.000000( 0.063347)\tObj:  0.018278( 0.025357)\tRPN  0.007236( 0.094664)\n",
      "[Train]Epoch: [2][2480/5093]\tLoss_sum:  0.145749( 0.234230)\tCls:  0.039369( 0.051306)\tBox:  0.057414( 0.063190)\tObj:  0.022161( 0.025289)\tRPN  0.026805( 0.094445)\n",
      "[Train]Epoch: [2][2490/5093]\tLoss_sum:  0.095181( 0.234161)\tCls:  0.001126( 0.051314)\tBox:  0.000000( 0.063273)\tObj:  0.003565( 0.025294)\tRPN  0.090491( 0.094281)\n",
      "[Train]Epoch: [2][2500/5093]\tLoss_sum:  0.445445( 0.233559)\tCls:  0.036739( 0.051129)\tBox:  0.005681( 0.063022)\tObj:  0.059887( 0.025254)\tRPN  0.343137( 0.094154)\n",
      "[Train]Epoch: [2][2510/5093]\tLoss_sum:  0.136140( 0.233845)\tCls:  0.040028( 0.051169)\tBox:  0.060476( 0.063139)\tObj:  0.025437( 0.025243)\tRPN  0.010200( 0.094294)\n",
      "[Train]Epoch: [2][2520/5093]\tLoss_sum:  0.307784( 0.233779)\tCls:  0.002507( 0.051095)\tBox:  0.000000( 0.063137)\tObj:  0.003688( 0.025213)\tRPN  0.301588( 0.094334)\n",
      "[Train]Epoch: [2][2530/5093]\tLoss_sum:  0.418996( 0.233834)\tCls:  0.087505( 0.051025)\tBox:  0.123163( 0.063064)\tObj:  0.013200( 0.025170)\tRPN  0.195129( 0.094575)\n",
      "[Train]Epoch: [2][2540/5093]\tLoss_sum:  0.341904( 0.234018)\tCls:  0.043198( 0.051080)\tBox:  0.089190( 0.063282)\tObj:  0.010008( 0.025150)\tRPN  0.199508( 0.094507)\n",
      "[Train]Epoch: [2][2550/5093]\tLoss_sum:  0.051037( 0.234008)\tCls:  0.006047( 0.051049)\tBox:  0.021764( 0.063399)\tObj:  0.012526( 0.025106)\tRPN  0.010701( 0.094454)\n",
      "[Train]Epoch: [2][2560/5093]\tLoss_sum:  0.295172( 0.233886)\tCls:  0.068594( 0.050927)\tBox:  0.047206( 0.063246)\tObj:  0.020587( 0.025105)\tRPN  0.158785( 0.094608)\n",
      "[Train]Epoch: [2][2570/5093]\tLoss_sum:  0.106860( 0.234122)\tCls:  0.000384( 0.050929)\tBox:  0.000000( 0.063370)\tObj:  0.003333( 0.025046)\tRPN  0.103143( 0.094777)\n",
      "[Train]Epoch: [2][2580/5093]\tLoss_sum:  0.328016( 0.234627)\tCls:  0.114790( 0.051077)\tBox:  0.179643( 0.063624)\tObj:  0.006723( 0.025058)\tRPN  0.026859( 0.094868)\n",
      "[Train]Epoch: [2][2590/5093]\tLoss_sum:  0.109710( 0.234711)\tCls:  0.005868( 0.051082)\tBox:  0.043206( 0.063729)\tObj:  0.008782( 0.025048)\tRPN  0.051854( 0.094852)\n",
      "[Train]Epoch: [2][2600/5093]\tLoss_sum:  0.033077( 0.234679)\tCls:  0.008059( 0.051057)\tBox:  0.000000( 0.063880)\tObj:  0.010711( 0.025016)\tRPN  0.014307( 0.094726)\n",
      "[Train]Epoch: [2][2610/5093]\tLoss_sum:  0.359481( 0.234670)\tCls:  0.072486( 0.051068)\tBox:  0.152084( 0.063877)\tObj:  0.036993( 0.025007)\tRPN  0.097918( 0.094719)\n",
      "[Train]Epoch: [2][2620/5093]\tLoss_sum:  0.251612( 0.234748)\tCls:  0.035582( 0.051052)\tBox:  0.093694( 0.064017)\tObj:  0.007022( 0.024946)\tRPN  0.115315( 0.094733)\n",
      "[Train]Epoch: [2][2630/5093]\tLoss_sum:  0.034501( 0.234533)\tCls:  0.002087( 0.051006)\tBox:  0.000000( 0.064050)\tObj:  0.004256( 0.024919)\tRPN  0.028158( 0.094557)\n",
      "[Train]Epoch: [2][2640/5093]\tLoss_sum:  0.013761( 0.233713)\tCls:  0.000320( 0.050816)\tBox:  0.000000( 0.063808)\tObj:  0.004273( 0.024852)\tRPN  0.009168( 0.094238)\n",
      "[Train]Epoch: [2][2650/5093]\tLoss_sum:  0.516611( 0.233860)\tCls:  0.215341( 0.050904)\tBox:  0.251167( 0.063918)\tObj:  0.015035( 0.024831)\tRPN  0.035069( 0.094206)\n",
      "[Train]Epoch: [2][2660/5093]\tLoss_sum:  0.039869( 0.233435)\tCls:  0.005283( 0.050819)\tBox:  0.000000( 0.063799)\tObj:  0.002350( 0.024806)\tRPN  0.032236( 0.094011)\n",
      "[Train]Epoch: [2][2670/5093]\tLoss_sum:  0.798113( 0.233347)\tCls:  0.374058( 0.050909)\tBox:  0.295543( 0.063842)\tObj:  0.028699( 0.024763)\tRPN  0.099814( 0.093833)\n",
      "[Train]Epoch: [2][2680/5093]\tLoss_sum:  0.215135( 0.233373)\tCls:  0.072477( 0.050991)\tBox:  0.128779( 0.063930)\tObj:  0.006849( 0.024754)\tRPN  0.007030( 0.093698)\n",
      "[Train]Epoch: [2][2690/5093]\tLoss_sum:  0.157354( 0.233132)\tCls:  0.048980( 0.050953)\tBox:  0.040288( 0.063916)\tObj:  0.009858( 0.024707)\tRPN  0.058229( 0.093556)\n",
      "[Train]Epoch: [2][2700/5093]\tLoss_sum:  0.065021( 0.233126)\tCls:  0.000215( 0.050848)\tBox:  0.000000( 0.063903)\tObj:  0.008788( 0.024669)\tRPN  0.056018( 0.093707)\n",
      "[Train]Epoch: [2][2710/5093]\tLoss_sum:  0.151799( 0.232580)\tCls:  0.039243( 0.050706)\tBox:  0.041689( 0.063714)\tObj:  0.020735( 0.024605)\tRPN  0.050132( 0.093555)\n",
      "[Train]Epoch: [2][2720/5093]\tLoss_sum:  0.242908( 0.232635)\tCls:  0.004021( 0.050689)\tBox:  0.000000( 0.063713)\tObj:  0.027586( 0.024573)\tRPN  0.211301( 0.093660)\n",
      "[Train]Epoch: [2][2730/5093]\tLoss_sum:  0.020022( 0.232411)\tCls:  0.001113( 0.050633)\tBox:  0.000000( 0.063754)\tObj:  0.004095( 0.024537)\tRPN  0.014813( 0.093487)\n",
      "[Train]Epoch: [2][2740/5093]\tLoss_sum:  0.150299( 0.231796)\tCls:  0.022190( 0.050479)\tBox:  0.069468( 0.063561)\tObj:  0.016419( 0.024499)\tRPN  0.042222( 0.093257)\n",
      "[Train]Epoch: [2][2750/5093]\tLoss_sum:  0.031306( 0.231256)\tCls:  0.002176( 0.050352)\tBox:  0.000000( 0.063479)\tObj:  0.021573( 0.024438)\tRPN  0.007557( 0.092987)\n",
      "[Train]Epoch: [2][2760/5093]\tLoss_sum:  0.281883( 0.230794)\tCls:  0.098462( 0.050247)\tBox:  0.121289( 0.063391)\tObj:  0.015027( 0.024384)\tRPN  0.047104( 0.092773)\n",
      "[Train]Epoch: [2][2770/5093]\tLoss_sum:  0.233229( 0.231071)\tCls:  0.064443( 0.050326)\tBox:  0.146559( 0.063696)\tObj:  0.013966( 0.024380)\tRPN  0.008261( 0.092670)\n",
      "[Train]Epoch: [2][2780/5093]\tLoss_sum:  0.403577( 0.231025)\tCls:  0.102867( 0.050306)\tBox:  0.223450( 0.063770)\tObj:  0.064769( 0.024351)\tRPN  0.012491( 0.092598)\n",
      "[Train]Epoch: [2][2790/5093]\tLoss_sum:  0.497178( 0.230949)\tCls:  0.256330( 0.050327)\tBox:  0.184368( 0.063809)\tObj:  0.005901( 0.024300)\tRPN  0.050579( 0.092514)\n",
      "[Train]Epoch: [2][2800/5093]\tLoss_sum:  0.101805( 0.231256)\tCls:  0.000260( 0.050441)\tBox:  0.000000( 0.064019)\tObj:  0.004007( 0.024277)\tRPN  0.097537( 0.092520)\n",
      "[Train]Epoch: [2][2810/5093]\tLoss_sum:  0.028310( 0.230572)\tCls:  0.000384( 0.050262)\tBox:  0.000000( 0.063791)\tObj:  0.018390( 0.024214)\tRPN  0.009536( 0.092305)\n",
      "[Train]Epoch: [2][2820/5093]\tLoss_sum:  0.034363( 0.230477)\tCls:  0.005724( 0.050306)\tBox:  0.000000( 0.063828)\tObj:  0.002987( 0.024215)\tRPN  0.025652( 0.092129)\n",
      "[Train]Epoch: [2][2830/5093]\tLoss_sum:  0.026483( 0.229723)\tCls:  0.000214( 0.050136)\tBox:  0.000000( 0.063602)\tObj:  0.022192( 0.024152)\tRPN  0.004078( 0.091833)\n",
      "[Train]Epoch: [2][2840/5093]\tLoss_sum:  0.333682( 0.229940)\tCls:  0.134958( 0.050251)\tBox:  0.126445( 0.063671)\tObj:  0.020756( 0.024127)\tRPN  0.051523( 0.091891)\n",
      "[Train]Epoch: [2][2850/5093]\tLoss_sum:  0.040157( 0.230076)\tCls:  0.013826( 0.050323)\tBox:  0.000000( 0.063880)\tObj:  0.005889( 0.024116)\tRPN  0.020442( 0.091757)\n",
      "[Train]Epoch: [2][2860/5093]\tLoss_sum:  0.171365( 0.229639)\tCls:  0.034980( 0.050259)\tBox:  0.053481( 0.063719)\tObj:  0.021482( 0.024074)\tRPN  0.061422( 0.091588)\n",
      "[Train]Epoch: [2][2870/5093]\tLoss_sum:  0.026669( 0.229517)\tCls:  0.000213( 0.050236)\tBox:  0.000000( 0.063884)\tObj:  0.002725( 0.024024)\tRPN  0.023730( 0.091373)\n",
      "[Train]Epoch: [2][2880/5093]\tLoss_sum:  0.027987( 0.228971)\tCls:  0.000049( 0.050097)\tBox:  0.000000( 0.063713)\tObj:  0.003145( 0.023981)\tRPN  0.024793( 0.091179)\n",
      "[Train]Epoch: [2][2890/5093]\tLoss_sum:  0.517755( 0.229203)\tCls:  0.109683( 0.050116)\tBox:  0.233502( 0.063901)\tObj:  0.029845( 0.023966)\tRPN  0.144725( 0.091219)\n",
      "[Train]Epoch: [2][2900/5093]\tLoss_sum:  0.399425( 0.229342)\tCls:  0.053107( 0.050113)\tBox:  0.080110( 0.063938)\tObj:  0.027604( 0.023981)\tRPN  0.238605( 0.091310)\n",
      "[Train]Epoch: [2][2910/5093]\tLoss_sum:  0.398311( 0.229640)\tCls:  0.056285( 0.050163)\tBox:  0.205400( 0.064158)\tObj:  0.019534( 0.023973)\tRPN  0.117091( 0.091346)\n",
      "[Train]Epoch: [2][2920/5093]\tLoss_sum:  0.211386( 0.229751)\tCls:  0.064083( 0.050111)\tBox:  0.061398( 0.064076)\tObj:  0.044149( 0.024026)\tRPN  0.041757( 0.091537)\n",
      "[Train]Epoch: [2][2930/5093]\tLoss_sum:  0.299254( 0.229772)\tCls:  0.000451( 0.050091)\tBox:  0.000000( 0.064108)\tObj:  0.014112( 0.024039)\tRPN  0.284691( 0.091534)\n",
      "[Train]Epoch: [2][2940/5093]\tLoss_sum:  0.079943( 0.229464)\tCls:  0.009421( 0.049924)\tBox:  0.026251( 0.063899)\tObj:  0.030516( 0.024008)\tRPN  0.013756( 0.091632)\n",
      "[Train]Epoch: [2][2950/5093]\tLoss_sum:  0.206793( 0.229636)\tCls:  0.000642( 0.050007)\tBox:  0.000000( 0.064040)\tObj:  0.020987( 0.023977)\tRPN  0.185164( 0.091612)\n",
      "[Train]Epoch: [2][2960/5093]\tLoss_sum:  0.244227( 0.229388)\tCls:  0.032739( 0.049887)\tBox:  0.043696( 0.063872)\tObj:  0.010781( 0.023934)\tRPN  0.157012( 0.091695)\n",
      "[Train]Epoch: [2][2970/5093]\tLoss_sum:  0.155239( 0.229371)\tCls:  0.075043( 0.049877)\tBox:  0.076115( 0.063854)\tObj:  0.001156( 0.023906)\tRPN  0.002925( 0.091733)\n",
      "[Train]Epoch: [2][2980/5093]\tLoss_sum:  0.016919( 0.228820)\tCls:  0.000132( 0.049741)\tBox:  0.000000( 0.063709)\tObj:  0.003334( 0.023845)\tRPN  0.013453( 0.091525)\n",
      "[Train]Epoch: [2][2990/5093]\tLoss_sum:  0.305223( 0.228746)\tCls:  0.030593( 0.049665)\tBox:  0.091968( 0.063723)\tObj:  0.022214( 0.023837)\tRPN  0.160448( 0.091521)\n",
      "[Train]Epoch: [2][3000/5093]\tLoss_sum:  0.082205( 0.228463)\tCls:  0.000184( 0.049537)\tBox:  0.000000( 0.063623)\tObj:  0.007229( 0.023789)\tRPN  0.074792( 0.091513)\n",
      "[Train]Epoch: [2][3010/5093]\tLoss_sum:  0.195040( 0.228397)\tCls:  0.054434( 0.049478)\tBox:  0.021704( 0.063597)\tObj:  0.014841( 0.023764)\tRPN  0.104061( 0.091559)\n",
      "[Train]Epoch: [2][3020/5093]\tLoss_sum:  0.642538( 0.228937)\tCls:  0.193637( 0.049609)\tBox:  0.175833( 0.063781)\tObj:  0.080720( 0.023816)\tRPN  0.192348( 0.091733)\n",
      "[Train]Epoch: [2][3030/5093]\tLoss_sum:  0.384376( 0.229599)\tCls:  0.044749( 0.049738)\tBox:  0.193099( 0.064126)\tObj:  0.019960( 0.023872)\tRPN  0.126569( 0.091863)\n",
      "[Train]Epoch: [2][3040/5093]\tLoss_sum:  0.281014( 0.230196)\tCls:  0.090125( 0.049884)\tBox:  0.135675( 0.064393)\tObj:  0.004809( 0.023882)\tRPN  0.050405( 0.092036)\n",
      "[Train]Epoch: [2][3050/5093]\tLoss_sum:  0.312286( 0.230273)\tCls:  0.048058( 0.049852)\tBox:  0.095267( 0.064449)\tObj:  0.005636( 0.023887)\tRPN  0.163326( 0.092085)\n",
      "[Train]Epoch: [2][3060/5093]\tLoss_sum:  0.052477( 0.229959)\tCls:  0.000536( 0.049736)\tBox:  0.000000( 0.064373)\tObj:  0.003771( 0.023835)\tRPN  0.048170( 0.092016)\n",
      "[Train]Epoch: [2][3070/5093]\tLoss_sum:  0.243346( 0.230151)\tCls:  0.041512( 0.049652)\tBox:  0.105391( 0.064340)\tObj:  0.025715( 0.023810)\tRPN  0.070728( 0.092348)\n",
      "[Train]Epoch: [2][3080/5093]\tLoss_sum:  0.022290( 0.229802)\tCls:  0.001375( 0.049605)\tBox:  0.000000( 0.064278)\tObj:  0.009862( 0.023759)\tRPN  0.011054( 0.092160)\n",
      "[Train]Epoch: [2][3090/5093]\tLoss_sum:  0.028991( 0.229479)\tCls:  0.000238( 0.049510)\tBox:  0.000000( 0.064194)\tObj:  0.003612( 0.023708)\tRPN  0.025140( 0.092067)\n",
      "[Train]Epoch: [2][3100/5093]\tLoss_sum:  0.196681( 0.229063)\tCls:  0.037767( 0.049391)\tBox:  0.075905( 0.064067)\tObj:  0.020513( 0.023660)\tRPN  0.062496( 0.091945)\n",
      "[Train]Epoch: [2][3110/5093]\tLoss_sum:  0.162714( 0.229069)\tCls:  0.025762( 0.049361)\tBox:  0.058269( 0.064151)\tObj:  0.003453( 0.023622)\tRPN  0.075230( 0.091936)\n",
      "[Train]Epoch: [2][3120/5093]\tLoss_sum:  0.011838( 0.228652)\tCls:  0.000732( 0.049272)\tBox:  0.000000( 0.064050)\tObj:  0.003081( 0.023581)\tRPN  0.008024( 0.091749)\n",
      "[Train]Epoch: [2][3130/5093]\tLoss_sum:  0.086415( 0.228694)\tCls:  0.003028( 0.049242)\tBox:  0.032552( 0.064128)\tObj:  0.000974( 0.023575)\tRPN  0.049862( 0.091748)\n",
      "[Train]Epoch: [2][3140/5093]\tLoss_sum:  0.113514( 0.228656)\tCls:  0.003584( 0.049212)\tBox:  0.000000( 0.064160)\tObj:  0.013720( 0.023571)\tRPN  0.096210( 0.091712)\n",
      "[Train]Epoch: [2][3150/5093]\tLoss_sum:  0.386052( 0.228369)\tCls:  0.043911( 0.049092)\tBox:  0.143269( 0.064087)\tObj:  0.028846( 0.023530)\tRPN  0.170027( 0.091661)\n",
      "[Train]Epoch: [2][3160/5093]\tLoss_sum:  0.072872( 0.228252)\tCls:  0.000123( 0.049024)\tBox:  0.000000( 0.064116)\tObj:  0.003416( 0.023503)\tRPN  0.069333( 0.091609)\n",
      "[Train]Epoch: [2][3170/5093]\tLoss_sum:  0.070353( 0.227651)\tCls:  0.007880( 0.048877)\tBox:  0.021545( 0.063930)\tObj:  0.002224( 0.023453)\tRPN  0.038705( 0.091391)\n",
      "[Train]Epoch: [2][3180/5093]\tLoss_sum:  0.110160( 0.227541)\tCls:  0.017002( 0.048859)\tBox:  0.077420( 0.063920)\tObj:  0.005715( 0.023416)\tRPN  0.010022( 0.091347)\n",
      "[Train]Epoch: [2][3190/5093]\tLoss_sum:  0.345925( 0.227736)\tCls:  0.028990( 0.048854)\tBox:  0.098891( 0.064037)\tObj:  0.018568( 0.023520)\tRPN  0.199476( 0.091326)\n",
      "[Train]Epoch: [2][3200/5093]\tLoss_sum:  0.188491( 0.227472)\tCls:  0.025010( 0.048767)\tBox:  0.056423( 0.063970)\tObj:  0.046484( 0.023506)\tRPN  0.060574( 0.091229)\n",
      "[Train]Epoch: [2][3210/5093]\tLoss_sum:  0.032502( 0.227107)\tCls:  0.001017( 0.048675)\tBox:  0.000000( 0.063890)\tObj:  0.022681( 0.023479)\tRPN  0.008804( 0.091063)\n",
      "[Train]Epoch: [2][3220/5093]\tLoss_sum:  0.174671( 0.226892)\tCls:  0.031282( 0.048586)\tBox:  0.116702( 0.063835)\tObj:  0.002040( 0.023455)\tRPN  0.024647( 0.091015)\n",
      "[Train]Epoch: [2][3230/5093]\tLoss_sum:  0.207815( 0.226675)\tCls:  0.058522( 0.048589)\tBox:  0.142319( 0.063915)\tObj:  0.001763( 0.023402)\tRPN  0.005211( 0.090770)\n",
      "[Train]Epoch: [2][3240/5093]\tLoss_sum:  0.102495( 0.226515)\tCls:  0.013847( 0.048537)\tBox:  0.059726( 0.063870)\tObj:  0.002912( 0.023367)\tRPN  0.026009( 0.090742)\n",
      "[Train]Epoch: [2][3250/5093]\tLoss_sum:  0.078118( 0.226390)\tCls:  0.009527( 0.048461)\tBox:  0.030824( 0.063777)\tObj:  0.019326( 0.023344)\tRPN  0.018440( 0.090808)\n",
      "[Train]Epoch: [2][3260/5093]\tLoss_sum:  0.287676( 0.226230)\tCls:  0.064543( 0.048394)\tBox:  0.158357( 0.063803)\tObj:  0.012199( 0.023310)\tRPN  0.052578( 0.090723)\n",
      "[Train]Epoch: [2][3270/5093]\tLoss_sum:  0.068783( 0.225807)\tCls:  0.010854( 0.048269)\tBox:  0.000000( 0.063651)\tObj:  0.026854( 0.023280)\tRPN  0.031075( 0.090607)\n",
      "[Train]Epoch: [2][3280/5093]\tLoss_sum:  0.215901( 0.225933)\tCls:  0.047141( 0.048275)\tBox:  0.089449( 0.063740)\tObj:  0.032179( 0.023297)\tRPN  0.047133( 0.090621)\n",
      "[Train]Epoch: [2][3290/5093]\tLoss_sum:  0.301248( 0.225746)\tCls:  0.078535( 0.048252)\tBox:  0.085914( 0.063713)\tObj:  0.054176( 0.023295)\tRPN  0.082622( 0.090486)\n",
      "[Train]Epoch: [2][3300/5093]\tLoss_sum:  0.144443( 0.226176)\tCls:  0.029969( 0.048359)\tBox:  0.052496( 0.063895)\tObj:  0.050110( 0.023344)\tRPN  0.011868( 0.090577)\n",
      "[Train]Epoch: [2][3310/5093]\tLoss_sum:  0.169356( 0.225986)\tCls:  0.038068( 0.048306)\tBox:  0.069731( 0.063840)\tObj:  0.049564( 0.023377)\tRPN  0.011992( 0.090463)\n",
      "[Train]Epoch: [2][3320/5093]\tLoss_sum:  0.238534( 0.225927)\tCls:  0.039106( 0.048255)\tBox:  0.123657( 0.063853)\tObj:  0.030765( 0.023370)\tRPN  0.045006( 0.090449)\n",
      "[Train]Epoch: [2][3330/5093]\tLoss_sum:  0.169696( 0.226034)\tCls:  0.037589( 0.048295)\tBox:  0.064675( 0.063927)\tObj:  0.017261( 0.023343)\tRPN  0.050171( 0.090468)\n",
      "[Train]Epoch: [2][3340/5093]\tLoss_sum:  0.601032( 0.225960)\tCls:  0.018825( 0.048266)\tBox:  0.002992( 0.063953)\tObj:  0.040705( 0.023322)\tRPN  0.538510( 0.090418)\n",
      "[Train]Epoch: [2][3350/5093]\tLoss_sum:  0.242880( 0.226041)\tCls:  0.080053( 0.048235)\tBox:  0.079341( 0.063919)\tObj:  0.029311( 0.023360)\tRPN  0.054175( 0.090528)\n",
      "[Train]Epoch: [2][3360/5093]\tLoss_sum:  0.219486( 0.225877)\tCls:  0.093283( 0.048218)\tBox:  0.056287( 0.063867)\tObj:  0.039420( 0.023383)\tRPN  0.030496( 0.090410)\n",
      "[Train]Epoch: [2][3370/5093]\tLoss_sum:  0.220638( 0.225728)\tCls:  0.010376( 0.048167)\tBox:  0.030743( 0.063830)\tObj:  0.011696( 0.023398)\tRPN  0.167823( 0.090333)\n",
      "[Train]Epoch: [2][3380/5093]\tLoss_sum:  0.031232( 0.225476)\tCls:  0.000298( 0.048094)\tBox:  0.000000( 0.063781)\tObj:  0.008871( 0.023371)\tRPN  0.022063( 0.090229)\n",
      "[Train]Epoch: [2][3390/5093]\tLoss_sum:  0.024455( 0.224902)\tCls:  0.000443( 0.047957)\tBox:  0.000000( 0.063593)\tObj:  0.010559( 0.023349)\tRPN  0.013454( 0.090003)\n",
      "[Train]Epoch: [2][3400/5093]\tLoss_sum:  0.254141( 0.224739)\tCls:  0.050637( 0.047903)\tBox:  0.133055( 0.063519)\tObj:  0.021027( 0.023335)\tRPN  0.049423( 0.089982)\n",
      "[Train]Epoch: [2][3410/5093]\tLoss_sum:  0.063714( 0.224354)\tCls:  0.001784( 0.047824)\tBox:  0.000000( 0.063410)\tObj:  0.021240( 0.023289)\tRPN  0.040691( 0.089831)\n",
      "[Train]Epoch: [2][3420/5093]\tLoss_sum:  0.352473( 0.224281)\tCls:  0.039383( 0.047794)\tBox:  0.051108( 0.063384)\tObj:  0.011372( 0.023309)\tRPN  0.250609( 0.089795)\n",
      "[Train]Epoch: [2][3430/5093]\tLoss_sum:  0.099238( 0.224237)\tCls:  0.034527( 0.047797)\tBox:  0.039689( 0.063405)\tObj:  0.015311( 0.023322)\tRPN  0.009713( 0.089713)\n",
      "[Train]Epoch: [2][3440/5093]\tLoss_sum:  0.023743( 0.223972)\tCls:  0.000293( 0.047727)\tBox:  0.000000( 0.063377)\tObj:  0.012154( 0.023289)\tRPN  0.011296( 0.089579)\n",
      "[Train]Epoch: [2][3450/5093]\tLoss_sum:  0.030395( 0.223655)\tCls:  0.000144( 0.047620)\tBox:  0.000000( 0.063315)\tObj:  0.003484( 0.023259)\tRPN  0.026767( 0.089461)\n",
      "[Train]Epoch: [2][3460/5093]\tLoss_sum:  0.316480( 0.223388)\tCls:  0.049685( 0.047575)\tBox:  0.146322( 0.063246)\tObj:  0.015445( 0.023233)\tRPN  0.105029( 0.089333)\n",
      "[Train]Epoch: [2][3470/5093]\tLoss_sum:  0.056399( 0.223443)\tCls:  0.000447( 0.047613)\tBox:  0.000000( 0.063389)\tObj:  0.020639( 0.023201)\tRPN  0.035312( 0.089240)\n",
      "[Train]Epoch: [2][3480/5093]\tLoss_sum:  0.376411( 0.223819)\tCls:  0.045075( 0.047648)\tBox:  0.110160( 0.063424)\tObj:  0.021997( 0.023310)\tRPN  0.199180( 0.089437)\n",
      "[Train]Epoch: [2][3490/5093]\tLoss_sum:  0.306905( 0.223734)\tCls:  0.078089( 0.047669)\tBox:  0.118622( 0.063427)\tObj:  0.049629( 0.023320)\tRPN  0.060565( 0.089319)\n",
      "[Train]Epoch: [2][3500/5093]\tLoss_sum:  0.199422( 0.223670)\tCls:  0.050388( 0.047667)\tBox:  0.114591( 0.063467)\tObj:  0.014448( 0.023361)\tRPN  0.019996( 0.089175)\n",
      "[Train]Epoch: [2][3510/5093]\tLoss_sum:  0.127860( 0.223502)\tCls:  0.013201( 0.047632)\tBox:  0.034734( 0.063443)\tObj:  0.050494( 0.023346)\tRPN  0.029432( 0.089080)\n",
      "[Train]Epoch: [2][3520/5093]\tLoss_sum:  0.119112( 0.222984)\tCls:  0.008532( 0.047504)\tBox:  0.022826( 0.063274)\tObj:  0.010522( 0.023319)\tRPN  0.077232( 0.088888)\n",
      "[Train]Epoch: [2][3530/5093]\tLoss_sum:  0.019046( 0.222748)\tCls:  0.001551( 0.047439)\tBox:  0.000000( 0.063189)\tObj:  0.008218( 0.023318)\tRPN  0.009277( 0.088802)\n",
      "[Train]Epoch: [2][3540/5093]\tLoss_sum:  0.104258( 0.222501)\tCls:  0.021652( 0.047357)\tBox:  0.031291( 0.063116)\tObj:  0.003445( 0.023305)\tRPN  0.047869( 0.088723)\n",
      "[Train]Epoch: [2][3550/5093]\tLoss_sum:  0.196646( 0.222571)\tCls:  0.017929( 0.047390)\tBox:  0.060946( 0.063157)\tObj:  0.007180( 0.023278)\tRPN  0.110591( 0.088746)\n",
      "[Train]Epoch: [2][3560/5093]\tLoss_sum:  0.082455( 0.222550)\tCls:  0.001779( 0.047379)\tBox:  0.000000( 0.063170)\tObj:  0.007962( 0.023259)\tRPN  0.072713( 0.088742)\n",
      "[Train]Epoch: [2][3570/5093]\tLoss_sum:  0.008022( 0.222043)\tCls:  0.000366( 0.047256)\tBox:  0.000000( 0.062993)\tObj:  0.003707( 0.023231)\tRPN  0.003949( 0.088563)\n",
      "[Train]Epoch: [2][3580/5093]\tLoss_sum:  0.116810( 0.222158)\tCls:  0.033042( 0.047393)\tBox:  0.064937( 0.063077)\tObj:  0.015017( 0.023228)\tRPN  0.003813( 0.088460)\n",
      "[Train]Epoch: [2][3590/5093]\tLoss_sum:  0.040498( 0.221962)\tCls:  0.006332( 0.047370)\tBox:  0.000000( 0.063034)\tObj:  0.015800( 0.023201)\tRPN  0.018366( 0.088356)\n",
      "[Train]Epoch: [2][3600/5093]\tLoss_sum:  0.088522( 0.221710)\tCls:  0.017302( 0.047324)\tBox:  0.061349( 0.063009)\tObj:  0.001853( 0.023170)\tRPN  0.008018( 0.088207)\n",
      "[Train]Epoch: [2][3610/5093]\tLoss_sum:  0.012643( 0.221215)\tCls:  0.000222( 0.047221)\tBox:  0.000000( 0.062893)\tObj:  0.004666( 0.023114)\tRPN  0.007755( 0.087986)\n",
      "[Train]Epoch: [2][3620/5093]\tLoss_sum:  0.024452( 0.220970)\tCls:  0.000077( 0.047220)\tBox:  0.000000( 0.062852)\tObj:  0.002908( 0.023070)\tRPN  0.021467( 0.087828)\n",
      "[Train]Epoch: [2][3630/5093]\tLoss_sum:  0.192068( 0.220922)\tCls:  0.044655( 0.047193)\tBox:  0.094729( 0.062898)\tObj:  0.014653( 0.023054)\tRPN  0.038030( 0.087777)\n",
      "[Train]Epoch: [2][3640/5093]\tLoss_sum:  0.333964( 0.220986)\tCls:  0.098805( 0.047195)\tBox:  0.173874( 0.062990)\tObj:  0.018571( 0.023050)\tRPN  0.042714( 0.087750)\n",
      "[Train]Epoch: [2][3650/5093]\tLoss_sum:  0.121292( 0.220782)\tCls:  0.027547( 0.047117)\tBox:  0.048898( 0.062868)\tObj:  0.002376( 0.023191)\tRPN  0.042472( 0.087605)\n",
      "[Train]Epoch: [2][3660/5093]\tLoss_sum:  0.007504( 0.220573)\tCls:  0.000611( 0.047183)\tBox:  0.000000( 0.062824)\tObj:  0.003118( 0.023157)\tRPN  0.003775( 0.087408)\n",
      "[Train]Epoch: [2][3670/5093]\tLoss_sum:  0.015091( 0.220398)\tCls:  0.000558( 0.047164)\tBox:  0.000000( 0.062827)\tObj:  0.010747( 0.023148)\tRPN  0.003787( 0.087259)\n",
      "[Train]Epoch: [2][3680/5093]\tLoss_sum:  0.008862( 0.219932)\tCls:  0.003221( 0.047073)\tBox:  0.000000( 0.062704)\tObj:  0.002961( 0.023119)\tRPN  0.002680( 0.087036)\n",
      "[Train]Epoch: [2][3690/5093]\tLoss_sum:  0.395377( 0.219940)\tCls:  0.141086( 0.047098)\tBox:  0.203281( 0.062756)\tObj:  0.014467( 0.023130)\tRPN  0.036543( 0.086956)\n",
      "[Train]Epoch: [2][3700/5093]\tLoss_sum:  0.246640( 0.220004)\tCls:  0.055607( 0.047095)\tBox:  0.123353( 0.062772)\tObj:  0.017307( 0.023138)\tRPN  0.050374( 0.087001)\n",
      "[Train]Epoch: [2][3710/5093]\tLoss_sum:  0.135764( 0.219935)\tCls:  0.047938( 0.047117)\tBox:  0.041687( 0.062769)\tObj:  0.014509( 0.023130)\tRPN  0.031631( 0.086919)\n",
      "[Train]Epoch: [2][3720/5093]\tLoss_sum:  0.037093( 0.219622)\tCls:  0.001328( 0.047061)\tBox:  0.000000( 0.062697)\tObj:  0.025816( 0.023106)\tRPN  0.009948( 0.086758)\n",
      "[Train]Epoch: [2][3730/5093]\tLoss_sum:  0.148159( 0.219495)\tCls:  0.048554( 0.047051)\tBox:  0.048110( 0.062670)\tObj:  0.003571( 0.023083)\tRPN  0.047924( 0.086691)\n",
      "[Train]Epoch: [2][3740/5093]\tLoss_sum:  0.031959( 0.219604)\tCls:  0.000689( 0.047158)\tBox:  0.000000( 0.062807)\tObj:  0.009183( 0.023057)\tRPN  0.022087( 0.086581)\n",
      "[Train]Epoch: [2][3750/5093]\tLoss_sum:  0.009274( 0.219346)\tCls:  0.000230( 0.047095)\tBox:  0.000000( 0.062720)\tObj:  0.003886( 0.023025)\tRPN  0.005158( 0.086506)\n",
      "[Train]Epoch: [2][3760/5093]\tLoss_sum:  0.101430( 0.218945)\tCls:  0.034962( 0.047002)\tBox:  0.042136( 0.062609)\tObj:  0.012664( 0.022985)\tRPN  0.011668( 0.086350)\n",
      "[Train]Epoch: [2][3770/5093]\tLoss_sum:  0.031191( 0.218790)\tCls:  0.000204( 0.046999)\tBox:  0.000000( 0.062594)\tObj:  0.008004( 0.022971)\tRPN  0.022983( 0.086226)\n",
      "[Train]Epoch: [2][3780/5093]\tLoss_sum:  0.071165( 0.218625)\tCls:  0.000369( 0.046946)\tBox:  0.000000( 0.062547)\tObj:  0.003825( 0.022951)\tRPN  0.066971( 0.086181)\n",
      "[Train]Epoch: [2][3790/5093]\tLoss_sum:  0.306918( 0.218402)\tCls:  0.070611( 0.046902)\tBox:  0.120010( 0.062492)\tObj:  0.009092( 0.022927)\tRPN  0.107204( 0.086080)\n",
      "[Train]Epoch: [2][3800/5093]\tLoss_sum:  0.017650( 0.217990)\tCls:  0.003590( 0.046809)\tBox:  0.000000( 0.062388)\tObj:  0.002728( 0.022888)\tRPN  0.011332( 0.085904)\n",
      "[Train]Epoch: [2][3810/5093]\tLoss_sum:  0.357717( 0.217922)\tCls:  0.052806( 0.046808)\tBox:  0.063117( 0.062352)\tObj:  0.122396( 0.022901)\tRPN  0.119397( 0.085861)\n",
      "[Train]Epoch: [2][3820/5093]\tLoss_sum:  0.161547( 0.218105)\tCls:  0.023849( 0.046839)\tBox:  0.000000( 0.062410)\tObj:  0.020871( 0.022968)\tRPN  0.116827( 0.085888)\n",
      "[Train]Epoch: [2][3830/5093]\tLoss_sum:  0.508720( 0.218173)\tCls:  0.045053( 0.046845)\tBox:  0.011402( 0.062446)\tObj:  0.051880( 0.022986)\tRPN  0.400384( 0.085896)\n",
      "[Train]Epoch: [2][3840/5093]\tLoss_sum:  0.229650( 0.218266)\tCls:  0.058892( 0.046837)\tBox:  0.107134( 0.062468)\tObj:  0.003691( 0.023013)\tRPN  0.059933( 0.085949)\n",
      "[Train]Epoch: [2][3850/5093]\tLoss_sum:  0.058135( 0.218182)\tCls:  0.002494( 0.046806)\tBox:  0.000000( 0.062512)\tObj:  0.045955( 0.023006)\tRPN  0.009685( 0.085857)\n",
      "[Train]Epoch: [2][3860/5093]\tLoss_sum:  0.113792( 0.218277)\tCls:  0.042987( 0.046823)\tBox:  0.051615( 0.062591)\tObj:  0.011816( 0.023027)\tRPN  0.007374( 0.085836)\n",
      "[Train]Epoch: [2][3870/5093]\tLoss_sum:  0.226078( 0.218160)\tCls:  0.026326( 0.046756)\tBox:  0.085546( 0.062533)\tObj:  0.021970( 0.023020)\tRPN  0.092236( 0.085850)\n",
      "[Train]Epoch: [2][3880/5093]\tLoss_sum:  0.102010( 0.218219)\tCls:  0.024647( 0.046740)\tBox:  0.022913( 0.062624)\tObj:  0.007980( 0.023015)\tRPN  0.046470( 0.085839)\n",
      "[Train]Epoch: [2][3890/5093]\tLoss_sum:  0.040491( 0.218309)\tCls:  0.009719( 0.046769)\tBox:  0.009329( 0.062637)\tObj:  0.012960( 0.023012)\tRPN  0.008483( 0.085890)\n",
      "[Train]Epoch: [2][3900/5093]\tLoss_sum:  0.328493( 0.218328)\tCls:  0.063267( 0.046797)\tBox:  0.173820( 0.062738)\tObj:  0.010093( 0.022987)\tRPN  0.081313( 0.085806)\n",
      "[Train]Epoch: [2][3910/5093]\tLoss_sum:  0.013243( 0.218150)\tCls:  0.001799( 0.046732)\tBox:  0.000000( 0.062773)\tObj:  0.005228( 0.022952)\tRPN  0.006216( 0.085693)\n",
      "[Train]Epoch: [2][3920/5093]\tLoss_sum:  0.024991( 0.218084)\tCls:  0.004472( 0.046709)\tBox:  0.000000( 0.062761)\tObj:  0.016014( 0.022954)\tRPN  0.004504( 0.085659)\n",
      "[Train]Epoch: [2][3930/5093]\tLoss_sum:  0.416071( 0.217660)\tCls:  0.074048( 0.046614)\tBox:  0.017733( 0.062606)\tObj:  0.203146( 0.022962)\tRPN  0.121144( 0.085478)\n",
      "[Train]Epoch: [2][3940/5093]\tLoss_sum:  0.017729( 0.217613)\tCls:  0.000607( 0.046622)\tBox:  0.000000( 0.062669)\tObj:  0.012201( 0.022948)\tRPN  0.004921( 0.085374)\n",
      "[Train]Epoch: [2][3950/5093]\tLoss_sum:  0.016586( 0.217108)\tCls:  0.000776( 0.046507)\tBox:  0.000000( 0.062510)\tObj:  0.013166( 0.022926)\tRPN  0.002644( 0.085164)\n",
      "[Train]Epoch: [2][3960/5093]\tLoss_sum:  0.187429( 0.216633)\tCls:  0.041318( 0.046401)\tBox:  0.060387( 0.062368)\tObj:  0.024994( 0.022894)\tRPN  0.060730( 0.084969)\n",
      "[Train]Epoch: [2][3970/5093]\tLoss_sum:  0.153214( 0.216444)\tCls:  0.041837( 0.046341)\tBox:  0.067409( 0.062357)\tObj:  0.029433( 0.022871)\tRPN  0.014535( 0.084876)\n",
      "[Train]Epoch: [2][3980/5093]\tLoss_sum:  0.154461( 0.216237)\tCls:  0.047206( 0.046296)\tBox:  0.045986( 0.062327)\tObj:  0.006255( 0.022827)\tRPN  0.055014( 0.084787)\n",
      "[Train]Epoch: [2][3990/5093]\tLoss_sum:  0.009946( 0.215941)\tCls:  0.000106( 0.046230)\tBox:  0.000000( 0.062269)\tObj:  0.004585( 0.022800)\tRPN  0.005255( 0.084641)\n",
      "[Train]Epoch: [2][4000/5093]\tLoss_sum:  0.134419( 0.215776)\tCls:  0.044149( 0.046235)\tBox:  0.075498( 0.062235)\tObj:  0.007797( 0.022780)\tRPN  0.006975( 0.084526)\n",
      "[Train]Epoch: [2][4010/5093]\tLoss_sum:  0.157811( 0.215600)\tCls:  0.045717( 0.046181)\tBox:  0.098644( 0.062234)\tObj:  0.001593( 0.022763)\tRPN  0.011858( 0.084423)\n",
      "[Train]Epoch: [2][4020/5093]\tLoss_sum:  0.171547( 0.215596)\tCls:  0.037172( 0.046176)\tBox:  0.060512( 0.062249)\tObj:  0.029784( 0.022753)\tRPN  0.044078( 0.084418)\n",
      "[Train]Epoch: [2][4030/5093]\tLoss_sum:  0.019428( 0.215517)\tCls:  0.000807( 0.046220)\tBox:  0.000000( 0.062292)\tObj:  0.011753( 0.022738)\tRPN  0.006868( 0.084268)\n",
      "[Train]Epoch: [2][4040/5093]\tLoss_sum:  0.192915( 0.215400)\tCls:  0.045294( 0.046200)\tBox:  0.107735( 0.062308)\tObj:  0.025489( 0.022729)\tRPN  0.014397( 0.084163)\n",
      "[Train]Epoch: [2][4050/5093]\tLoss_sum:  0.295462( 0.215522)\tCls:  0.058925( 0.046222)\tBox:  0.110300( 0.062379)\tObj:  0.024348( 0.022714)\tRPN  0.101889( 0.084207)\n",
      "[Train]Epoch: [2][4060/5093]\tLoss_sum:  0.149042( 0.215467)\tCls:  0.000124( 0.046238)\tBox:  0.000000( 0.062383)\tObj:  0.003082( 0.022677)\tRPN  0.145837( 0.084169)\n",
      "[Train]Epoch: [2][4070/5093]\tLoss_sum:  0.143067( 0.215116)\tCls:  0.010909( 0.046128)\tBox:  0.038396( 0.062240)\tObj:  0.024679( 0.022639)\tRPN  0.069084( 0.084110)\n",
      "[Train]Epoch: [2][4080/5093]\tLoss_sum:  0.055970( 0.215025)\tCls:  0.000367( 0.046075)\tBox:  0.000000( 0.062233)\tObj:  0.002377( 0.022626)\tRPN  0.053226( 0.084091)\n",
      "[Train]Epoch: [2][4090/5093]\tLoss_sum:  0.214286( 0.214808)\tCls:  0.033351( 0.046007)\tBox:  0.124889( 0.062220)\tObj:  0.017809( 0.022600)\tRPN  0.038238( 0.083980)\n",
      "[Train]Epoch: [2][4100/5093]\tLoss_sum:  0.243710( 0.214749)\tCls:  0.048089( 0.045947)\tBox:  0.108784( 0.062154)\tObj:  0.002241( 0.022570)\tRPN  0.084596( 0.084079)\n",
      "[Train]Epoch: [2][4110/5093]\tLoss_sum:  0.275352( 0.214586)\tCls:  0.058436( 0.045886)\tBox:  0.204377( 0.062123)\tObj:  0.000620( 0.022548)\tRPN  0.011919( 0.084029)\n",
      "[Train]Epoch: [2][4120/5093]\tLoss_sum:  0.228625( 0.214380)\tCls:  0.041319( 0.045855)\tBox:  0.136187( 0.062123)\tObj:  0.013704( 0.022514)\tRPN  0.037415( 0.083888)\n",
      "[Train]Epoch: [2][4130/5093]\tLoss_sum:  0.143530( 0.214375)\tCls:  0.017905( 0.045867)\tBox:  0.086974( 0.062150)\tObj:  0.005659( 0.022532)\tRPN  0.032993( 0.083825)\n",
      "[Train]Epoch: [2][4140/5093]\tLoss_sum:  0.020088( 0.214147)\tCls:  0.000941( 0.045829)\tBox:  0.000000( 0.062130)\tObj:  0.003652( 0.022510)\tRPN  0.015495( 0.083677)\n",
      "[Train]Epoch: [2][4150/5093]\tLoss_sum:  0.347265( 0.214155)\tCls:  0.068558( 0.045822)\tBox:  0.173737( 0.062191)\tObj:  0.043101( 0.022502)\tRPN  0.061869( 0.083640)\n",
      "[Train]Epoch: [2][4160/5093]\tLoss_sum:  0.113837( 0.214230)\tCls:  0.011769( 0.045841)\tBox:  0.000000( 0.062252)\tObj:  0.060314( 0.022537)\tRPN  0.041754( 0.083601)\n",
      "[Train]Epoch: [2][4170/5093]\tLoss_sum:  0.352569( 0.214107)\tCls:  0.139203( 0.045873)\tBox:  0.117529( 0.062260)\tObj:  0.063985( 0.022529)\tRPN  0.031852( 0.083444)\n",
      "[Train]Epoch: [2][4180/5093]\tLoss_sum:  0.023944( 0.213787)\tCls:  0.000539( 0.045790)\tBox:  0.000000( 0.062167)\tObj:  0.020921( 0.022503)\tRPN  0.002484( 0.083327)\n",
      "[Train]Epoch: [2][4190/5093]\tLoss_sum:  0.141420( 0.213622)\tCls:  0.038676( 0.045743)\tBox:  0.087383( 0.062113)\tObj:  0.005146( 0.022468)\tRPN  0.010216( 0.083298)\n",
      "[Train]Epoch: [2][4200/5093]\tLoss_sum:  0.648358( 0.213763)\tCls:  0.149066( 0.045766)\tBox:  0.297583( 0.062229)\tObj:  0.012349( 0.022444)\tRPN  0.189361( 0.083324)\n",
      "[Train]Epoch: [2][4210/5093]\tLoss_sum:  0.207555( 0.213557)\tCls:  0.037680( 0.045693)\tBox:  0.101140( 0.062182)\tObj:  0.016852( 0.022433)\tRPN  0.051883( 0.083248)\n",
      "[Train]Epoch: [2][4220/5093]\tLoss_sum:  0.609777( 0.213649)\tCls:  0.107097( 0.045691)\tBox:  0.276383( 0.062274)\tObj:  0.030392( 0.022419)\tRPN  0.195905( 0.083265)\n",
      "[Train]Epoch: [2][4230/5093]\tLoss_sum:  0.488503( 0.214273)\tCls:  0.097309( 0.045818)\tBox:  0.245829( 0.062641)\tObj:  0.038330( 0.022447)\tRPN  0.107036( 0.083367)\n",
      "[Train]Epoch: [2][4240/5093]\tLoss_sum:  0.237459( 0.214308)\tCls:  0.035213( 0.045844)\tBox:  0.080215( 0.062705)\tObj:  0.018259( 0.022434)\tRPN  0.103772( 0.083326)\n",
      "[Train]Epoch: [2][4250/5093]\tLoss_sum:  0.012960( 0.214140)\tCls:  0.002173( 0.045800)\tBox:  0.000000( 0.062690)\tObj:  0.003649( 0.022420)\tRPN  0.007138( 0.083229)\n",
      "[Train]Epoch: [2][4260/5093]\tLoss_sum:  0.233725( 0.214030)\tCls:  0.065185( 0.045806)\tBox:  0.112826( 0.062676)\tObj:  0.037260( 0.022398)\tRPN  0.018455( 0.083150)\n",
      "[Train]Epoch: [2][4270/5093]\tLoss_sum:  0.267505( 0.213911)\tCls:  0.050278( 0.045794)\tBox:  0.154144( 0.062729)\tObj:  0.026275( 0.022388)\tRPN  0.036808( 0.082999)\n",
      "[Train]Epoch: [2][4280/5093]\tLoss_sum:  0.397136( 0.214072)\tCls:  0.172419( 0.045850)\tBox:  0.213466( 0.062807)\tObj:  0.001125( 0.022372)\tRPN  0.010125( 0.083044)\n",
      "[Train]Epoch: [2][4290/5093]\tLoss_sum:  0.038824( 0.213824)\tCls:  0.000328( 0.045796)\tBox:  0.000000( 0.062761)\tObj:  0.005403( 0.022336)\tRPN  0.033093( 0.082931)\n",
      "[Train]Epoch: [2][4300/5093]\tLoss_sum:  0.339619( 0.214048)\tCls:  0.114245( 0.045836)\tBox:  0.178194( 0.062898)\tObj:  0.027382( 0.022380)\tRPN  0.019797( 0.082933)\n",
      "[Train]Epoch: [2][4310/5093]\tLoss_sum:  0.057090( 0.213922)\tCls:  0.004408( 0.045824)\tBox:  0.000000( 0.062839)\tObj:  0.010695( 0.022345)\tRPN  0.041987( 0.082913)\n",
      "[Train]Epoch: [2][4320/5093]\tLoss_sum:  0.192427( 0.214046)\tCls:  0.053087( 0.045875)\tBox:  0.095830( 0.062866)\tObj:  0.028116( 0.022353)\tRPN  0.015394( 0.082952)\n",
      "[Train]Epoch: [2][4330/5093]\tLoss_sum:  0.532039( 0.214614)\tCls:  0.151330( 0.046040)\tBox:  0.217075( 0.063049)\tObj:  0.024918( 0.022358)\tRPN  0.138717( 0.083167)\n",
      "[Train]Epoch: [2][4340/5093]\tLoss_sum:  0.074884( 0.214695)\tCls:  0.013998( 0.046095)\tBox:  0.000000( 0.063122)\tObj:  0.009085( 0.022344)\tRPN  0.051800( 0.083134)\n",
      "[Train]Epoch: [2][4350/5093]\tLoss_sum:  0.138959( 0.214858)\tCls:  0.035154( 0.046148)\tBox:  0.088513( 0.063197)\tObj:  0.003124( 0.022329)\tRPN  0.012167( 0.083185)\n",
      "[Train]Epoch: [2][4360/5093]\tLoss_sum:  0.078234( 0.214513)\tCls:  0.001929( 0.046054)\tBox:  0.000000( 0.063057)\tObj:  0.028063( 0.022304)\tRPN  0.048242( 0.083098)\n",
      "[Train]Epoch: [2][4370/5093]\tLoss_sum:  0.169202( 0.214760)\tCls:  0.056983( 0.046199)\tBox:  0.107845( 0.063203)\tObj:  0.001556( 0.022304)\tRPN  0.002818( 0.083054)\n",
      "[Train]Epoch: [2][4380/5093]\tLoss_sum:  0.012242( 0.214348)\tCls:  0.002301( 0.046106)\tBox:  0.000000( 0.063087)\tObj:  0.004930( 0.022275)\tRPN  0.005012( 0.082880)\n",
      "[Train]Epoch: [2][4390/5093]\tLoss_sum:  0.287086( 0.214396)\tCls:  0.051423( 0.046111)\tBox:  0.082302( 0.063136)\tObj:  0.022016( 0.022258)\tRPN  0.131346( 0.082891)\n",
      "[Train]Epoch: [2][4400/5093]\tLoss_sum:  0.081159( 0.214457)\tCls:  0.004896( 0.046145)\tBox:  0.000000( 0.063142)\tObj:  0.005955( 0.022338)\tRPN  0.070308( 0.082832)\n",
      "[Train]Epoch: [2][4410/5093]\tLoss_sum:  0.017413( 0.214082)\tCls:  0.003360( 0.046052)\tBox:  0.000000( 0.062999)\tObj:  0.008973( 0.022339)\tRPN  0.005080( 0.082692)\n",
      "[Train]Epoch: [2][4420/5093]\tLoss_sum:  0.080784( 0.213970)\tCls:  0.006306( 0.046042)\tBox:  0.000000( 0.062977)\tObj:  0.026117( 0.022329)\tRPN  0.048361( 0.082622)\n",
      "[Train]Epoch: [2][4430/5093]\tLoss_sum:  0.032142( 0.213554)\tCls:  0.010425( 0.045944)\tBox:  0.000000( 0.062834)\tObj:  0.016588( 0.022301)\tRPN  0.005129( 0.082475)\n",
      "[Train]Epoch: [2][4440/5093]\tLoss_sum:  0.080357( 0.213754)\tCls:  0.000654( 0.046017)\tBox:  0.000000( 0.062916)\tObj:  0.012871( 0.022297)\tRPN  0.066832( 0.082524)\n",
      "[Train]Epoch: [2][4450/5093]\tLoss_sum:  0.415365( 0.213819)\tCls:  0.074567( 0.046045)\tBox:  0.129495( 0.062934)\tObj:  0.097211( 0.022312)\tRPN  0.114092( 0.082528)\n",
      "[Train]Epoch: [2][4460/5093]\tLoss_sum:  0.222087( 0.213766)\tCls:  0.041350( 0.046063)\tBox:  0.107665( 0.062956)\tObj:  0.029383( 0.022314)\tRPN  0.043689( 0.082432)\n",
      "[Train]Epoch: [2][4470/5093]\tLoss_sum:  0.008891( 0.213384)\tCls:  0.000352( 0.045974)\tBox:  0.000000( 0.062860)\tObj:  0.002676( 0.022280)\tRPN  0.005863( 0.082269)\n",
      "[Train]Epoch: [2][4480/5093]\tLoss_sum:  0.017466( 0.213057)\tCls:  0.000278( 0.045898)\tBox:  0.000000( 0.062782)\tObj:  0.011272( 0.022256)\tRPN  0.005916( 0.082121)\n",
      "[Train]Epoch: [2][4490/5093]\tLoss_sum:  0.062877( 0.212643)\tCls:  0.006776( 0.045808)\tBox:  0.020061( 0.062652)\tObj:  0.019588( 0.022232)\tRPN  0.016452( 0.081951)\n",
      "[Train]Epoch: [2][4500/5093]\tLoss_sum:  0.009568( 0.212512)\tCls:  0.001582( 0.045830)\tBox:  0.000000( 0.062659)\tObj:  0.003185( 0.022218)\tRPN  0.004801( 0.081805)\n",
      "[Train]Epoch: [2][4510/5093]\tLoss_sum:  0.010844( 0.212223)\tCls:  0.006264( 0.045788)\tBox:  0.000000( 0.062582)\tObj:  0.002491( 0.022198)\tRPN  0.002089( 0.081654)\n",
      "[Train]Epoch: [2][4520/5093]\tLoss_sum:  0.311008( 0.212324)\tCls:  0.112044( 0.045843)\tBox:  0.154483( 0.062603)\tObj:  0.028292( 0.022243)\tRPN  0.016189( 0.081635)\n",
      "[Train]Epoch: [2][4530/5093]\tLoss_sum:  0.080867( 0.212211)\tCls:  0.023764( 0.045815)\tBox:  0.000000( 0.062545)\tObj:  0.016299( 0.022260)\tRPN  0.040805( 0.081591)\n",
      "[Train]Epoch: [2][4540/5093]\tLoss_sum:  0.009483( 0.212028)\tCls:  0.002241( 0.045785)\tBox:  0.000000( 0.062519)\tObj:  0.002924( 0.022243)\tRPN  0.004319( 0.081481)\n",
      "[Train]Epoch: [2][4550/5093]\tLoss_sum:  0.274139( 0.211785)\tCls:  0.019238( 0.045719)\tBox:  0.094845( 0.062446)\tObj:  0.021545( 0.022225)\tRPN  0.138511( 0.081396)\n",
      "[Train]Epoch: [2][4560/5093]\tLoss_sum:  0.006915( 0.211482)\tCls:  0.000088( 0.045655)\tBox:  0.000000( 0.062388)\tObj:  0.003936( 0.022192)\tRPN  0.002891( 0.081246)\n",
      "[Train]Epoch: [2][4570/5093]\tLoss_sum:  0.005820( 0.211040)\tCls:  0.001182( 0.045558)\tBox:  0.000000( 0.062251)\tObj:  0.002947( 0.022157)\tRPN  0.001690( 0.081073)\n",
      "[Train]Epoch: [2][4580/5093]\tLoss_sum:  0.241519( 0.211010)\tCls:  0.070062( 0.045572)\tBox:  0.105137( 0.062246)\tObj:  0.028199( 0.022180)\tRPN  0.038120( 0.081013)\n",
      "[Train]Epoch: [2][4590/5093]\tLoss_sum:  0.222298( 0.211030)\tCls:  0.030321( 0.045569)\tBox:  0.095415( 0.062314)\tObj:  0.021205( 0.022182)\tRPN  0.075358( 0.080965)\n",
      "[Train]Epoch: [2][4600/5093]\tLoss_sum:  0.216256( 0.210994)\tCls:  0.070154( 0.045570)\tBox:  0.058842( 0.062363)\tObj:  0.003435( 0.022164)\tRPN  0.083824( 0.080897)\n",
      "[Train]Epoch: [2][4610/5093]\tLoss_sum:  0.319037( 0.211078)\tCls:  0.081638( 0.045595)\tBox:  0.131714( 0.062426)\tObj:  0.006738( 0.022169)\tRPN  0.098947( 0.080889)\n",
      "[Train]Epoch: [2][4620/5093]\tLoss_sum:  0.190953( 0.211137)\tCls:  0.021753( 0.045608)\tBox:  0.082463( 0.062509)\tObj:  0.031189( 0.022156)\tRPN  0.055549( 0.080864)\n",
      "[Train]Epoch: [2][4630/5093]\tLoss_sum:  0.179154( 0.211004)\tCls:  0.014443( 0.045575)\tBox:  0.051565( 0.062513)\tObj:  0.001855( 0.022129)\tRPN  0.111291( 0.080787)\n",
      "[Train]Epoch: [2][4640/5093]\tLoss_sum:  0.242810( 0.210981)\tCls:  0.058186( 0.045617)\tBox:  0.075499( 0.062517)\tObj:  0.034548( 0.022119)\tRPN  0.074577( 0.080729)\n",
      "[Train]Epoch: [2][4650/5093]\tLoss_sum:  0.323984( 0.210824)\tCls:  0.004308( 0.045591)\tBox:  0.002623( 0.062474)\tObj:  0.006110( 0.022090)\tRPN  0.310942( 0.080669)\n",
      "[Train]Epoch: [2][4660/5093]\tLoss_sum:  0.498308( 0.210843)\tCls:  0.075682( 0.045579)\tBox:  0.153829( 0.062472)\tObj:  0.032430( 0.022065)\tRPN  0.236367( 0.080726)\n",
      "[Train]Epoch: [2][4670/5093]\tLoss_sum:  0.403638( 0.211185)\tCls:  0.127709( 0.045680)\tBox:  0.165318( 0.062602)\tObj:  0.015191( 0.022084)\tRPN  0.095419( 0.080819)\n",
      "[Train]Epoch: [2][4680/5093]\tLoss_sum:  0.252564( 0.211578)\tCls:  0.061195( 0.045834)\tBox:  0.075619( 0.062787)\tObj:  0.009474( 0.022078)\tRPN  0.106276( 0.080879)\n",
      "[Train]Epoch: [2][4690/5093]\tLoss_sum:  0.192311( 0.211473)\tCls:  0.045947( 0.045836)\tBox:  0.130263( 0.062791)\tObj:  0.003167( 0.022052)\tRPN  0.012934( 0.080793)\n",
      "[Train]Epoch: [2][4700/5093]\tLoss_sum:  0.363961( 0.211190)\tCls:  0.041873( 0.045756)\tBox:  0.028836( 0.062679)\tObj:  0.025761( 0.022025)\tRPN  0.267490( 0.080730)\n",
      "[Train]Epoch: [2][4710/5093]\tLoss_sum:  0.154089( 0.211303)\tCls:  0.034366( 0.045858)\tBox:  0.085776( 0.062717)\tObj:  0.028818( 0.022047)\tRPN  0.005129( 0.080681)\n",
      "[Train]Epoch: [2][4720/5093]\tLoss_sum:  0.249452( 0.211054)\tCls:  0.019779( 0.045771)\tBox:  0.018906( 0.062590)\tObj:  0.033289( 0.022019)\tRPN  0.177478( 0.080673)\n",
      "[Train]Epoch: [2][4730/5093]\tLoss_sum:  0.091512( 0.211049)\tCls:  0.000484( 0.045736)\tBox:  0.000000( 0.062612)\tObj:  0.004175( 0.021999)\tRPN  0.086853( 0.080702)\n",
      "[Train]Epoch: [2][4740/5093]\tLoss_sum:  0.017156( 0.210936)\tCls:  0.000326( 0.045703)\tBox:  0.000000( 0.062588)\tObj:  0.002788( 0.022001)\tRPN  0.014042( 0.080644)\n",
      "[Train]Epoch: [2][4750/5093]\tLoss_sum:  0.194678( 0.210635)\tCls:  0.013508( 0.045620)\tBox:  0.054631( 0.062488)\tObj:  0.011591( 0.021974)\tRPN  0.114948( 0.080553)\n",
      "[Train]Epoch: [2][4760/5093]\tLoss_sum:  0.007144( 0.210420)\tCls:  0.001075( 0.045550)\tBox:  0.000000( 0.062423)\tObj:  0.002852( 0.021960)\tRPN  0.003217( 0.080487)\n",
      "[Train]Epoch: [2][4770/5093]\tLoss_sum:  0.310194( 0.210323)\tCls:  0.072758( 0.045504)\tBox:  0.117176( 0.062371)\tObj:  0.037265( 0.021941)\tRPN  0.082996( 0.080507)\n",
      "[Train]Epoch: [2][4780/5093]\tLoss_sum:  0.296423( 0.210184)\tCls:  0.071148( 0.045476)\tBox:  0.133362( 0.062367)\tObj:  0.027412( 0.021931)\tRPN  0.064500( 0.080410)\n",
      "[Train]Epoch: [2][4790/5093]\tLoss_sum:  0.401423( 0.210137)\tCls:  0.071681( 0.045470)\tBox:  0.123307( 0.062405)\tObj:  0.022230( 0.021910)\tRPN  0.184205( 0.080352)\n",
      "[Train]Epoch: [2][4800/5093]\tLoss_sum:  0.197753( 0.210467)\tCls:  0.010790( 0.045499)\tBox:  0.021296( 0.062492)\tObj:  0.018453( 0.021945)\tRPN  0.147214( 0.080532)\n",
      "[Train]Epoch: [2][4810/5093]\tLoss_sum:  0.063677( 0.210353)\tCls:  0.001744( 0.045446)\tBox:  0.019568( 0.062459)\tObj:  0.006483( 0.021945)\tRPN  0.035882( 0.080503)\n",
      "[Train]Epoch: [2][4820/5093]\tLoss_sum:  0.176142( 0.210124)\tCls:  0.040996( 0.045395)\tBox:  0.081697( 0.062390)\tObj:  0.007833( 0.021929)\tRPN  0.045616( 0.080409)\n",
      "[Train]Epoch: [2][4830/5093]\tLoss_sum:  0.125296( 0.210106)\tCls:  0.023625( 0.045369)\tBox:  0.027501( 0.062378)\tObj:  0.023968( 0.021930)\tRPN  0.050203( 0.080429)\n",
      "[Train]Epoch: [2][4840/5093]\tLoss_sum:  0.010558( 0.210043)\tCls:  0.002760( 0.045370)\tBox:  0.000000( 0.062381)\tObj:  0.003030( 0.021934)\tRPN  0.004768( 0.080359)\n",
      "[Train]Epoch: [2][4850/5093]\tLoss_sum:  0.189570( 0.209852)\tCls:  0.062188( 0.045359)\tBox:  0.096489( 0.062341)\tObj:  0.029473( 0.021924)\tRPN  0.001420( 0.080227)\n",
      "[Train]Epoch: [2][4860/5093]\tLoss_sum:  0.197985( 0.209566)\tCls:  0.035887( 0.045296)\tBox:  0.033545( 0.062258)\tObj:  0.035913( 0.021899)\tRPN  0.092640( 0.080113)\n",
      "[Train]Epoch: [2][4870/5093]\tLoss_sum:  0.575331( 0.209859)\tCls:  0.131653( 0.045381)\tBox:  0.210528( 0.062366)\tObj:  0.067272( 0.021904)\tRPN  0.165878( 0.080207)\n",
      "[Train]Epoch: [2][4880/5093]\tLoss_sum:  0.015950( 0.209609)\tCls:  0.001382( 0.045335)\tBox:  0.000000( 0.062307)\tObj:  0.003058( 0.021881)\tRPN  0.011510( 0.080085)\n",
      "[Train]Epoch: [2][4890/5093]\tLoss_sum:  0.073181( 0.209775)\tCls:  0.000526( 0.045343)\tBox:  0.000000( 0.062287)\tObj:  0.013232( 0.021876)\tRPN  0.059423( 0.080269)\n",
      "[Train]Epoch: [2][4900/5093]\tLoss_sum:  0.015074( 0.209410)\tCls:  0.002396( 0.045252)\tBox:  0.000000( 0.062160)\tObj:  0.003308( 0.021845)\tRPN  0.009370( 0.080153)\n",
      "[Train]Epoch: [2][4910/5093]\tLoss_sum:  0.022686( 0.209243)\tCls:  0.001015( 0.045204)\tBox:  0.000000( 0.062106)\tObj:  0.003180( 0.021822)\tRPN  0.018492( 0.080111)\n",
      "[Train]Epoch: [2][4920/5093]\tLoss_sum:  0.023190( 0.209338)\tCls:  0.000139( 0.045220)\tBox:  0.000000( 0.062170)\tObj:  0.003747( 0.021858)\tRPN  0.019304( 0.080090)\n",
      "[Train]Epoch: [2][4930/5093]\tLoss_sum:  0.224684( 0.209460)\tCls:  0.097964( 0.045269)\tBox:  0.087070( 0.062226)\tObj:  0.029521( 0.021874)\tRPN  0.010130( 0.080091)\n",
      "[Train]Epoch: [2][4940/5093]\tLoss_sum:  0.471794( 0.209327)\tCls:  0.167654( 0.045249)\tBox:  0.092303( 0.062176)\tObj:  0.018530( 0.021873)\tRPN  0.193308( 0.080029)\n",
      "[Train]Epoch: [2][4950/5093]\tLoss_sum:  0.340623( 0.209623)\tCls:  0.146841( 0.045382)\tBox:  0.100307( 0.062304)\tObj:  0.042691( 0.021884)\tRPN  0.050784( 0.080053)\n",
      "[Train]Epoch: [2][4960/5093]\tLoss_sum:  0.031366( 0.209597)\tCls:  0.003055( 0.045396)\tBox:  0.000000( 0.062366)\tObj:  0.006296( 0.021868)\tRPN  0.022015( 0.079967)\n",
      "[Train]Epoch: [2][4970/5093]\tLoss_sum:  0.395957( 0.209649)\tCls:  0.114466( 0.045438)\tBox:  0.208199( 0.062435)\tObj:  0.030077( 0.021856)\tRPN  0.043215( 0.079921)\n",
      "[Train]Epoch: [2][4980/5093]\tLoss_sum:  0.031171( 0.209406)\tCls:  0.018430( 0.045420)\tBox:  0.000000( 0.062368)\tObj:  0.003911( 0.021829)\tRPN  0.008830( 0.079789)\n",
      "[Train]Epoch: [2][4990/5093]\tLoss_sum:  0.039123( 0.209493)\tCls:  0.012481( 0.045488)\tBox:  0.000000( 0.062429)\tObj:  0.017972( 0.021847)\tRPN  0.008670( 0.079729)\n",
      "[Train]Epoch: [2][5000/5093]\tLoss_sum:  0.109076( 0.209579)\tCls:  0.000535( 0.045466)\tBox:  0.000000( 0.062429)\tObj:  0.002174( 0.021845)\tRPN  0.106368( 0.079840)\n",
      "[Train]Epoch: [2][5010/5093]\tLoss_sum:  0.334048( 0.209784)\tCls:  0.033386( 0.045508)\tBox:  0.120484( 0.062506)\tObj:  0.018895( 0.021869)\tRPN  0.161282( 0.079902)\n",
      "[Train]Epoch: [2][5020/5093]\tLoss_sum:  0.160060( 0.209897)\tCls:  0.034454( 0.045551)\tBox:  0.105135( 0.062601)\tObj:  0.012390( 0.021860)\tRPN  0.008081( 0.079886)\n",
      "[Train]Epoch: [2][5030/5093]\tLoss_sum:  0.029474( 0.209851)\tCls:  0.000507( 0.045477)\tBox:  0.000000( 0.062497)\tObj:  0.003069( 0.021838)\tRPN  0.025898( 0.080039)\n",
      "[Train]Epoch: [2][5040/5093]\tLoss_sum:  0.272268( 0.209707)\tCls:  0.061945( 0.045422)\tBox:  0.090286( 0.062426)\tObj:  0.005394( 0.021812)\tRPN  0.114643( 0.080047)\n",
      "[Train]Epoch: [2][5050/5093]\tLoss_sum:  0.327377( 0.209782)\tCls:  0.001693( 0.045457)\tBox:  0.000000( 0.062495)\tObj:  0.006877( 0.021811)\tRPN  0.318808( 0.080018)\n",
      "[Train]Epoch: [2][5060/5093]\tLoss_sum:  0.139373( 0.209984)\tCls:  0.000190( 0.045496)\tBox:  0.000000( 0.062557)\tObj:  0.006229( 0.021795)\tRPN  0.132954( 0.080135)\n",
      "[Train]Epoch: [2][5070/5093]\tLoss_sum:  0.255152( 0.209929)\tCls:  0.055834( 0.045448)\tBox:  0.131931( 0.062510)\tObj:  0.017718( 0.021792)\tRPN  0.049670( 0.080179)\n",
      "[Train]Epoch: [2][5080/5093]\tLoss_sum:  0.207011( 0.210117)\tCls:  0.000139( 0.045457)\tBox:  0.000000( 0.062576)\tObj:  0.002214( 0.021788)\tRPN  0.204658( 0.080296)\n",
      "[Train]Epoch: [2][5090/5093]\tLoss_sum:  0.204904( 0.209974)\tCls:  0.050766( 0.045401)\tBox:  0.105304( 0.062519)\tObj:  0.004959( 0.021771)\tRPN  0.043876( 0.080283)\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epoch = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], gamma=0.5)\n",
    "losses = []\n",
    "for e in range(start_epoch+1, epoch):\n",
    "    train_one_epoch(model, device, train_data, optimizer, e, losses)\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "            'epoch': e,\n",
    "            'weights': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict()\n",
    "        }\n",
    "torch.save(states,'checkpoints/last_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load('checkpoints/last_checkpoint.pt')\n",
    "start_epoch = checkpoints['epoch']\n",
    "model.load_state_dict(checkpoints['weights'])\n",
    "optimizer.load_state_dict(checkpoints['optimizer'])\n",
    "lr_scheduler.load_state_dict(checkpoints['lr_scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[244.6000, 140.7000, 246.5500, 144.4500],\n",
      "        [253.2500, 136.1000, 255.9000, 140.1000],\n",
      "        [262.0500, 140.6500, 264.2000, 144.2500]]), 'labels': tensor([ 3, 13, 13])}\n",
      "[{'boxes': tensor([[261.3960, 140.5317, 264.2551, 144.8651],\n",
      "        [253.6525, 136.7338, 256.2070, 141.7906],\n",
      "        [253.3901, 136.5048, 255.5030, 140.5381],\n",
      "        [253.9260, 136.1562, 256.0099, 139.8969],\n",
      "        [261.5974, 139.7525, 264.0901, 144.0281],\n",
      "        [253.6632, 136.0107, 256.0873, 140.7885],\n",
      "        [261.4073, 140.7559, 264.2865, 145.1864],\n",
      "        [254.2957, 136.1245, 256.9283, 141.3715],\n",
      "        [253.6626, 137.0677, 256.1863, 142.1774]], device='cuda:0'), 'labels': tensor([13, 13, 13, 13, 11, 11,  3, 13,  3], device='cuda:0'), 'scores': tensor([0.6349, 0.5779, 0.3207, 0.2503, 0.1234, 0.1016, 0.0995, 0.0939, 0.0862],\n",
      "       device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x = data_list[6][0][0].to(device)\n",
    "with torch.no_grad():\n",
    "    predictions = model([x])\n",
    "print(data_list[6][1][0])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96410b080c3ace32be3f113203d8e11bd99d59bea389843ba463ca870d414648"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
